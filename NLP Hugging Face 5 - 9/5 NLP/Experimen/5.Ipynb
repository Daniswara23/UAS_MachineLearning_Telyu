{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-train.json.gz\n",
    "!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-test.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ccf97fa802842b8b84e3832415e2c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "squad_it_dataset = load_dataset(\"json\", data_files=\"SQuAD_it-train.json\", field=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Terremoto del Sichuan del 2008',\n",
       " 'paragraphs': [{'context': \"Il terremoto del Sichuan del 2008 o il terremoto del Gran Sichuan, misurato a 8.0 Ms e 7.9 Mw, e si è verificato alle 02:28:01 PM China Standard Time all' epicentro (06:28:01 UTC) il 12 maggio nella provincia del Sichuan, ha ucciso 69.197 persone e lasciato 18.222 dispersi.\",\n",
       "   'qas': [{'answers': [{'answer_start': 29, 'text': '2008'}],\n",
       "     'id': '56cdca7862d2951400fa6826',\n",
       "     'question': 'In quale anno si è verificato il terremoto nel Sichuan?'},\n",
       "    {'answers': [{'answer_start': 232, 'text': '69.197'}],\n",
       "     'id': '56cdca7862d2951400fa6828',\n",
       "     'question': 'Quante persone sono state uccise come risultato?'},\n",
       "    {'answers': [{'answer_start': 29, 'text': '2008'}],\n",
       "     'id': '56d4f9902ccc5a1400d833c0',\n",
       "     'question': 'Quale anno ha avuto luogo il terremoto del Sichuan?'},\n",
       "    {'answers': [{'answer_start': 78, 'text': '8.0 Ms e 7.9 Mw'}],\n",
       "     'id': '56d4f9902ccc5a1400d833c1',\n",
       "     'question': 'Che cosa ha fatto la misura di sisma?'},\n",
       "    {'answers': [{'answer_start': 183, 'text': '12 maggio'}],\n",
       "     'id': '56d4f9902ccc5a1400d833c2',\n",
       "     'question': 'Che giorno si è verificato il terremoto?'},\n",
       "    {'answers': [{'answer_start': 118,\n",
       "       'text': '02:28:01 PM China Standard Time'}],\n",
       "     'id': '56d4f9902ccc5a1400d833c3',\n",
       "     'question': 'Che ora del giorno è accaduto il terremoto?'},\n",
       "    {'answers': [{'answer_start': 232, 'text': '69.197'}],\n",
       "     'id': '56d4f9902ccc5a1400d833c4',\n",
       "     'question': 'Quante persone sono morte?'}]},\n",
       "  {'context': 'E\\' noto anche come terremoto di Wenchuan (Cinese:????; pinyin: Wènchu? n dà dìzhèn; letteralmente:\"Grande terremoto di Wenchuan\"), dopo l\\' ubicazione dell\\' epicentro del terremoto, Wenchuan County, Sichuan. L\\' epicentro era di 80 chilometri (50 miglia) ad ovest nord-ovest di Chengdu, capoluogo di provincia, con una profondità focale di 19 km (12 miglia). Il terremoto ha colpito anche i paesi vicini e lontani da Pechino e Shanghai-1.500 km (930 mi) e 1.700 km (1.060 mi) di distanza, dove gli edifici adibiti a uffici hanno oscillato con il tremore. Forti scosse di assestamento, un po\\' superiori alla magnitudo 6, hanno continuato a colpire l\\' area anche mesi dopo il sisma principale, causando nuove vittime e danni.',\n",
       "   'qas': [{'answers': [{'answer_start': 415, 'text': 'Pechino e Shanghai'}],\n",
       "     'id': '56cdcb2c62d2951400fa6830',\n",
       "     'question': 'Quali città lontane in altri paesi potrebbero sentire il terremoto?'},\n",
       "    {'answers': [{'answer_start': 338, 'text': '19 km'}],\n",
       "     'id': '56cdcb2c62d2951400fa6833',\n",
       "     'question': 'Qual è stata la profondità focale del terremoto?'},\n",
       "    {'answers': [{'answer_start': 659, 'text': 'mesi dopo'}],\n",
       "     'id': '56cdcb2c62d2951400fa6834',\n",
       "     'question': 'Quanto tempo dopo il terremoto si sono sentite le scosse di assestamento?'},\n",
       "    {'answers': [{'answer_start': 181, 'text': 'Wenchuan County, Sichuan'}],\n",
       "     'id': '56d4fb6f2ccc5a1400d833d5',\n",
       "     'question': \"Dov' era l' epicentro del terremoto?\"},\n",
       "    {'answers': [{'answer_start': 227, 'text': '80 chilometri'}],\n",
       "     'id': '56d4fb6f2ccc5a1400d833d6',\n",
       "     'question': 'Quanto lontano era da Chengdu?'},\n",
       "    {'answers': [{'answer_start': 338, 'text': '19 km'}],\n",
       "     'id': '56d4fb6f2ccc5a1400d833d7',\n",
       "     'question': 'Qual era la profondità focale del sisma?'}]},\n",
       "  {'context': \"I dati ufficiali (al 21 luglio 2008 ore 12:00 CST) hanno dichiarato che 69.197 sono stati confermati morti, di cui 68.636 nella provincia del Sichuan e 374.176 feriti, di cui 18.222 scomparsi. Il terremoto ha lasciato circa 4,8 milioni di senzatetto, anche se il numero potrebbe raggiungere gli 11 milioni. Circa 15 milioni di persone vivevano nell' area colpita. E' stato il terremoto più mortale per colpire la Cina dopo il terremoto di Tangshan 1976, che ha ucciso almeno 240.000 persone, e il più forte del paese dal terremoto di Chayu 1950, che ha registrato a 8,5 sulla scala di magnitudo Richter. E' il 21° terremoto più morto di tutti i tempi. Il 6 novembre 2008, il governo centrale ha annunciato che avrebbe speso 1 trilione di RMB (circa 146,5 miliardi di dollari USA) nei prossimi tre anni per ricostruire le aree devastate dal terremoto, come parte del programma cinese di stimolo economico.\",\n",
       "   'qas': [{'answers': [{'answer_start': 72, 'text': '69.197'}],\n",
       "     'id': '56cdcbb762d2951400fa683a',\n",
       "     'question': 'Quante persone sono state confermate morte?'},\n",
       "    {'answers': [{'answer_start': 115, 'text': '68.636'}],\n",
       "     'id': '56cdcbb762d2951400fa683b',\n",
       "     'question': 'Quanti morti sono stati confermati solo nella provincia del Sichuan?'},\n",
       "    {'answers': [{'answer_start': 224, 'text': '4,8 milioni'}],\n",
       "     'id': '56cdcbb762d2951400fa683c',\n",
       "     'question': 'Quante persone sono rimaste senza tetto a causa del terremoto?'},\n",
       "    {'answers': [{'answer_start': 313, 'text': '15 milioni'}],\n",
       "     'id': '56cdcbb762d2951400fa683d',\n",
       "     'question': 'Quante persone hanno vissuto nella zona colpita?'},\n",
       "    {'answers': [{'answer_start': 724, 'text': '1 trilione di RMB'}],\n",
       "     'id': '56cdcbb762d2951400fa683e',\n",
       "     'question': 'Quanto denaro è stato destinato alla ricostruzione di aree devastate?'},\n",
       "    {'answers': [{'answer_start': 115, 'text': '68.636'}],\n",
       "     'id': '56d4fca52ccc5a1400d833de',\n",
       "     'question': 'Quante persone sono morte nella provincia del Sichuan?'},\n",
       "    {'answers': [{'answer_start': 152, 'text': '374.176'}],\n",
       "     'id': '56d4fca52ccc5a1400d833df',\n",
       "     'question': 'Quanti sono stati feriti nel Sichuan?'},\n",
       "    {'answers': [{'answer_start': 175, 'text': '18.222'}],\n",
       "     'id': '56d4fca52ccc5a1400d833e0',\n",
       "     'question': 'Quante persone sono elencate come scomparse?'},\n",
       "    {'answers': [{'answer_start': 224, 'text': '4,8 milioni'}],\n",
       "     'id': '56d4fca52ccc5a1400d833e1',\n",
       "     'question': 'Quante persone sono senzatetto a causa del terremoto?'},\n",
       "    {'answers': [{'answer_start': 295, 'text': '11 milioni'}],\n",
       "     'id': '56d4fca52ccc5a1400d833e2',\n",
       "     'question': 'Quanto potrebbe arrivare il numero dei senzatetto?'}]},\n",
       "  {'context': \"Il terremoto ha avuto una magnitudine di 8,0 Ms e 7,9 Mw. L' epicentro è stato in Wenchuan County, Ngawa Tibetano e Prefettura Autonoma di Qiang, 80 km ad ovest / nord-ovest del capoluogo di provincia di Chengdu, con il suo tremore principale che si verifica alle 14:28:01.42 China Standard Time (06:28:01.42 UTC), il 12 maggio 2008 della durata di circa 2 minuti, nel terremoto quasi l' 80% degli edifici sono stati distrutti.\",\n",
       "   'qas': [{'answers': [{'answer_start': 355, 'text': '2 minuti'}],\n",
       "     'id': '56cdcc5562d2951400fa6847',\n",
       "     'question': 'Quanto tempo è durato il terremoto?'},\n",
       "    {'answers': [{'answer_start': 388, 'text': '80%'}],\n",
       "     'id': '56cdcc5562d2951400fa6848',\n",
       "     'question': 'Quale percentuale di edifici è stata distrutta?'},\n",
       "    {'answers': [{'answer_start': 41, 'text': '8,0 Ms e 7,9 Mw'}],\n",
       "     'id': '56d4fe332ccc5a1400d833e8',\n",
       "     'question': 'Qual era la magnitudo del terremoto?'},\n",
       "    {'answers': [{'answer_start': 355, 'text': '2 minuti'}],\n",
       "     'id': '56d4fe332ccc5a1400d833eb',\n",
       "     'question': 'Quanto tempo è durato il tremore principale?'},\n",
       "    {'answers': [{'answer_start': 379, 'text': \"quasi l' 80%\"}],\n",
       "     'id': '56d4fe332ccc5a1400d833ec',\n",
       "     'question': 'Quale percentuale di edifici è stata distrutta durante il sisma?'}]},\n",
       "  {'context': \"Secondo uno studio della China Earthquake Administration (CEA), il terremoto si è verificato lungo la faglia Longmenshan, una struttura di spinta lungo il confine della piastra Indo-Australiana e placca eurasiatica. Le attività sismiche si sono concentrate sulla sua frattura media (nota come frattura Yingxiu-Beichuan). La rottura è durata quasi 120 sec, con la maggior parte dell' energia rilasciata nei primi 80 sec. Partendo da Wenchuan, la rottura si propagò ad una velocità media di 3,1 chilometri al secondo 49° verso nord-est, rompendosi per un totale di circa 300 km. Lo spostamento massimo ammontava a 9 metri. Il fuoco era più profondo di 10 km.\",\n",
       "   'qas': [{'answers': [{'answer_start': 347, 'text': '120 sec'}],\n",
       "     'id': '56cdccd962d2951400fa6850',\n",
       "     'question': 'Quanto tempo ha durato la rottura?'},\n",
       "    {'answers': [{'answer_start': 650, 'text': '10 km'}],\n",
       "     'id': '56cdccd962d2951400fa6852',\n",
       "     'question': 'Quanto è stato profondo il centro del terremoto?'},\n",
       "    {'answers': [{'answer_start': 293, 'text': 'frattura Yingxiu-Beichuan'}],\n",
       "     'id': '56d5005d2ccc5a1400d833f4',\n",
       "     'question': 'Su quale frattura ha messo a fuoco il terremoto?'},\n",
       "    {'answers': [{'answer_start': 612, 'text': '9 metri'}],\n",
       "     'id': '56d5005d2ccc5a1400d833f6',\n",
       "     'question': 'Qual è stato lo sfollamento più causato dal terremoto?'}]},\n",
       "  {'context': 'Yazhou Zhoukan, con sede in Malesia, ha condotto un\\' intervista con l\\' ex ricercatore presso il China Seismological Bureau Geng Qingguo (??), in cui Geng ha sostenuto che un rapporto scritto riservato è stato inviato all\\' Ufficio sismologico di Stato il 30 aprile 2008, avvertendo circa il possibile verificarsi di un terremoto significativo nella regione della prefettura di Ngawa del Sichuan intorno all\\' 8 maggio, con una gamma di 10 giorni prima o dopo il terremoto. Il Geng, pur riconoscendo che la predizione del terremoto era ampiamente considerata problematica dalla comunità scientifica, credeva che \"più grande è il terremoto, più facile è prevedere\". Geng aveva a lungo tentato di stabilire una correlazione tra il verificarsi di siccità e terremoti; Premier Zhou Enlai ha riferito che ha preso interesse nel lavoro di Geng. La teoria di correlazione siccità-terra terremoto di Geng è stata pubblicata per la prima volta nel 1972, e ha detto di aver pronosticato con successo i terremoti di Haicheng 1975 e 1976 Tangshan. Lo stesso articolo di Yazhou Zhoukan ha sottolineato le difficoltà intrinseche associate alla previsione dei terremoti.',\n",
       "   'qas': [{'answers': [{'answer_start': 936, 'text': '1972'}],\n",
       "     'id': '56cdce0b62d2951400fa685b',\n",
       "     'question': 'Quando è stata rilasciata la teoria di correlazione siccità-terra terremoto di Geng?'},\n",
       "    {'answers': [{'answer_start': 394, 'text': \"intorno all' 8 maggio\"}],\n",
       "     'id': '56d67a8d1c8504140094714f',\n",
       "     'question': 'Qual era il tempo previsto per il terremoto?'},\n",
       "    {'answers': [{'answer_start': 741, 'text': 'siccità'}],\n",
       "     'id': '56d67a8d1c85041400947150',\n",
       "     'question': 'Che cosa ha cercato Geng a lungo di stabilire come rapporto con i terremoti?'}]},\n",
       "  {'context': 'In uno studio dell\\' USGS (United States Geological Survey) i modelli preliminari di rottura del terremoto hanno indicato uno spostamento fino a 9 metri lungo un guasto lungo circa 240 km di lunghezza e 20 km di profondità. Il terremoto ha generato deformazioni della superficie superiori a 3 metri e ha aumentato lo stress (e la probabilità che si verifichino eventi futuri) alle estremità nord-orientale e sud-occidentale del guasto. Il 20 maggio, il sismologo dell\\' USGS Tom Parsons ha avvertito che c\\' è \"alto rischio\" di una grave scossa di assestamento M>7 nelle prossime settimane o mesi.',\n",
       "   'qas': [{'answers': [{'answer_start': 137, 'text': 'fino a 9 metri'}],\n",
       "     'id': '56cdcebe62d2951400fa6862',\n",
       "     'question': 'Quanto è stato grande lo spostamento?'},\n",
       "    {'answers': [{'answer_start': 473, 'text': 'Tom Parsons'}],\n",
       "     'id': '56cdcebe62d2951400fa6866',\n",
       "     'question': \"Chi ha prima messo in guardia da possibili attività sismiche nell' area?\"},\n",
       "    {'answers': [{'answer_start': 144, 'text': '9 metri'}],\n",
       "     'id': '56d5027a9d1b871400ae05e1',\n",
       "     'question': \"Che cosa ha mostrato il Geological Survey degli Stati Uniti come l' entità dello spostamento?\"},\n",
       "    {'answers': [{'answer_start': 202, 'text': '20 km di profondità'}],\n",
       "     'id': '56d5027a9d1b871400ae05e3',\n",
       "     'question': 'Quanto è profondo il guasto?'},\n",
       "    {'answers': [{'answer_start': 508, 'text': 'alto rischio'}],\n",
       "     'id': '56d5027a9d1b871400ae05e5',\n",
       "     'question': 'Che cosa ha considerato Tom Parsons come il fattore di rischio per forti terremoti futuri?'}]},\n",
       "  {'context': 'Sismologo giapponese Yuji Yagi Yuji Yagi presso l\\' Università di Tsukuba ha detto che il terremoto si è verificato in due fasi:\"Il 155 miglia Longmenshan Fault tore in due sezioni, il primo uno strappo di circa sette metri, seguita da un secondo che ha tosato quattro metri\". I suoi dati hanno anche mostrato che il terremoto è durato circa due minuti e ha rilasciato 30 volte l\\' energia del grande terremoto di Hanshin del 1995 in Giappone, che ha ucciso oltre 6.000 persone. Egli ha sottolineato che la scarsità dell\\' epicentro e la densità di popolazione hanno notevolmente aumentato la gravità del terremoto. Teruyuki Kato, un sismologo dell\\' Università di Tokyo, ha detto che le onde sismiche del terremoto hanno percorso una lunga distanza senza perdere il loro potere a causa della fermezza del terreno nella Cina centrale.',\n",
       "   'qas': [{'answers': [{'answer_start': 115, 'text': 'in due fasi'}],\n",
       "     'id': '56d504539d1b871400ae05eb',\n",
       "     'question': 'Come ha fatto Yuji Yagi a dire che il terremoto è successo?'},\n",
       "    {'answers': [{'answer_start': 142, 'text': 'Longmenshan Fault'}],\n",
       "     'id': '56d504539d1b871400ae05ec',\n",
       "     'question': 'Che errore si è verificato in due luoghi?'},\n",
       "    {'answers': [{'answer_start': 368, 'text': '30 volte'}],\n",
       "     'id': '56d504539d1b871400ae05ee',\n",
       "     'question': 'Quanta più energia di quella prodotta dal terremoto del 1995 in Giappone?'},\n",
       "    {'answers': [{'answer_start': 789, 'text': 'fermezza del terreno'}],\n",
       "     'id': '56d504539d1b871400ae05ef',\n",
       "     'question': 'Perché le onde sismiche hanno viaggiato finora?'}]},\n",
       "  {'context': 'Tra 64 e 104 scosse di assestamento importanti, di magnitudo compresa tra 4,0 e 6,1, sono state registrate entro 72 ore dal sisma principale. Secondo i conteggi ufficiali cinesi,\"alle ore 12:00 CST, 6 novembre 2008 c\\' erano state 42.719 scariche post-shock totali, di cui 246 variavano da 4,0 SM a 4,9 SM, 34 da 5,0 MS a 5,9 MS, e 8 da 6,0 Ms a 6,4 MS; l\\' urto post-shock più forte misurato 6,4 MS.\" L\\' ultima scossa post-shock superiore a M6 si è verificato il 5 agosto.',\n",
       "   'qas': [{'answers': [{'answer_start': 0, 'text': 'Tra 64 e 104'}],\n",
       "     'id': '56cdd08862d2951400fa6894',\n",
       "     'question': 'Quante sono state le scosse di assestamento?'},\n",
       "    {'answers': [{'answer_start': 107,\n",
       "       'text': 'entro 72 ore dal sisma principale'}],\n",
       "     'id': '56cdd08862d2951400fa6896',\n",
       "     'question': 'Quando sono state registrate le scosse di assestamento?'},\n",
       "    {'answers': [{'answer_start': 0, 'text': 'Tra 64 e 104'}],\n",
       "     'id': '56d505f99d1b871400ae05f5',\n",
       "     'question': 'Quante sono state le scosse di assestamento entro 72 ore?'},\n",
       "    {'answers': [{'answer_start': 230, 'text': '42.719'}],\n",
       "     'id': '56d505f99d1b871400ae05f6',\n",
       "     'question': 'Che cosa dicono i cinesi è il numero totale di shock dopo il terremoto?'},\n",
       "    {'answers': [{'answer_start': 272, 'text': '246'}],\n",
       "     'id': '56d505f99d1b871400ae05f8',\n",
       "     'question': 'In quale data si sono verificate le scosse di assestamento più recenti superiori a 6 SM?'}]},\n",
       "  {'context': '(Il terremoto della sig. ra 6.1 del 30 agosto 2008 nel Sichuan meridionale non faceva parte di questa serie perché è stato causato da una diversa colpa.',\n",
       "   'qas': [{'answers': [{'answer_start': 55, 'text': 'Sichuan meridionale'}],\n",
       "     'id': '56cdd10962d2951400fa68a0',\n",
       "     'question': 'Dove si è verificato il terremoto?'},\n",
       "    {'answers': [{'answer_start': 55, 'text': 'Sichuan meridionale'}],\n",
       "     'id': '56cdd10962d2951400fa68a2',\n",
       "     'question': \"Dov' era il terremoto del 30 agosto 2008?\"},\n",
       "    {'answers': [{'answer_start': 20, 'text': 'sig'}],\n",
       "     'id': '56d507269d1b871400ae05ff',\n",
       "     'question': 'Qual era la grandezza del terremoto del Sichuan meridionale?'}]},\n",
       "  {'context': 'La mappa dell\\' intensità sismica pubblicata dal CEA dopo aver rilevato 500.000 km2 dell\\' area colpita mostra una liedu massima di XI sulla scala di intensità sismica cinese (CSIS), descritta come \"molto distruttiva\" sulla scala macrosismica europea (EMS) da cui il CSIS ha tratto riferimento. (USGS, utilizzando la scala di intensità Mercalli modificata (CC), collocava anche l\\' intensità massima a XI,\"molto disastrosa\". Due strisce sud-ovest-nord-est di liedu XI sono centrate intorno a Yingxiu, Wenchuan (la città più vicina all\\' epicentro del terremoto principale) e Beichuan (la città ripetutamente colpita da forti scosse di assestamento tra cui una che registra MS 6.1 il 1 agosto 2008), entrambe nella provincia del Sichuan, occupando un totale di 2.419 km2. La zona Yingxiu liedu-XI è lunga circa 66 km e larga 20 km lungo Wenchuan-Dujiangyan-Pengzhou; la zona Beichuan liedu-XI è lunga circa 82 km e larga 15 km lungo An County-Beichuan-Pingwu. L\\' area con liedu X (comparabile a X su EMS,\"distruttivo\" e X su MM,\"disastroso\") ha una superficie di 3.144 km2.',\n",
       "   'qas': [{'answers': [{'answer_start': 48, 'text': 'CEA'}],\n",
       "     'id': '56cdd21562d2951400fa68b0',\n",
       "     'question': \"Chi ha pubblicato la mappa dell' intensità dei terremoti?\"},\n",
       "    {'answers': [{'answer_start': 130, 'text': 'XI'}],\n",
       "     'id': '56cdd21562d2951400fa68b2',\n",
       "     'question': 'A quale intensità è stata scalata?'},\n",
       "    {'answers': [{'answer_start': 489, 'text': 'Yingxiu, Wenchuan'}],\n",
       "     'id': '56d5098a9d1b871400ae0609',\n",
       "     'question': \"Quale città era più vicina all' epicentro principale?\"}]},\n",
       "  {'context': \"Il sistema Longmen Shan Fault System si trova al confine orientale dell' altopiano tibetano e contiene diversi difetti. Questo terremoto ha rotto almeno due strutture imbricate in Longmen Shan Fault System, vale a dire il Fault Beichuan e il Guanxian-Anxian Fault. Nell' area epicentrale, lo slittamento medio in Fault Beichuan era di circa 3,5 metri (11 ft) verticale, di 3,5 metri (11 ft) orizzontale parallelo al guasto, e di 4,8 metri (16 ft) orizzontale-pendicolare al guasto. Nell' area di circa 30 chilometri (19 miglia) a nord-est dell' epicentro, lo scivolamento superficiale su Beichuan Fault è stato quasi esclusivamente dextral strike-slip fino a circa 3 metri, mentre lo scivolamento medio in Guanxian-Anxian Fault è stato di circa 2 metri verticali (6 ft 7 in) e 2,3 metri (7 ft 7 in) orizzontali. il confine orientale dell' altopiano tibetano.\",\n",
       "   'qas': [{'answers': [{'answer_start': 665, 'text': '3 metri'}],\n",
       "     'id': '56cdd4d762d2951400fa68cd',\n",
       "     'question': 'Quanto è stato grande lo slip 30 km a nord-est del guasto?'},\n",
       "    {'answers': [{'answer_start': 745, 'text': '2 metri'}],\n",
       "     'id': '56cdd4d762d2951400fa68ce',\n",
       "     'question': 'Qual è stato lo slittamento verticale media sul Guanxian-Anxian errore?'},\n",
       "    {'answers': [{'answer_start': 777, 'text': '2,3 metri'}],\n",
       "     'id': '56cdd4d762d2951400fa68cf',\n",
       "     'question': 'Che cosa è stato lo slittamento orizzontale media sul Guanxian-Anxian errore?'},\n",
       "    {'answers': [{'answer_start': 73, 'text': 'altopiano tibetano'}],\n",
       "     'id': '56cdd4d762d2951400fa68d0',\n",
       "     'question': 'Dove si trova il guasto dello shan Longmen?'},\n",
       "    {'answers': [{'answer_start': 3,\n",
       "       'text': 'sistema Longmen Shan Fault System'}],\n",
       "     'id': '56d516439d1b871400ae0611',\n",
       "     'question': 'Dove sono i guasti Beichuan e Guanxian-Ansia?'},\n",
       "    {'answers': [{'answer_start': 341, 'text': '3,5 metri'}],\n",
       "     'id': '56d516439d1b871400ae0612',\n",
       "     'question': 'Qual è stato lo slittamento verticale medio nel difetto di Beichaun?'},\n",
       "    {'answers': [{'answer_start': 341, 'text': '3,5 metri'}],\n",
       "     'id': '56d516439d1b871400ae0613',\n",
       "     'question': \"Qual è stato lo slittamento orizzontale nel Fault Beichuan all' epicentro?\"},\n",
       "    {'answers': [{'answer_start': 429, 'text': '4,8 metri'}],\n",
       "     'id': '56d516439d1b871400ae0614',\n",
       "     'question': 'Qual è stato lo slittamento orizzontale perpendicolare al guasto?'}]},\n",
       "  {'context': 'Gli edifici per uffici nel distretto finanziario di Shanghai, tra cui la Jin Mao Tower e la Hong Kong New World Tower, sono stati evacuati. Un receptionist al Tibet Hotel di Chengdu ha detto che le cose erano \"calme\" dopo che l\\' hotel ha evacuato i suoi ospiti. Nel frattempo, i lavoratori di uno stabilimento Ford nel Sichuan sono stati evacuati per circa 10 minuti. L\\' aeroporto internazionale di Chengdu Shuangliu è stato chiuso e la torre di controllo e il controllo radar regionale sono stati evacuati. Un volo di SilkAir è stato deviato e atterrato a Kunming. Cathay Pacific ha ritardato entrambe le tratte del suo quadruplo quotidiano Hong Kong a Londra a causa di questa perturbazione dei servizi di traffico aereo. Chengdu Shuangliu Aeroporto riaperto più tardi la sera del 12 maggio, offrendo un servizio limitato come l\\' aeroporto ha cominciato ad essere utilizzato come una zona di sosta per le operazioni di soccorso.',\n",
       "   'qas': [{'answers': [{'answer_start': 210, 'text': 'calm'}],\n",
       "     'id': '56cdd63a62d2951400fa68d7',\n",
       "     'question': \"Come ha descritto un receptionist l' atmosfera dopo l' evacuazione?\"},\n",
       "    {'answers': [{'answer_start': 357, 'text': '10 minuti'}],\n",
       "     'id': '56cdd63a62d2951400fa68d8',\n",
       "     'question': 'Per quanto tempo sono stati evacuati i lavoratori di Ford Plant?'},\n",
       "    {'answers': [{'answer_start': 371,\n",
       "       'text': 'aeroporto internazionale di Chengdu Shuangliu'}],\n",
       "     'id': '56cdd63a62d2951400fa68d9',\n",
       "     'question': 'Quale aeroporto è stato chiuso?'},\n",
       "    {'answers': [{'answer_start': 783, 'text': '12 maggio'}],\n",
       "     'id': '56cdd63a62d2951400fa68da',\n",
       "     'question': \"Quando è stato riaperto l' aeroporto?\"},\n",
       "    {'answers': [{'answer_start': 907, 'text': 'operazioni di soccorso'}],\n",
       "     'id': '56d5185a9d1b871400ae061d',\n",
       "     'question': \"A cosa servivano l' aeroporto per fare tappa?\"}]},\n",
       "  {'context': \"Reporter a Chengdu hanno detto che hanno visto crepe sulle pareti di alcuni edifici residenziali nelle zone del centro, ma nessun edificio è crollato. Molti uffici di Pechino torri ufficio sono stati evacuati, tra cui l' edificio che ospita gli uffici dei media per gli organizzatori delle Olimpiadi estive 2008. Nessuna delle sedi olimpiche sono state danneggiate. Nel frattempo, un treno cargo che trasportava 13 cisterne a benzina deragliato nella contea di Hui, Gansu, e prese fuoco dopo che la ferrovia era stata distorta.\",\n",
       "   'qas': [{'answers': [{'answer_start': 9, 'text': 'a Chengdu'}],\n",
       "     'id': '56cddec762d2951400fa692c',\n",
       "     'question': 'Dove hanno detto i giornalisti che hanno visto crepe sulle pareti di alcuni edifici?'},\n",
       "    {'answers': [{'answer_start': 167, 'text': 'Pechino'}],\n",
       "     'id': '56cddec762d2951400fa692d',\n",
       "     'question': 'Dove sono state evacuate le torri degli uffici?'},\n",
       "    {'answers': [{'answer_start': 47, 'text': 'crepe sulle pareti'}],\n",
       "     'id': '56d519a82593cc1400307a6b',\n",
       "     'question': 'Cosa è stato riportato in Chengdu?'}]},\n",
       "  {'context': \"Tutte le autostrade in Wenchuan, e altri in tutta la provincia, sono stati danneggiati, con conseguente ritardo di arrivo delle truppe di soccorso. Nella contea di Beichuan, l' 80% degli edifici è crollato secondo Xinhua News. Nella città di Shifang, il crollo di due impianti chimici ha portato alla fuoriuscita di circa 80 tonnellate di ammoniaca liquida, con centinaia di persone segnalate sepolte. Nella città di Dujiangyan, a sud-est dell' epicentro, un' intera scuola è crollata con 900 studenti sepolti e meno di 60 sopravvissuti. La Juyuan Middle School, dove sono stati sepolti molti adolescenti, è stata scavata da civili e gru. Dujiangyan è la sede del Dujiangyan Irrigation System, un antico progetto di deviazione dell' acqua che è ancora in uso ed è un patrimonio mondiale dell' UNESCO. La famosa bocca di pesce del progetto è stata incrinata, ma non gravemente danneggiata altrimenti.\",\n",
       "   'qas': [{'answers': [{'answer_start': 0, 'text': 'Tutte le autostrade'}],\n",
       "     'id': '56cddf9e62d2951400fa6934',\n",
       "     'question': 'Quante autostrade che conducono a Wenchuan sono state danneggiate?'},\n",
       "    {'answers': [{'answer_start': 177, 'text': '80%'}],\n",
       "     'id': '56cddf9e62d2951400fa6936',\n",
       "     'question': \"Quale percentuale dell' edificio è crollata a Beichuan?\"},\n",
       "    {'answers': [{'answer_start': 417, 'text': 'Dujiangyan'}],\n",
       "     'id': '56cddf9e62d2951400fa6937',\n",
       "     'question': 'Dove sono crollati due impianti chimici?'},\n",
       "    {'answers': [{'answer_start': 520, 'text': '60'}],\n",
       "     'id': '56cddf9e62d2951400fa6938',\n",
       "     'question': 'Quanti studenti su 900 nella scuola sono sopravvissuti al crollo?'},\n",
       "    {'answers': [{'answer_start': 0, 'text': 'Tutte le autostrade'}],\n",
       "     'id': '56d51b832593cc1400307a75',\n",
       "     'question': 'Quali autostrade di Wenchuan sono state danneggiate?'},\n",
       "    {'answers': [{'answer_start': 177, 'text': '80%'}],\n",
       "     'id': '56d51b832593cc1400307a77',\n",
       "     'question': 'Quanti edifici di Beichuan sono crollati?'},\n",
       "    {'answers': [{'answer_start': 264, 'text': 'due impianti chimici'}],\n",
       "     'id': '56d51b832593cc1400307a78',\n",
       "     'question': 'Quale ammoniaca liquida fuoriuscita a Shifang?'},\n",
       "    {'answers': [{'answer_start': 512, 'text': 'meno di 60'}],\n",
       "     'id': '56d51b832593cc1400307a79',\n",
       "     'question': 'Quanti dei 900 studenti sepolti in un crollo scolastico Dujiangyan sono sopravvissuti?'}]},\n",
       "  {'context': 'Sia la borsa valori di Shanghai che la Shenzhen Stock Exchange hanno sospeso il commercio di società con sede nella Cina sudoccidentale. Il rame è aumentato a causa delle speculazioni che la produzione nel sud-ovest della Cina potrebbe essere influenzata, e i prezzi del petrolio è sceso a fronte di speculazioni che la domanda dalla Cina sarebbe scesa.',\n",
       "   'qas': [{'answers': [{'answer_start': 116, 'text': 'Cina sudoccidentale'}],\n",
       "     'id': '56cddfff62d2951400fa693f',\n",
       "     'question': 'Dove si sono basati gli scambi?'},\n",
       "    {'answers': [{'answer_start': 140, 'text': 'rame'}],\n",
       "     'id': '56cddfff62d2951400fa6940',\n",
       "     'question': 'Quale metallo è aumentato di valore?'},\n",
       "    {'answers': [{'answer_start': 275, 'text': 'olio'}],\n",
       "     'id': '56cddfff62d2951400fa6941',\n",
       "     'question': 'Quale risorsa naturale è diminuita di valore?'},\n",
       "    {'answers': [{'answer_start': 116, 'text': 'Cina sudoccidentale'}],\n",
       "     'id': '56d51d272593cc1400307a80',\n",
       "     'question': 'Dove si trovavano le società che avevano sospeso il loro commercio di azioni?'},\n",
       "    {'answers': [{'answer_start': 140, 'text': 'rame'}],\n",
       "     'id': '56d51d272593cc1400307a81',\n",
       "     'question': 'Quale metallo è aumentato a causa della speculazione?'},\n",
       "    {'answers': [{'answer_start': 39, 'text': 'Shenzhen Stock Exchange'}],\n",
       "     'id': '56d51d272593cc1400307a83',\n",
       "     'question': 'Oltre alla borsa valori di Shanghai, quale altra borsa sospesa negoziazione di titoli azionari sud-ovest della Cina?'}]},\n",
       "  {'context': \"Immediatamente dopo l' evento sismico, le telecomunicazioni mobili e terrestri sono state tagliate verso l' area colpita e quella circostante, con tutte le capacità internet tagliate anche verso l' area del Sichuan. Elementi di telecomunicazioni sono stati ripristinati dal governo pezzo per pezzo nel corso dei prossimi mesi come la situazione nella provincia del Sichuan gradualmente migliorata. Alla fine, una manciata di importanti siti web di notizie e media sono stati resi accessibili online nella regione, anche se con pagine web drammaticamente ridotte.\",\n",
       "   'qas': [{'answers': [{'answer_start': 165, 'text': 'internet'}],\n",
       "     'id': '56cde07662d2951400fa6947',\n",
       "     'question': \"Quali capacità sono state tagliate all' intera area del Sichuan?\"},\n",
       "    {'answers': [{'answer_start': 321, 'text': 'mesi'}],\n",
       "     'id': '56cde07662d2951400fa6948',\n",
       "     'question': 'Quanto tempo ci è voluto per ripristinare queste capacità?'},\n",
       "    {'answers': [{'answer_start': 42, 'text': 'telecomunicazioni'}],\n",
       "     'id': '56d51ea52593cc1400307a89',\n",
       "     'question': 'Cosa è stato tagliato dopo il terremoto?'},\n",
       "    {'answers': [{'answer_start': 436, 'text': 'siti web di notizie e media'}],\n",
       "     'id': '56d51ea52593cc1400307a8c',\n",
       "     'question': \"Quali servizi internet sono diminuiti nell' area?\"}]},\n",
       "  {'context': \"China Mobile ha avuto più di 2.300 stazioni base sospese a causa di interruzione dell' alimentazione o grave congestione del traffico delle telecomunicazioni. Metà delle comunicazioni wireless sono andate perse nella provincia del Sichuan. Il servizio di China Unicom a Wenchuan e in quattro contee vicine è stato interrotto, con più di 700 torri sospese.\",\n",
       "   'qas': [{'answers': [{'answer_start': 29, 'text': '2.300'}],\n",
       "     'id': '56cde11f62d2951400fa694c',\n",
       "     'question': 'Quante stazioni base sono state sospese?'},\n",
       "    {'answers': [{'answer_start': 29, 'text': '2.300'}],\n",
       "     'id': '56d5202a2593cc1400307a93',\n",
       "     'question': 'Quante stazioni base China Mobile hanno smesso di funzionare?'},\n",
       "    {'answers': [{'answer_start': 109, 'text': 'congestione del traffico'}],\n",
       "     'id': '56d5202a2593cc1400307a94',\n",
       "     'question': \"Oltre all' interruzione dell' alimentazione, cosa ha causato la sospensione delle telecomunicazioni?\"},\n",
       "    {'answers': [{'answer_start': 159, 'text': 'Metà'}],\n",
       "     'id': '56d5202a2593cc1400307a95',\n",
       "     'question': 'Quante comunicazioni wireless sono fallite nel Sichuan?'},\n",
       "    {'answers': [{'answer_start': 255, 'text': 'China Unicom'}],\n",
       "     'id': '56d5202a2593cc1400307a96',\n",
       "     'question': 'Chi servizio a Wenchuan è stato interrotto?'},\n",
       "    {'answers': [{'answer_start': 337, 'text': '700'}],\n",
       "     'id': '56d5202a2593cc1400307a97',\n",
       "     'question': 'Quante torri di China Unicom sono state tagliate?'}]},\n",
       "  {'context': \"Inizialmente, i funzionari non erano in grado di contattare la Wolong National Nature Reserve, sede di circa 280 panda giganti. Tuttavia, il Ministero degli Esteri in seguito ha detto che un gruppo di 31 turisti britannici che visitano la riserva Wolong Panda nella zona colpita dal terremoto ha restituito sicuro e indenne a Chengdu. Tuttavia, il benessere di un numero ancora maggiore di panda nelle vicine riserve del panda è rimasto sconosciuto. Cinque guardie di sicurezza della riserva sono state uccise dal terremoto. Sei panda sono fuggiti dopo che i loro recinti sono stati danneggiati. Entro il 20 maggio, due panda presso la riserva sono stati trovati per essere feriti, mentre la ricerca è continuata per altri due panda adulti che è andato perduto dopo il terremoto. Al 28 maggio 2008 mancava ancora un panda. Il panda mancante è stato poi trovato morto sotto le macerie di un recinto. Mao Mao Mao Mao, nove anni, madre di cinque anni nel centro di allevamento, è stata scoperta lunedì, il suo corpo schiacciato da un muro nel suo recinto. I detentori di panda e altri lavoratori hanno messo i suoi resti in una piccola cassa di legno e l' hanno seppellita fuori dal centro di allevamento.\",\n",
       "   'qas': [{'answers': [{'answer_start': 103, 'text': 'circa 280'}],\n",
       "     'id': '56cde1f462d2951400fa695f',\n",
       "     'question': 'Quanti panda vivono nella riserva?'},\n",
       "    {'answers': [{'answer_start': 201, 'text': '31'}],\n",
       "     'id': '56cde1f462d2951400fa6960',\n",
       "     'question': 'Quanti visitatori britannici della Riserva hanno lasciato illeso?'},\n",
       "    {'answers': [{'answer_start': 109, 'text': '2'}],\n",
       "     'id': '56cde1f462d2951400fa6961',\n",
       "     'question': 'Quanti panda sono stati feriti?'},\n",
       "    {'answers': [{'answer_start': 63,\n",
       "       'text': 'Wolong National Nature Reserve'}],\n",
       "     'id': '56d521ee2593cc1400307a9d',\n",
       "     'question': 'Quale centro naturalistico è stato tagliato?'},\n",
       "    {'answers': [{'answer_start': 525, 'text': 'Sei'}],\n",
       "     'id': '56d521ee2593cc1400307a9f',\n",
       "     'question': 'Quanti panda sono fuggiti dalla riserva?'},\n",
       "    {'answers': [{'answer_start': 450, 'text': 'cinque'}],\n",
       "     'id': '56d521ee2593cc1400307aa0',\n",
       "     'question': 'Quante guardie di sicurezza sono morte nella riserva?'},\n",
       "    {'answers': [{'answer_start': 899, 'text': 'Mao Mao Mao'}],\n",
       "     'id': '56d521ee2593cc1400307aa1',\n",
       "     'question': 'Quale famoso panda è stato ucciso sotto le macerie?'}]},\n",
       "  {'context': \"La centrale idroelettrica Zipingpu (semplificata cinese:????; tradizionale cinese:??????) situata a 20 km ad est dell' epicentro è stata danneggiata. Da una recente ispezione è emerso che il danno era meno grave di quanto inizialmente temuto e resta strutturalmente stabile e sicuro. Il serbatoio di Tulong a monte rischia di crollare. Circa 2.000 soldati sono stati assegnati a Zipingpu, cercando di liberare la pressione attraverso lo sfioratore. In totale sono state segnalate 391 dighe, per la maggior parte di piccole dimensioni, danneggiate dal sisma.\",\n",
       "   'qas': [{'answers': [{'answer_start': 342, 'text': '2.000'}],\n",
       "     'id': '56cde29b62d2951400fa696b',\n",
       "     'question': 'Quante truppe sono state assegnate a Zipingpu?'},\n",
       "    {'answers': [{'answer_start': 480, 'text': '391'}],\n",
       "     'id': '56cde29b62d2951400fa696c',\n",
       "     'question': 'Quante dighe sono state danneggiate?'},\n",
       "    {'answers': [{'answer_start': 100, 'text': '20 km'}],\n",
       "     'id': '56d523bd2593cc1400307aa8',\n",
       "     'question': \"Quanto era vicina all' epicentro la centrale elettrica?\"},\n",
       "    {'answers': [{'answer_start': 201, 'text': 'meno grave'}],\n",
       "     'id': '56d523bd2593cc1400307aa9',\n",
       "     'question': 'Che cosa è emerso da una recente ispezione sui danni alla centrale?'},\n",
       "    {'answers': [{'answer_start': 480, 'text': '391'}],\n",
       "     'id': '56d523bd2593cc1400307aab',\n",
       "     'question': 'Qual è il numero totale di dighe danneggiate?'}]},\n",
       "  {'context': \"Secondo i funzionari di Stato cinesi, il terremoto ha causato 69.180 morti conosciute tra cui 68.636 nella provincia del Sichuan; 18.498 persone sono elencate come scomparse, e 374.176 feriti, ma queste cifre possono ulteriormente aumentare con l' arrivo di più rapporti.\",\n",
       "   'qas': [{'answers': [{'answer_start': 94, 'text': '68.636'}],\n",
       "     'id': '56cde34662d2951400fa6973',\n",
       "     'question': 'Quanti decessi sono stati segnalati solo nella provincia del Sichuan?'},\n",
       "    {'answers': [{'answer_start': 130, 'text': '18.498'}],\n",
       "     'id': '56cde34662d2951400fa6974',\n",
       "     'question': \"Quante persone sono state inserite nell' elenco come scomparse?\"},\n",
       "    {'answers': [{'answer_start': 177, 'text': '374.176'}],\n",
       "     'id': '56cde34662d2951400fa6975',\n",
       "     'question': 'Quante persone sono rimaste ferite?'},\n",
       "    {'answers': [{'answer_start': 94, 'text': '68.636'}],\n",
       "     'id': '56d525192593cc1400307ab1',\n",
       "     'question': 'Quanti morti nel Sichuan?'},\n",
       "    {'answers': [{'answer_start': 62, 'text': '69.180'}],\n",
       "     'id': '56d525192593cc1400307ab2',\n",
       "     'question': 'Qual è il conteggio totale dei morti noti causati dal terremoto?'},\n",
       "    {'answers': [{'answer_start': 130, 'text': '18.498'}],\n",
       "     'id': '56d525192593cc1400307ab3',\n",
       "     'question': 'Qual è il numero di persone scomparse?'},\n",
       "    {'answers': [{'answer_start': 177, 'text': '374.176'}],\n",
       "     'id': '56d525192593cc1400307ab4',\n",
       "     'question': 'Quante persone sono rimaste ferite?'}]},\n",
       "  {'context': \"Una squadra di soccorso ha riportato solo 2.300 sopravvissuti della città di Yingxiu nella contea di Wenchuan, su una popolazione totale di circa 9.000 abitanti. Da 3.000 a 5.000 persone sono state uccise nella sola contea di Beichuan, nel Sichuan; nello stesso luogo, 10.000 persone sono rimaste ferite e l' 80% degli edifici sono stati distrutti. L' antica sede della contea di Beichuan è stata abbandonata e conservata come parte del Beichuan Earthquake Museum. Otto scuole sono state abbattute nel Dujiangyan. Un cinquantaseienne è stato ucciso a Dujiangyan durante un tentativo di salvataggio sulla Lingyanshan Ropeway, dove a causa del terremoto 11 turisti taiwanesi erano rimasti intrappolati all' interno di funivie dal 13 maggio. Un ragazzo di 4 anni di nome Zhu Shaowei (cinese tradizionale:???; cinese semplificato:???; pinyin: Zh? Shàowéi) è stato ucciso anche a Mianzhu City quando una casa è crollata su di lui e un altro è stato segnalato perduto.\",\n",
       "   'qas': [{'answers': [{'answer_start': 42, 'text': '2.300'}],\n",
       "     'id': '56ceb9c4aab44d1400b8892b',\n",
       "     'question': 'Quanti sopravvissuti ci sono stati da Yingxiu?'},\n",
       "    {'answers': [{'answer_start': 146, 'text': '9.000'}],\n",
       "     'id': '56ceb9c4aab44d1400b8892d',\n",
       "     'question': 'Quante persone in totale vivevano a Yingxiu?'},\n",
       "    {'answers': [{'answer_start': 162, 'text': 'Da 3.000 a 5.000'}],\n",
       "     'id': '56ceb9c4aab44d1400b8892e',\n",
       "     'question': 'Quante persone sono state uccise nella contea di Beichuan?'},\n",
       "    {'answers': [{'answer_start': 269, 'text': '10.000'}],\n",
       "     'id': '56ceb9c4aab44d1400b8892f',\n",
       "     'question': 'Quante persone sono rimaste ferite nella contea di Beichuan?'},\n",
       "    {'answers': [{'answer_start': 42, 'text': '2.300'}],\n",
       "     'id': '56d5307f2593cc1400307abb',\n",
       "     'question': \"Quanti sopravvissuti c' erano nella città di Yingxiu?\"},\n",
       "    {'answers': [{'answer_start': 140, 'text': 'circa 9.000'}],\n",
       "     'id': '56d5307f2593cc1400307abc',\n",
       "     'question': 'Qual era la popolazione precedente di Yingxiu?'},\n",
       "    {'answers': [{'answer_start': 162, 'text': 'Da 3.000 a 5.000'}],\n",
       "     'id': '56d5307f2593cc1400307abd',\n",
       "     'question': 'Quanti residenti sono stati uccisi nella contea di Beichuan?'},\n",
       "    {'answers': [{'answer_start': 269, 'text': '10.000'}],\n",
       "     'id': '56d5307f2593cc1400307abe',\n",
       "     'question': 'Quanto è stato grande il numero di feriti nella contea di Beichuan?'},\n",
       "    {'answers': [{'answer_start': 465, 'text': 'Otto scuole'}],\n",
       "     'id': '56d5307f2593cc1400307abf',\n",
       "     'question': 'Qual è il numero di scuole crollate in Dujiangyan?'}]},\n",
       "  {'context': 'Gli esperti sottolineano che il terremoto ha colpito un\\' area in gran parte trascurata e non toccata dall\\' ascesa economica della Cina. L\\' assistenza sanitaria è carente nelle zone interne come il Sichuan, il che mette in evidenza il crescente divario tra gli abitanti urbani prosperi e le popolazioni rurali in difficoltà. Vice Ministro della Sanità Gao Qiang ha detto ai giornalisti a Pechino che il \"sistema sanitario pubblico in Cina è insufficiente\".',\n",
       "   'qas': [{'answers': [{'answer_start': 351, 'text': 'Gao Qiang'}],\n",
       "     'id': '56ceba72aab44d1400b88936',\n",
       "     'question': 'Chi era il Vice Ministro della Salute?'},\n",
       "    {'answers': [{'answer_start': 176, 'text': 'zone interne'}],\n",
       "     'id': '56d5324d2593cc1400307ac6',\n",
       "     'question': \"Dove è povera l' assistenza sanitaria in Cina?\"},\n",
       "    {'answers': [{'answer_start': 440, 'text': 'insufficiente'}],\n",
       "     'id': '56d5324d2593cc1400307ac7',\n",
       "     'question': 'Che cosa ha chiamato il Vice Ministro della Salute il sistema sanitario pubblico in Cina?'}]},\n",
       "  {'context': 'In termini di feriti scolastici, migliaia di bambini sono morti a causa di costruzioni scadenti. A Mianyang City, sette scuole sono crollate, seppellendo almeno 1.700 persone. Almeno 7.000 edifici scolastici in tutta la provincia sono crollati. Altri 700 studenti sono stati sepolti in una scuola di Hanwang. Alla scuola elementare Juyuan sono morti almeno 600 studenti e personale. Fino a 1.300 bambini e insegnanti sono morti alla Beichuan Middle School.',\n",
       "   'qas': [{'answers': [{'answer_start': 33, 'text': 'migliaia'}],\n",
       "     'id': '56cebae8aab44d1400b8893d',\n",
       "     'question': 'Quanti bambini sono morti a causa di costruzioni scadenti?'},\n",
       "    {'answers': [{'answer_start': 114, 'text': 'sette'}],\n",
       "     'id': '56cebae8aab44d1400b8893e',\n",
       "     'question': 'Quante scuole sono crollate a Mianyang City?'},\n",
       "    {'answers': [{'answer_start': 161, 'text': '1.700'}],\n",
       "     'id': '56cebae8aab44d1400b8893f',\n",
       "     'question': 'Quante persone sono state sepolte nelle scuole crollate?'},\n",
       "    {'answers': [{'answer_start': 183, 'text': '7.000'}],\n",
       "     'id': '56cebae8aab44d1400b88940',\n",
       "     'question': 'Quanti edifici scolastici sono crollati in provincia?'},\n",
       "    {'answers': [{'answer_start': 163, 'text': '700'}],\n",
       "     'id': '56cebae8aab44d1400b88941',\n",
       "     'question': 'Quanti studenti sono stati sepolti in una scuola di Hanwang?'},\n",
       "    {'answers': [{'answer_start': 114, 'text': 'sette'}],\n",
       "     'id': '56d533a52593cc1400307ad0',\n",
       "     'question': 'Quante scuole sono crollate a Mianyang City?'},\n",
       "    {'answers': [{'answer_start': 183, 'text': '7.000'}],\n",
       "     'id': '56d533a52593cc1400307ad1',\n",
       "     'question': 'Quanti edifici scolastici sono caduti in tutta la provincia?'},\n",
       "    {'answers': [{'answer_start': 357, 'text': '600'}],\n",
       "     'id': '56d533a52593cc1400307ad2',\n",
       "     'question': 'Quanti sono stati uccisi alla scuola elementare di Juyuan?'}]},\n",
       "  {'context': \"I dettagli delle vittime scolastiche sono stati oggetto di indagini non governative dal dicembre 2008 da parte di volontari, tra cui l' artista e architetto Ai Weiwei, che dal marzo 2009 ha costantemente pubblicato aggiornamenti sul suo blog. Il conteggio ufficiale degli studenti uccisi nel terremoto è stato rilasciato solo il 7 maggio 2009, quasi un anno dopo il terremoto. Secondo l' agenzia di stampa statale Xinhua, il terremoto ha ucciso 5.335 studenti e lasciato altri 546 bambini disabili. All' indomani del terremoto, il governo cinese ha dichiarato che i genitori che avevano perso i loro soli figli avrebbero ricevuto cure gratuite da cliniche di fertilità per invertire vasectomie e legature tubarie condotte dalle autorità di pianificazione familiare.\",\n",
       "   'qas': [{'answers': [{'answer_start': 88, 'text': 'dicembre 2008'}],\n",
       "     'id': '56cebb71aab44d1400b88951',\n",
       "     'question': \"Quando si è svolta un' indagine in seguito a incidenti scolastici?\"},\n",
       "    {'answers': [{'answer_start': 329, 'text': '7 maggio 2009'}],\n",
       "     'id': '56cebb71aab44d1400b88952',\n",
       "     'question': 'Quando è stato rilasciato il conteggio ufficiale degli studenti uccisi nel terremoto?'},\n",
       "    {'answers': [{'answer_start': 445, 'text': '5.335'}],\n",
       "     'id': '56cebb71aab44d1400b88953',\n",
       "     'question': 'Quanti studenti sono stati uccisi a Xinhua?'},\n",
       "    {'answers': [{'answer_start': 477, 'text': '546'}],\n",
       "     'id': '56cebb71aab44d1400b88954',\n",
       "     'question': 'Quanti studenti sono stati disabili a Xinhua?'},\n",
       "    {'answers': [{'answer_start': 329, 'text': '7 maggio 2009'}],\n",
       "     'id': '56d5357b2593cc1400307ad9',\n",
       "     'question': 'Qual è stata la data in cui è stato rilasciato il numero ufficiale degli studenti uccisi nel terremoto?'},\n",
       "    {'answers': [{'answer_start': 157, 'text': 'Ai Weiwei'}],\n",
       "     'id': '56d5357b2593cc1400307ada',\n",
       "     'question': 'Chi ha tenuto un blog sui decessi scolastici?'},\n",
       "    {'answers': [{'answer_start': 445, 'text': '5.335'}],\n",
       "     'id': '56d5357b2593cc1400307adb',\n",
       "     'question': 'Qual è il numero totale di bambini che hanno perso la scuola?'},\n",
       "    {'answers': [{'answer_start': 477, 'text': '546'}],\n",
       "     'id': '56d5357b2593cc1400307adc',\n",
       "     'question': 'Quanti bambini sono disabili?'},\n",
       "    {'answers': [{'answer_start': 647, 'text': 'cliniche di fertilità'}],\n",
       "     'id': '56d5357b2593cc1400307add',\n",
       "     'question': 'Dove ha deciso il governo cinese che i genitori che avevano perso i figli potessero farsi curare gratuitamente?'}]},\n",
       "  {'context': \"Il terremoto ha lasciato almeno 5 milioni di persone senza alloggio, anche se il numero potrebbe raggiungere gli 11 milioni. Milioni di animali da allevamento e una notevole quantità di agricoltura sono stati distrutti, tra cui 12,5 milioni di animali, principalmente uccelli. Nella provincia del Sichuan sono morti un milione di suini su un totale di 60 milioni. Catastrophe modeling firm AIR Worldwide ha riportato stime ufficiali delle perdite degli assicuratori pari a 1 miliardo di dollari USA dal terremoto; i danni totali stimati superano i 20 miliardi di dollari USA. Valorizza Chengdu, all' epoca con una popolazione urbana di 4,5 milioni di persone, a circa 115 miliardi di dollari, con solo una piccola parte coperta da assicurazioni.\",\n",
       "   'qas': [{'answers': [{'answer_start': 32, 'text': '5 milioni'}],\n",
       "     'id': '56cebbdeaab44d1400b88959',\n",
       "     'question': 'Quante persone sono rimaste senza alloggio?'},\n",
       "    {'answers': [{'answer_start': 113, 'text': '11 milioni'}],\n",
       "     'id': '56cebbdeaab44d1400b8895a',\n",
       "     'question': 'Quante persone potrebbero essere potenzialmente senza alloggio?'},\n",
       "    {'answers': [{'answer_start': 228, 'text': '12,5 milioni'}],\n",
       "     'id': '56cebbdeaab44d1400b8895b',\n",
       "     'question': 'Quanti animali sono stati uccisi?'},\n",
       "    {'answers': [{'answer_start': 113, 'text': '11 milioni'}],\n",
       "     'id': '56d5372f2593cc1400307ae4',\n",
       "     'question': 'Quante persone potrebbero effettivamente essere senzatetto?'},\n",
       "    {'answers': [{'answer_start': 228, 'text': '12,5 milioni di animali'}],\n",
       "     'id': '56d5372f2593cc1400307ae5',\n",
       "     'question': 'Quanto bestiame è andato perduto?'},\n",
       "    {'answers': [{'answer_start': 316, 'text': 'un milione'}],\n",
       "     'id': '56d5372f2593cc1400307ae6',\n",
       "     'question': 'Quanti maiali sono morti a causa del terremoto nel Sichuan?'}]},\n",
       "  {'context': 'Reginald DesRoches, professore di ingegneria civile e ambientale presso la Georgia Tech, ha sottolineato che i danni massicci di proprietà e case nella zona sismica sono dovuti al fatto che la Cina ha creato un adeguato codice di progettazione sismica solo dopo il devastante terremoto di Tangshan del 1976. DesRoches ha detto:\"Se gli edifici fossero più vecchi e costruiti prima di quel terremoto del 1976, è probabile che non siano stati costruiti per un\\' adeguata forza sismica\".',\n",
       "   'qas': [{'answers': [{'answer_start': 0, 'text': 'Reginald DesRoches'}],\n",
       "     'id': '56cebcb4aab44d1400b88963',\n",
       "     'question': 'Chi era professore di ingegneria civile e ambientale alla Georgia Tech?'},\n",
       "    {'answers': [{'answer_start': 20,\n",
       "       'text': 'professore di ingegneria civile e ambientale'}],\n",
       "     'id': '56d538bc2593cc1400307aed',\n",
       "     'question': 'Qual è la professione di Reginald DesRoches?'},\n",
       "    {'answers': [{'answer_start': 302, 'text': '1976'}],\n",
       "     'id': '56d538bc2593cc1400307aee',\n",
       "     'question': \"Quando la Cina ha creato un codice di progettazione sismica per l' edilizia?\"},\n",
       "    {'answers': [{'answer_start': 276, 'text': 'terremoto di Tangshan'}],\n",
       "     'id': '56d538bc2593cc1400307aef',\n",
       "     'question': \"Che catastrofe li ha spinti a fare un codice di progettazione dell' edificio /.?\"}]},\n",
       "  {'context': \"Nei giorni successivi al disastro, un team internazionale di ingegneri è stato inviato nella regione per effettuare un' indagine preliminare dettagliata sugli edifici danneggiati. I loro risultati mostrano una varietà di ragioni per cui molte costruzioni non sono riuscite a resistere al terremoto.\",\n",
       "   'qas': []},\n",
       "  {'context': 'Le notizie di cronaca indicano che i villaggi rurali più poveri sono stati colpiti più duramente. Swaminathan Krishnan, assistente professore di ingegneria civile e geofisica presso il California Institute of Technology ha dichiarato:\"Il terremoto si è verificato nella parte rurale della Cina. Probabilmente, molti degli edifici sono stati appena costruiti; non sono stati progettati, per così dire. Swaminathan Krishnan ha aggiunto:\"In Cina ci sono norme edilizie molto forti, che si occupano di terremoto e problemi di progettazione sismica.',\n",
       "   'qas': [{'answers': [{'answer_start': 98, 'text': 'Swaminathan Krishnan'}],\n",
       "     'id': '56cebd8aaab44d1400b88978',\n",
       "     'question': 'Chi era professore assistente di ingegneria civile e geofisica presso il California Institute of Technology?'},\n",
       "    {'answers': [{'answer_start': 270, 'text': 'parte rurale'}],\n",
       "     'id': '56d53bf82593cc1400307afd',\n",
       "     'question': 'In quale parte della Cina si è verificato il terremoto?'}]},\n",
       "  {'context': 'Anche con le cinque città più grandi del Sichuan che subiscono solo danni di modesta entità a causa del terremoto, alcune stime della perdita economica superano i 75 miliardi di dollari, rendendo il terremoto uno dei disastri naturali più costosi della storia cinese.',\n",
       "   'qas': [{'answers': [{'answer_start': 163,\n",
       "       'text': '75 miliardi di dollari'}],\n",
       "     'id': '56cebdd0aab44d1400b8897f',\n",
       "     'question': 'Qual è la stima della perdita economica del terremoto?'},\n",
       "    {'answers': [{'answer_start': 163, 'text': '75 miliardi di dollari'}],\n",
       "     'id': '56d53d9a2593cc1400307b08',\n",
       "     'question': 'Qual è la stima delle perdite economiche?'},\n",
       "    {'answers': [{'answer_start': 253, 'text': 'storia cinese'}],\n",
       "     'id': '56d53d9a2593cc1400307b09',\n",
       "     'question': 'Chi è questo uno dei disastri più costosi della storia di?'},\n",
       "    {'answers': [{'answer_start': 13, 'text': 'cinque città più grandi'}],\n",
       "     'id': '56d53d9a2593cc1400307b0a',\n",
       "     'question': 'Quali città del Sichuan hanno subito danni minori?'}]},\n",
       "  {'context': \"Forti scosse di assestamento hanno continuato a colpire anche mesi dopo il terremoto principale. Il 25 maggio, una scossa di assestamento di 6.0 Mw (6.4 Ms secondo CEA) ha colpito a nord-est dell' epicentro del terremoto originale, nella contea di Qingchuan, Sichuan, causando otto morti, 1000 feriti e distruggendo migliaia di edifici. Il 27 maggio, due scosse di assestamento, una 5.2 Mw nella contea di Qingchuan e una 5.7 Mw nella contea di Ningqiang, Shaanxi, hanno portato al crollo di oltre 420.000 case e feriti 63 persone. La stessa area ha sofferto due scosse di assestamento più di 5,6 e 6,0 Ms (5,8 e 5,5 Mw, rispettivamente, secondo USGS) il 23 luglio, con conseguente 1 decesso, 6 feriti gravi, crollo di centinaia di case e danni chilometri di autostrade. Pingwu County e Beichuan County, Sichuan, anche a nord-est di Wenchuan e vicino all' epicentro di un terremoto della sig. ra 7.2 nel 1976, subì un terremoto di 6.1 Ms aftershock (5.7 Mw secondo l' USGS) il 1 agosto 1; ha causato 2 morti, 345 feriti, crollo di 707 case, danni a oltre 1.000 case, e bloccato 25 chilometri (16 mi) di strade di campagna.\",\n",
       "   'qas': [{'answers': [{'answer_start': 141, 'text': '6.0 Mw'}],\n",
       "     'id': '56d540072593cc1400307b0f',\n",
       "     'question': 'Quanto è stata forte la scossa di assestamento del 25 maggio nella contea di Qingchuan?'},\n",
       "    {'answers': [{'answer_start': 289, 'text': '1000'}],\n",
       "     'id': '56d540072593cc1400307b10',\n",
       "     'question': 'Quante persone sono rimaste ferite durante la scossa di assestamento del 25 maggio?'},\n",
       "    {'answers': [{'answer_start': 520, 'text': '63'}],\n",
       "     'id': '56d540072593cc1400307b12',\n",
       "     'question': 'Durante il 27 maggio scosse di assestamento, quante persone sono rimaste ferite?'},\n",
       "    {'answers': [{'answer_start': 248, 'text': 'Qingchuan, Sichuan'}],\n",
       "     'id': '56d540072593cc1400307b13',\n",
       "     'question': \"Dov' è stata la scossa di assestamento del 5 agosto che ha causato ampie frane di collina?\"}]},\n",
       "  {'context': 'Vice governatore esecutivo Wei Hong Wei ha confermato il 21 novembre 2008 che più di 90.000 persone in totale erano morti o dispersi nel terremoto. Ha dichiarato che 200.000 case sono state ricostruite e 685.000 sono in fase di ricostruzione, ma 1,94 milioni di famiglie sono ancora prive di ricovero permanente. Sono state ricostruite 1.300 scuole, con il trasferimento iniziale di 25 città, tra cui Beichuan e Wenchuan, due delle aree più devastate. Il governo ha speso 441 miliardi di dollari per gli sforzi di soccorso e ricostruzione.',\n",
       "   'qas': [{'answers': [{'answer_start': 27, 'text': 'Wei Hong'}],\n",
       "     'id': '56cebef6aab44d1400b88997',\n",
       "     'question': 'Chi era il vice governatore esecutivo?'},\n",
       "    {'answers': [{'answer_start': 166, 'text': '200.000'}],\n",
       "     'id': '56cebef6aab44d1400b88999',\n",
       "     'question': 'Quante case sono state ricostruite?'},\n",
       "    {'answers': [{'answer_start': 336, 'text': '1.300'}],\n",
       "     'id': '56cebef6aab44d1400b8899b',\n",
       "     'question': 'Quante scuole sono state ricostruite?'},\n",
       "    {'answers': [{'answer_start': 27, 'text': 'Wei Hong'}],\n",
       "     'id': '56d548552593cc1400307b19',\n",
       "     'question': 'Chi ha parlato dei morti e dei dispersi il 21 novembre 2008?'},\n",
       "    {'answers': [{'answer_start': 85, 'text': '90.000'}],\n",
       "     'id': '56d548552593cc1400307b1a',\n",
       "     'question': 'Quante persone hanno detto Wei Hong che erano morte o mancanti?'},\n",
       "    {'answers': [{'answer_start': 166, 'text': '200.000'}],\n",
       "     'id': '56d548552593cc1400307b1b',\n",
       "     'question': 'Quante case sono state ricostruite?'},\n",
       "    {'answers': [{'answer_start': 204, 'text': '685.000'}],\n",
       "     'id': '56d548552593cc1400307b1c',\n",
       "     'question': 'Quante case erano ancora in costruzione?'}]},\n",
       "  {'context': \"Il segretario generale e presidente Hu Jintao ha annunciato che la risposta alle catastrofi sarà rapida. A soli 90 minuti dal terremoto, il premier Wen Jiabao, che ha una formazione accademica in geomeccanica, ha volato nella zona del terremoto per sorvegliare i lavori di salvataggio. Poco dopo, il Ministero della Salute ha detto che aveva inviato dieci squadre mediche di emergenza a Wenchuan County. Lo stesso giorno, il comando militare della regione militare di Chengdu ha inviato 50.000 soldati e polizia armata per aiutare con il lavoro di soccorso in caso di catastrofe nella contea di Wenchuan. Tuttavia, a causa del terreno accidentato e della vicinanza dell' epicentro del sisma, i soldati hanno avuto molte difficoltà ad ottenere aiuto nelle regioni rurali della provincia.\",\n",
       "   'qas': [{'answers': [{'answer_start': 137,\n",
       "       'text': 'il premier Wen Jiabao'}],\n",
       "     'id': '56cebf6aaab44d1400b889a1',\n",
       "     'question': \"Chi ha volato nella zona sismica 90 minuti dopo l' urto?\"},\n",
       "    {'answers': [{'answer_start': 196, 'text': 'geomeccanica'}],\n",
       "     'id': '56cebf6aaab44d1400b889a2',\n",
       "     'question': \"In cosa c' era il background di Premier Wen Jiabao?\"},\n",
       "    {'answers': [{'answer_start': 261, 'text': 'i lavori di salvataggio'}],\n",
       "     'id': '56cebf6aaab44d1400b889a3',\n",
       "     'question': 'Che cosa ha supervisionato Jiabao nella regione?'},\n",
       "    {'answers': [{'answer_start': 487, 'text': '50.000'}],\n",
       "     'id': '56cebf6aaab44d1400b889a4',\n",
       "     'question': 'Quante truppe sono state inviate dai militari Chengdu?'},\n",
       "    {'answers': [{'answer_start': 350, 'text': 'dieci'}],\n",
       "     'id': '56d54a582593cc1400307b25',\n",
       "     'question': 'Quante squadre mediche sono state inviate nella contea di Wenchuan?'},\n",
       "    {'answers': [{'answer_start': 487, 'text': '50.000'}],\n",
       "     'id': '56d54a582593cc1400307b26',\n",
       "     'question': 'Quante truppe sono state inviate nella zona per operazioni di soccorso?'}]},\n",
       "  {'context': 'La Commissione nazionale di soccorso in caso di catastrofe ha avviato un \"piano di emergenza di II livello\", che copre la categoria più grave di catastrofi naturali. Il piano è salito al livello I alle 22:15 CST, 12 maggio.',\n",
       "   'qas': [{'answers': [{'answer_start': 197,\n",
       "       'text': 'alle 22:15 CST, 12 maggio'}],\n",
       "     'id': '56cebfcaaab44d1400b889ab',\n",
       "     'question': 'Quando è salito il piano al livello I?'},\n",
       "    {'answers': [{'answer_start': 132, 'text': 'più grave'}],\n",
       "     'id': '56d54bc82593cc1400307b2e',\n",
       "     'question': \"Quale classe di catastrofi è un' emergenza di livello II?\"},\n",
       "    {'answers': [{'answer_start': 3,\n",
       "       'text': 'Commissione nazionale di soccorso in caso di catastrofe'}],\n",
       "     'id': '56d54bc82593cc1400307b30',\n",
       "     'question': 'Quale dipartimento ha avviato il piano di emergenza?'}]},\n",
       "  {'context': \"Un' équipe di soccorso in caso di terremoto di 184 persone (composta da 12 persone dell' Ufficio sismologico di Stato, 150 del Comando dell' Area militare di Pechino e 22 dell' Ospedale Generale della Polizia Armata) ha lasciato Pechino dall' aeroporto di Nanyuan alla fine del 12 maggio in due aerei da trasporto militare per raggiungere la contea di Wenchuan.\",\n",
       "   'qas': [{'answers': [{'answer_start': 47, 'text': '184'}],\n",
       "     'id': '56cec033aab44d1400b889af',\n",
       "     'question': 'Quante persone erano nel team di soccorso in caso di terremoto?'},\n",
       "    {'answers': [{'answer_start': 72, 'text': '12'}],\n",
       "     'id': '56cec033aab44d1400b889b0',\n",
       "     'question': \"Quante squadre di soccorso provenivano dall' Ufficio sismologico di Stato?\"},\n",
       "    {'answers': [{'answer_start': 119, 'text': '150'}],\n",
       "     'id': '56cec033aab44d1400b889b1',\n",
       "     'question': 'Quanti membri della squadra erano militari?'},\n",
       "    {'answers': [{'answer_start': 168, 'text': '22'}],\n",
       "     'id': '56cec033aab44d1400b889b2',\n",
       "     'question': 'Quanti membri della squadra provenivano dalla polizia?'},\n",
       "    {'answers': [{'answer_start': 47, 'text': '184'}],\n",
       "     'id': '56d5d41b1c85041400946e0d',\n",
       "     'question': 'Quante persone costituivano la squadra di soccorso?'},\n",
       "    {'answers': [{'answer_start': 119, 'text': '150'}],\n",
       "     'id': '56d5d41b1c85041400946e0e',\n",
       "     'question': \"Quanti soldati provenivano dall' esercito di Pechino?\"},\n",
       "    {'answers': [{'answer_start': 177,\n",
       "       'text': 'Ospedale Generale della Polizia Armata'}],\n",
       "     'id': '56d5d41b1c85041400946e0f',\n",
       "     'question': 'Da dove provengono 22 della squadra di soccorso?'}]},\n",
       "  {'context': 'Nel China Digital Times un articolo riporta un\\' analisi approfondita da parte di un presunto ingegnere edile cinese conosciuto online come \"Book Blade\" (??), che ha dichiarato: un\\' analisi approfondita da parte di un presunto ingegnere edile cinese.',\n",
       "   'qas': [{'answers': [{'answer_start': 140, 'text': 'Book Blade'}],\n",
       "     'id': '56cec11faab44d1400b889c8',\n",
       "     'question': \"Dov' è stato riportato un articolo sullo scandalo?\"},\n",
       "    {'answers': [{'answer_start': 4, 'text': 'China Digital Times'}],\n",
       "     'id': '56d64d231c85041400947089',\n",
       "     'question': 'Qual è stato il nome della persona che ha pubblicato un rapporto nel China Digital Times?'}]},\n",
       "  {'context': 'In occasione della Festa dei bambini, il 1° giugno 2008, molti genitori si sono recati sulle macerie delle scuole per piangere i loro figli. I bambini sopravvissuti, che vivevano per lo più in centri di soccorso, hanno compiuto cerimonie che hanno segnato il giorno speciale, ma anche riconosciuto il terremoto.',\n",
       "   'qas': [{'answers': [{'answer_start': 19, 'text': 'Festa dei bambini'}],\n",
       "     'id': '56cec174aab44d1400b889cb',\n",
       "     'question': 'Che cosa è stato chiamato 1 giugno 2008?'}]},\n",
       "  {'context': \"Le imprese statali centrali hanno donato complessivamente più di 48,6 milioni di dollari. China National Petroleum Corp e Sinopec ha donato 10 milioni di yuan ciascuno per l' area del disastro.\",\n",
       "   'qas': [{'answers': [{'answer_start': 140, 'text': '10 milioni di yuan'}],\n",
       "     'id': '56cec1ffaab44d1400b889de',\n",
       "     'question': 'Quanto ha donato China National Petroleum Corp e Sinopec?'},\n",
       "    {'answers': [{'answer_start': 65, 'text': '48,6 milioni'}],\n",
       "     'id': '56d6647b1c850414009470ed',\n",
       "     'question': 'Quanto hanno donato le imprese statali centrali?'},\n",
       "    {'answers': [{'answer_start': 140, 'text': '10 milioni di yuan ciascuno'}],\n",
       "     'id': '56d6647b1c850414009470ee',\n",
       "     'question': 'Quanto ha donato China National Petroleum e Sinopec?'}]},\n",
       "  {'context': \"Il 16 maggio la Cina ha dichiarato di aver ricevuto anche 457 milioni di dollari in donazioni di denaro e beni per gli sforzi di salvataggio finora compiuti, compresi 83 milioni di dollari provenienti da 19 paesi e quattro organizzazioni internazionali. L' Arabia Saudita è stata il principale donatore di aiuti alla Cina, fornendo quasi 40.000.000 di euro in assistenza finanziaria e altri 8.000.000 di euro di materiale di soccorso.\",\n",
       "   'qas': [{'answers': [{'answer_start': 58,\n",
       "       'text': '457 milioni di dollari'}],\n",
       "     'id': '56cec2a1aab44d1400b889e1',\n",
       "     'question': 'Quanto ha ricevuto la Cina in denaro e beni donati?'},\n",
       "    {'answers': [{'answer_start': 204, 'text': '19 paesi'}],\n",
       "     'id': '56cec2a1aab44d1400b889e2',\n",
       "     'question': 'Quanti paesi hanno donato?'},\n",
       "    {'answers': [{'answer_start': 215, 'text': 'quattro'}],\n",
       "     'id': '56cec2a1aab44d1400b889e3',\n",
       "     'question': 'Quante organizzazioni internazionali hanno donato?'},\n",
       "    {'answers': [{'answer_start': 257, 'text': 'Arabia Saudita'}],\n",
       "     'id': '56cec2a1aab44d1400b889e4',\n",
       "     'question': 'Quale paese è stato il maggiore donatore di aiuti alla Cina?'},\n",
       "    {'answers': [{'answer_start': 167, 'text': '83 milioni'}],\n",
       "     'id': '56d6696d1c850414009470fb',\n",
       "     'question': 'Quanto denaro è stato donato da fonti straniere?'},\n",
       "    {'answers': [{'answer_start': 257, 'text': 'Arabia Saudita'}],\n",
       "     'id': '56d6696d1c850414009470fc',\n",
       "     'question': 'Quale paese è stato il maggiore donatore di aiuti alla Cina?'},\n",
       "    {'answers': [{'answer_start': 215, 'text': 'quattro'}],\n",
       "     'id': '56d6696d1c850414009470fe',\n",
       "     'question': 'Quante organizzazioni internazionali hanno fatto donazioni?'}]},\n",
       "  {'context': 'Nel 2008, il Consiglio di Stato ha stabilito un piano di sostegno alla controparte????????? Il piano è quello di organizzare 19 province orientali e centrali e municipalitie per aiutare 18 contee, su \"una provincia a una contea interessata\" base. Il piano ha una durata di 3 anni, e costa non meno dell\\' uno per cento del bilancio della provincia o del comune. un piano di sostegno di contropartita.',\n",
       "   'qas': [{'answers': [{'answer_start': 273, 'text': '3 anni'}],\n",
       "     'id': '56d66f3e1c85041400947117',\n",
       "     'question': 'Quanto dura il piano?'},\n",
       "    {'answers': [{'answer_start': 304, 'text': 'uno per cento'}],\n",
       "     'id': '56d66f3e1c85041400947118',\n",
       "     'question': 'Qual è il costo per il bilancio della provincia?'}]},\n",
       "  {'context': 'Un articolo in Science suggerisce che la costruzione e il riempimento della diga di Zipingpu potrebbe aver innescato il terremoto. L\\' ingegnere capo del Sichuan Geology and Mineral Bureau ha detto che lo spostamento improvviso di una grande quantità d\\' acqua nella regione avrebbe potuto allentare la tensione tra i due lati del guasto, permettendo loro di allontanarsi, e avrebbe potuto aumentare la pressione diretta su di esso, causando una violenta rottura. L\\' effetto è stato \"25 volte più\" dello stress naturale del movimento tettonico di un anno. Il governo aveva ignorato gli avvertimenti relativi a tanti progetti di dighe su larga scala in un\\' area sismicamente attiva. Ai ricercatori è stato negato l\\' accesso ai dati sismologici e geologici per esaminare ulteriormente la causa del terremoto.',\n",
       "   'qas': [{'answers': [{'answer_start': 554, 'text': 'Il governo'}],\n",
       "     'id': '56d677f31c85041400947145',\n",
       "     'question': 'Chi ha ignorato gli avvertimenti sulle dighe nella zona?'},\n",
       "    {'answers': [{'answer_start': 713,\n",
       "       'text': 'accesso ai dati sismologici e geologici'}],\n",
       "     'id': '56d677f31c85041400947147',\n",
       "     'question': 'Che cosa sono stati negati ai ricercatori?'}]},\n",
       "  {'context': 'Il terremoto ha inoltre offerto ai ricercatori l\\' opportunità di aggiornare i dati per modellare le previsioni future. Utilizzando i dati dell\\' osservatorio geomagnetico Intermagnet Lanzhou, i geologi Lazo Pekevski della Ss. Cyril e Methodius University di Skopje in Macedonia e Strachimir Mavrodiev dell\\' Accademia bulgara delle Scienze hanno cercato di stabilire un \"metodo di previsione temporale\" attraverso la raccolta di statistiche sul geomagnetismo con potenziale gravitazionale delle maree. Utilizzando questo metodo, si diceva che avessero previsto il tempo del terremoto del Sichuan del 2008 con una precisione di ± 1 giorno. Lo stesso studio, tuttavia, riconosce la limitazione dei modelli di previsione dei terremoti e non menziona che la localizzazione del sisma potrebbe essere accuratamente prevista.',\n",
       "   'qas': [{'answers': [{'answer_start': 559,\n",
       "       'text': 'il tempo del terremoto del Sichuan del 2008'}],\n",
       "     'id': '56cec484aab44d1400b88a09',\n",
       "     'question': 'Cosa prevedevano i professori?'},\n",
       "    {'answers': [{'answer_start': 427, 'text': 'statistiche'}],\n",
       "     'id': '56d675ed1c8504140094713d',\n",
       "     'question': 'Cosa hanno raccolto per usare questo metodo?'}]},\n",
       "  {'context': 'In una conferenza stampa tenuta dall\\' Ufficio informazioni del Consiglio di Stato il giorno dopo il terremoto, il geologo Zhang Xiaodong, vice direttore del CEA Seismic Monitoring Network Center, ha ribadito che la previsione del terremoto era un problema globale, nel senso che non esistono metodi comprovati, e che nessuna notifica di previsione è stata ricevuta prima del terremoto. Il sismologo Gary Gibson dell\\' Università di Monash University in Australia ha detto a Deutsche Presse-Agentur che anche lui non vedeva nulla che potesse essere considerato come aver \"previsto\" l\\' accadimento del terremoto.',\n",
       "   'qas': [{'answers': [{'answer_start': 279,\n",
       "       'text': 'non esistono metodi comprovati'}],\n",
       "     'id': '56d674591c85041400947133',\n",
       "     'question': 'Che cosa credono molti geologi nella previsione dei terremoti?'},\n",
       "    {'answers': [{'answer_start': 317,\n",
       "       'text': 'nessuna notifica di previsione'}],\n",
       "     'id': '56d674591c85041400947135',\n",
       "     'question': 'Cosa è stato ricevuto prima del terremoto?'}]},\n",
       "  {'context': \"Nel 2002, il geologo cinese Chen Xuezhong ha pubblicato uno studio di analisi del rischio sismico in cui è giunto alla conclusione che a partire dal 2003, l' attenzione dovrebbe essere prestata alla possibilità di un terremoto con una magnitudo superiore a 7,0 che si verifica nella regione del Sichuan. Ha basato il suo studio sulla correlazione statistica. Che il Sichuan è un' area sismicamente attiva è stata discussa per anni prima del terremoto, anche se pochi studi indicano una data e un' ora specifiche.\",\n",
       "   'qas': [{'answers': [{'answer_start': 0, 'text': 'Nel 2002'}],\n",
       "     'id': '56cec548aab44d1400b88a13',\n",
       "     'question': \"Quando è stata pubblicata l' analisi del rischio sismico?\"},\n",
       "    {'answers': [{'answer_start': 28, 'text': 'Chen Xuezhong'}],\n",
       "     'id': '56cec548aab44d1400b88a14',\n",
       "     'question': \"Chi ha pubblicato l' analisi del rischio sismico?\"},\n",
       "    {'answers': [{'answer_start': 28, 'text': 'Chen Xuezhong'}],\n",
       "     'id': '56d672d21c85041400947129',\n",
       "     'question': 'Chi ha pubblicato uno studio di analisi del rischio sismico?'},\n",
       "    {'answers': [{'answer_start': 4, 'text': '2002'}],\n",
       "     'id': '56d672d21c8504140094712a',\n",
       "     'question': 'In quale anno Chen Xuezhong ha pubblicato uno studio sul terremoto?'}]},\n",
       "  {'context': 'Il terremoto è stato il peggiore a colpire l\\' area del Sichuan in oltre 30 anni. A seguito del terremoto, esperti e il pubblico in generale hanno chiesto informazioni per sapere se il terremoto avrebbe potuto essere previsto in anticipo e se lo studio delle statistiche relative al terremoto avrebbe potuto portare a una migliore previsione dei terremoti in futuro. La predizione del terremoto non è ancora una scienza consolidata; non c\\' era consenso all\\' interno della comunità scientifica sul fatto che la \"previsione\" del terremoto sia possibile.',\n",
       "   'qas': [{'answers': [{'answer_start': 66, 'text': 'oltre 30 anni'}],\n",
       "     'id': '56cec5d1aab44d1400b88a23',\n",
       "     'question': 'Da quanto tempo si è verificato un terremoto di simile entità?'},\n",
       "    {'answers': [{'answer_start': 72, 'text': '30 anni'}],\n",
       "     'id': '56d6713f1c8504140094711f',\n",
       "     'question': \"Da quanto tempo da quando l' area del Sichuan ha subito un grave terremoto?\"},\n",
       "    {'answers': [{'answer_start': 258, 'text': 'statistiche'}],\n",
       "     'id': '56d6713f1c85041400947122',\n",
       "     'question': 'La gente voleva sapere se lo studio di quale matematica poteva produrre previsioni migliori?'}]},\n",
       "  {'context': 'Molte squadre di soccorso, tra cui quella del Taipei Fire Department di Taiwan, sono state segnalate pronte ad unirsi allo sforzo di salvataggio nel Sichuan già mercoledì. Tuttavia, la Croce Rossa Società della Cina ha detto che (il 13 maggio)\"è stato scomodo attualmente a causa del problema del traffico alle zone più colpite più vicino all\\' epicentro\". La Società della Croce Rossa Cinese ha anche dichiarato che le zone disastrate hanno bisogno di tende, forniture mediche, acqua potabile e cibo; tuttavia ha raccomandato di donare denaro invece di altri oggetti, in quanto non era stato possibile raggiungere strade completamente danneggiate o luoghi che sono stati bloccati da frane. Le frane minacciavano continuamente il progresso di un gruppo di ricerca e salvataggio di 80 uomini, ognuno dei quali trasportava circa 40 kg di materiale di soccorso, provenienti da una brigata motorizzata di fanteria sotto il comandante Yang Wenyao, mentre cercavano di raggiungere il villaggio etnicamente tibetano di Sier ad un\\' altezza di 4000 m sul livello del mare nella contea di Pingwu.',\n",
       "   'qas': [{'answers': [{'answer_start': 683, 'text': 'frane'}],\n",
       "     'id': '56d5db271c85041400946e42',\n",
       "     'question': 'Quale problema ha continuato ad impedire alle squadre di soccorso di raggiungere le zone colpite?'}]},\n",
       "  {'context': \"Le piogge e gli smottamenti persistenti nella contea di Wenchuan e nella zona vicina hanno gravemente influenzato gli sforzi di salvataggio. All' inizio delle operazioni di soccorso, il 12 maggio, sono stati impiegati 20 elicotteri per la fornitura di cibo, acqua e aiuti d' emergenza, nonché per l' evacuazione dei feriti e la ricognizione delle aree colpite dal terremoto. A partire dalle 17:37 CST del 13 maggio, un totale di oltre 15.600 soldati e riservisti della milizia della regione militare di Chengdu si erano uniti alla forza di soccorso nelle zone gravemente colpite. Un comandante ha riferito da Yingxiu Town, Wenchuan, che sono stati trovati circa 3.000 sopravvissuti, mentre lo stato degli altri abitanti (circa 9.000) è rimasto poco chiaro. I 1.300 soccorritori raggiunsero l' epicentro e 300 truppe pioniere raggiunsero la sede di Wenchuan a circa 23:30 CST. Entro le 12:17 CST, 14 maggio 2008, la comunicazione nella sede di Wenchuan è stata in parte ripresa. Il pomeriggio del 14 maggio, 15 operazioni speciali 15 truppe, insieme con le forniture di soccorso e attrezzature di comunicazione, paracadutati in inaccessibile Mao County, a nord-est di Wenchuan.\",\n",
       "   'qas': [{'answers': [{'answer_start': 218, 'text': '20'}],\n",
       "     'id': '56cec79caab44d1400b88a34',\n",
       "     'question': 'Quanti elicotteri sono stati impiegati?'},\n",
       "    {'answers': [{'answer_start': 435, 'text': '15.600'}],\n",
       "     'id': '56cec79caab44d1400b88a35',\n",
       "     'question': 'Quanti riservisti delle milizie si sono uniti agli sforzi di salvataggio?'},\n",
       "    {'answers': [{'answer_start': 656, 'text': 'circa 3.000'}],\n",
       "     'id': '56cec79caab44d1400b88a36',\n",
       "     'question': 'Quanti sopravvissuti sono stati trovati?'},\n",
       "    {'answers': [{'answer_start': 435, 'text': '15'}],\n",
       "     'id': '56cec79caab44d1400b88a37',\n",
       "     'question': 'Quante truppe paracadute nella contea di Mao?'},\n",
       "    {'answers': [{'answer_start': 218, 'text': '20'}],\n",
       "     'id': '56d5ecf21c85041400946e5b',\n",
       "     'question': 'Quanti elicotteri sono stati inviati per fornire aiuti alle zone colpite?'},\n",
       "    {'answers': [{'answer_start': 435, 'text': '15.600'}],\n",
       "     'id': '56d5ecf21c85041400946e5c',\n",
       "     'question': 'Entro il 13 maggio, quante truppe erano state aggiunte agli sforzi di salvataggio?'},\n",
       "    {'answers': [{'answer_start': 656, 'text': 'circa 3.000'}],\n",
       "     'id': '56d5ecf21c85041400946e5d',\n",
       "     'question': 'Come sono state segnalate le persone sopravvissute nella città di Yingxiu?'},\n",
       "    {'answers': [{'answer_start': 721, 'text': 'circa 9.000'}],\n",
       "     'id': '56d5ecf21c85041400946e5e',\n",
       "     'question': 'Quante persone a Yingxiu erano ancora sconosciute?'}]},\n",
       "  {'context': \"Il 15 maggio, il premier Wen Jiabao ha ordinato lo spiegamento di altri 90 elicotteri, di cui 60 forniti dal PLAAF e 30 forniti dall' industria dell' aviazione civile, portando così il numero totale di aeromobili impiegati nelle operazioni di soccorso dall' aviazione civile, dall' esercito e dall' aviazione civile a oltre 150, il che ha portato alla più grande operazione di non combattimento nella storia dell' Esercito popolare di liberazione.\",\n",
       "   'qas': [{'answers': [{'answer_start': 94, 'text': '60'}],\n",
       "     'id': '56cec801aab44d1400b88a3e',\n",
       "     'question': 'Quanti elicotteri sono stati forniti dal PLAAF?'},\n",
       "    {'answers': [{'answer_start': 117, 'text': '30'}],\n",
       "     'id': '56cec801aab44d1400b88a3f',\n",
       "     'question': \"Quanti elicotteri sarebbero stati forniti dall' industria dell' aviazione civile?\"},\n",
       "    {'answers': [{'answer_start': 318, 'text': 'oltre 150'}],\n",
       "     'id': '56cec801aab44d1400b88a40',\n",
       "     'question': \"Quanti aerei c' erano in totale?\"},\n",
       "    {'answers': [{'answer_start': 318, 'text': 'oltre 150'}],\n",
       "     'id': '56d60cd01c85041400946eea',\n",
       "     'question': \"Qual è il numero totale di aeromobili utilizzati nell' operazione di soccorso?\"},\n",
       "    {'answers': [{'answer_start': 94, 'text': '60'}],\n",
       "     'id': '56d60cd01c85041400946eec',\n",
       "     'question': 'Quanti elicotteri provenivano dal PLAAF?'},\n",
       "    {'answers': [{'answer_start': 134,\n",
       "       'text': \"industria dell' aviazione civile\"}],\n",
       "     'id': '56d60cd01c85041400946eed',\n",
       "     'question': 'Chi ha fornito gli altri 30 elicotteri?'}]},\n",
       "  {'context': \"Pechino ha accettato l' aiuto della Fondazione Tzu Chi di Taiwan alla fine del 13 maggio. Tzu Chi è stata la prima forza al di fuori della Repubblica Popolare Cinese a partecipare allo sforzo di salvataggio. La Cina ha dichiarato di voler accettare con gratitudine l' aiuto internazionale per far fronte al terremoto.\",\n",
       "   'qas': [{'answers': [{'answer_start': 36, 'text': 'Fondazione Tzu Chi'}],\n",
       "     'id': '56cec88baab44d1400b88a45',\n",
       "     'question': 'Quale Fondazione ha voluto aiutare Pechino?'},\n",
       "    {'answers': [{'answer_start': 58, 'text': 'Taiwan'}],\n",
       "     'id': '56cec88baab44d1400b88a46',\n",
       "     'question': \"Dov' era la fondazione?\"},\n",
       "    {'answers': [{'answer_start': 36, 'text': 'Fondazione Tzu Chi'}],\n",
       "     'id': '56d60ddf1c85041400946ef5',\n",
       "     'question': \"Qual è stato il primo gruppo di fuori della Cina a partecipare all' operazione di soccorso?\"},\n",
       "    {'answers': [{'answer_start': 268, 'text': 'aiuto internazionale'}],\n",
       "     'id': '56d60ddf1c85041400946ef6',\n",
       "     'question': 'Che cosa ha detto la Cina di accettare?'}]},\n",
       "  {'context': \"Un volo merci charter diretto è stato effettuato dalla China Airlines da Taiwan Taoyuan International Airport all' aeroporto internazionale di Chengdu Shuangliu, che ha inviato circa 100 tonnellate di forniture di soccorso donate dalla Fondazione Tzu Chi e dalla Croce Rossa di Taiwan alle zone colpite. È stata chiesta l' approvazione delle autorità cinesi della Cina continentale e il volo charter è partito da Taipei alle 17:00 CST, il 15 maggio e è arrivato a Chengdu entro le 20:30 CST. Una squadra di soccorso della Croce Rossa di Taiwan avrebbe dovuto partire da Taipei con un volo charter diretto di Mandarin Airlines verso Chengdu alle 15:00 CST del 16 maggio.\",\n",
       "   'qas': [{'answers': [{'answer_start': 55, 'text': 'China Airlines'}],\n",
       "     'id': '56cec8e2aab44d1400b88a55',\n",
       "     'question': 'Chi ha effettuato un volo cargo charter diretto?'},\n",
       "    {'answers': [{'answer_start': 439, 'text': '15 maggio'}],\n",
       "     'id': '56cec8e2aab44d1400b88a57',\n",
       "     'question': 'Quale data di partenza del volo cargo?'},\n",
       "    {'answers': [{'answer_start': 659, 'text': '16 maggio'}],\n",
       "     'id': '56cec8e2aab44d1400b88a58',\n",
       "     'question': 'Quando è partita una squadra di soccorso?'},\n",
       "    {'answers': [{'answer_start': 73,\n",
       "       'text': 'Taiwan Taoyuan International Airport'}],\n",
       "     'id': '56d613011c85041400946efd',\n",
       "     'question': 'Da quale aeroporto parte il volo charter?'},\n",
       "    {'answers': [{'answer_start': 143, 'text': 'Chengdu'}],\n",
       "     'id': '56d613011c85041400946efe',\n",
       "     'question': 'Dove è avvenuto il volo charter da Taiwan?'},\n",
       "    {'answers': [{'answer_start': 496, 'text': 'squadra di soccorso'}],\n",
       "     'id': '56d613011c85041400946eff',\n",
       "     'question': 'Che cosa ha lasciato il team della Croce Rossa a Taipei il 16 maggio Chengdu?'}]},\n",
       "  {'context': \"Il 16 maggio, i gruppi di soccorso provenienti da Corea del Sud, Giappone, Singapore, Russia e Taiwan sono arrivati per unirsi allo sforzo di salvataggio. Gli Stati Uniti hanno condiviso con le autorità cinesi alcune delle sue immagini satellitari delle zone colpite dal terremoto. Durante il fine settimana, gli Stati Uniti hanno inviato in Cina due forniture di trasporto dell' aeronautica militare C-17 degli Stati Uniti, tra cui tende e generatori. Xinhua ha riferito 135.000 truppe cinesi e medici sono stati coinvolti nello sforzo di salvataggio in 58 contee e città. immagini satellitari delle aree colpite dal terremoto.\",\n",
       "   'qas': [{'answers': [{'answer_start': 472, 'text': '135.000'}],\n",
       "     'id': '56cec9e1aab44d1400b88a63',\n",
       "     'question': 'Quante truppe cinesi sono state coinvolte negli sforzi di salvataggio?'},\n",
       "    {'answers': [{'answer_start': 3, 'text': '16 maggio'}],\n",
       "     'id': '56cec9e1aab44d1400b88a65',\n",
       "     'question': 'Quando sono arrivati in Cina gruppi provenienti dalla Corea del Sud, dal Giappone e da altri paesi?'},\n",
       "    {'answers': [{'answer_start': 227, 'text': 'immagini satellitari'}],\n",
       "     'id': '56d61a451c85041400946f10',\n",
       "     'question': 'Che cosa ha condiviso gli Stati Uniti con la Cina?'},\n",
       "    {'answers': [{'answer_start': 433, 'text': 'tende e generatori'}],\n",
       "     'id': '56d61a451c85041400946f11',\n",
       "     'question': \"Cosa è stato incluso nelle forniture dell' aeronautica militare C-17?\"},\n",
       "    {'answers': [{'answer_start': 472, 'text': '135.000'}],\n",
       "     'id': '56d61a451c85041400946f13',\n",
       "     'question': 'Quante truppe e medici cinesi sono stati coinvolti negli sforzi di soccorso?'}]},\n",
       "  {'context': \"Internet è stato ampiamente utilizzato per trasmettere informazioni a sostegno degli sforzi di salvataggio e recupero. Ad esempio, l' agenzia di stampa ufficiale Xinhua ha istituito un centro online di richiesta di soccorso per trovare gli angoli ciechi del disaster recovery. Dopo aver saputo che gli elicotteri di soccorso avevano avuto difficoltà ad atterrare nell' area dell' epicentro di Wenchuan, uno studente ha proposto un punto di atterraggio online ed è stato scelto come primo touchdown per gli elicotteri[non in citazione dato]. I volontari hanno anche creato diversi siti web per aiutare a memorizzare le informazioni di contatto per le vittime e gli sfollati. Il 31 maggio, un elicottero di salvataggio che trasportava sopravvissuti al terremoto e membri dell' equipaggio si è schiantato a causa della nebbia e delle turbolenze nella contea di Wenchuan. Nessuno è sopravvissuto.\",\n",
       "   'qas': [{'answers': [{'answer_start': 0, 'text': 'Internet'}],\n",
       "     'id': '56ceccc7aab44d1400b88a7d',\n",
       "     'question': 'Che cosa è stato ampiamente utilizzato per trasmettere informazioni a sostegno degli sforzi di salvataggio e recupero?'},\n",
       "    {'answers': [{'answer_start': 228,\n",
       "       'text': 'trovare gli angoli ciechi del disaster recovery'}],\n",
       "     'id': '56ceccc7aab44d1400b88a7f',\n",
       "     'question': 'Qual era lo scopo di questo centro di richiesta di soccorso online?'},\n",
       "    {'answers': [{'answer_start': 393, 'text': 'Wenchuan'}],\n",
       "     'id': '56ceccc7aab44d1400b88a80',\n",
       "     'question': 'Dove hanno avuto difficoltà di atterraggio gli elicotteri di soccorso?'},\n",
       "    {'answers': [{'answer_start': 0, 'text': 'Internet'}],\n",
       "     'id': '56d61c4e1c85041400946f1a',\n",
       "     'question': 'Che cosa è stato utilizzato come aiuto alle comunicazioni negli sforzi di soccorso?'},\n",
       "    {'answers': [{'answer_start': 403, 'text': 'uno studente'}],\n",
       "     'id': '56d61c4e1c85041400946f1c',\n",
       "     'question': \"Quale persona ha suggerito un atterraggio per elicotteri vicino all' epicentro?\"},\n",
       "    {'answers': [{'answer_start': 618, 'text': 'informazioni di contatto'}],\n",
       "     'id': '56d61c4e1c85041400946f1d',\n",
       "     'question': 'Che tipo di informazioni sono state create sui siti web da archiviare?'}]},\n",
       "  {'context': \"Il 12 maggio 2009, la Cina ha celebrato il primo anniversario del terremoto con un momento di silenzio mentre le persone in tutta la nazione ricordavano i morti. Il governo ha anche aperto l' accesso alle rovine sigillate della sede della contea del Beichuan per tre giorni, dopo di che sarà congelato in tempo come un museo reliquia terremoto di stato, per ricordare alla gente del disastro terribile. Ci sono stati anche diversi concerti in tutto il paese per raccogliere fondi per i sopravvissuti al terremoto.\",\n",
       "   'qas': [{'answers': [{'answer_start': 80,\n",
       "       'text': 'un momento di silenzio'}],\n",
       "     'id': '56cecd53aab44d1400b88a88',\n",
       "     'question': \"Cosa è stato fatto per l' anniversario?\"},\n",
       "    {'answers': [{'answer_start': 263, 'text': 'tre giorni'}],\n",
       "     'id': '56cecd53aab44d1400b88a8a',\n",
       "     'question': 'Per quanto tempo è stato aperto?'},\n",
       "    {'answers': [{'answer_start': 80, 'text': 'un momento di silenzio'}],\n",
       "     'id': '56d66b221c85041400947103',\n",
       "     'question': 'Che cosa ha fatto la Cina per celebrare il primo anniversario del terremoto?'},\n",
       "    {'answers': [{'answer_start': 423, 'text': 'diversi concerti'}],\n",
       "     'id': '56d66b221c85041400947105',\n",
       "     'question': 'Che tipo di evento è stato dato per raccogliere fondi per i sopravvissuti al terremoto?'}]},\n",
       "  {'context': 'A seguito del terremoto, le donazioni sono state effettuate da persone provenienti da tutta la Cina continentale, con cabine allestite nelle scuole, presso le banche e nelle vicinanze di distributori di benzina. La gente ha anche donato sangue, con conseguente secondo Xinhua lungo line-up Xinhua nella maggior parte delle principali città cinesi. Molti donato attraverso messaggi di testo sui telefoni cellulari per i conti istituiti da China Unicom e China Mobile 16 maggio, il governo cinese aveva stanziato un totale di 772 milioni di dollari per il terremoto di soccorso finora, in forte aumento da $ 159 milioni di dollari dal 14 maggio sangue.',\n",
       "   'qas': [{'answers': [{'answer_start': 230, 'text': 'donato sangue'}],\n",
       "     'id': '56d666041c850414009470f1',\n",
       "     'question': 'Che cosa ha causato le lunghe linee nella maggior parte delle grandi città?'},\n",
       "    {'answers': [{'answer_start': 118, 'text': 'cabine'}],\n",
       "     'id': '56d666041c850414009470f2',\n",
       "     'question': 'Quali sono state le premesse cinesi per raccogliere donazioni?'},\n",
       "    {'answers': [{'answer_start': 524, 'text': '772 milioni di dollari'}],\n",
       "     'id': '56d666041c850414009470f4',\n",
       "     'question': 'Quanto aveva designato il governo cinese entro il 16 maggio?'}]},\n",
       "  {'context': 'La Società Croce Rossa della Cina ha volato 557 tende e 2.500 trapunte del valore di 788.000 yuan (113.000 dollari USA) nella contea di Wenchuan. La Fondazione Amity ha già iniziato i lavori di soccorso nella regione e ha stanziato 143.000 USD per i soccorsi in caso di catastrofe. Il ministero degli Affari civili del Sichuan ha dichiarato di aver fornito 30.000 tende per i senzatetto rimasti senza tetto.',\n",
       "   'qas': [{'answers': [{'answer_start': 44, 'text': '557'}],\n",
       "     'id': '56cece5caab44d1400b88a9b',\n",
       "     'question': 'Quante tende sono state volate nella regione?'},\n",
       "    {'answers': [{'answer_start': 56, 'text': '2.500'}],\n",
       "     'id': '56cece5caab44d1400b88a9c',\n",
       "     'question': 'Quanti trapunte sono state volate nella regione?'},\n",
       "    {'answers': [{'answer_start': 85, 'text': '788.000 yuan'}],\n",
       "     'id': '56cece5caab44d1400b88a9d',\n",
       "     'question': 'Quanto valevano entrambe le forniture?'},\n",
       "    {'answers': [{'answer_start': 357, 'text': '30.000'}],\n",
       "     'id': '56cece5caab44d1400b88a9f',\n",
       "     'question': 'Quante tende ha fornito il ministero del Sichuan ai senzatetto?'},\n",
       "    {'answers': [{'answer_start': 357, 'text': '30.000'}],\n",
       "     'id': '56d663b11c850414009470e5',\n",
       "     'question': 'Quante tende ha fornito il Ministero degli Affari del Sichuan?'},\n",
       "    {'answers': [{'answer_start': 146, 'text': 'La Fondazione Amity'}],\n",
       "     'id': '56d663b11c850414009470e7',\n",
       "     'question': 'Quali fondamenta avevano già iniziato i lavori di soccorso nella zona?'}]},\n",
       "  {'context': 'Il governo centrale stima che oltre 7.000 aule scolastiche non adeguatamente attrezzate siano crollate in seguito al terremoto. Da allora i cittadini cinesi hanno inventato una frase di cattura:\"tofu-dregs schoolhouses\" (Cinese:?????), per fingere sia la qualità che la quantità di queste costruzioni inferiori che hanno ucciso così tanti bambini in età scolare. A causa della politica del figlio unico, molte famiglie hanno perso l\\' unico figlio quando le scuole della regione sono crollate durante il terremoto. Di conseguenza, i funzionari provinciali e locali del Sichuan hanno abolito la restrizione per le famiglie il cui unico bambino è stato ucciso o gravemente ferito in seguito al disastro. I cosiddetti \"bambini illegali\" di età inferiore ai 18 anni possono essere registrati come sostituti legali dei loro fratelli morti; se il bambino morto fosse illegale, non si applicherebbero ulteriori sanzioni pecuniarie. Il rimborso non sarebbe tuttavia offerto per le ammende già riscosse.',\n",
       "   'qas': [{'answers': [{'answer_start': 36, 'text': '7.000'}],\n",
       "     'id': '56cecf68aab44d1400b88ab7',\n",
       "     'question': 'Quante aule scolastiche sono crollate nel terremoto?'},\n",
       "    {'answers': [{'answer_start': 195, 'text': 'tofu-dregs schoolhouses'}],\n",
       "     'id': '56cecf68aab44d1400b88ab8',\n",
       "     'question': \"Quale frase d' insieme è stata inventata a seguito del crollo delle scuole?\"},\n",
       "    {'answers': [{'answer_start': 195, 'text': 'tofu-dregs schoolhouses'}],\n",
       "     'id': '56d64a821c85041400947077',\n",
       "     'question': 'Che cosa ha iniziato la cittadinanza a chiamare questo tipo di scuole?'}]},\n",
       "  {'context': 'La sera del 18 maggio, il CCTV-1 ha ospitato un programma speciale di quattro ore chiamato The Giving of Love (cinese semplificato:???; cinese tradizionale:????), ospitato da regolari del Gala di Capodanno CCTV e dall\\' ancora di copertura 24 ore su 24 Bai Yansong. Vi hanno partecipato una vasta gamma di personaggi dello spettacolo, letterari, commerciali e politici provenienti dalla Cina continentale, Hong Kong, Singapore e Taiwan. Le donazioni della serata sono ammontate a 1,5 miliardi di yuan cinese (~208 milioni di dollari USA). Tra le donazioni, la TVCC ha dato il maggior contributo aziendale a ¥50 milioni. Quasi contemporaneamente a Taiwan, un programma tematico simile era in onda ospitato dal presidente in carica Ma Ying-jeou. A giugno, l\\' attore di Hong Kong Jackie Chan, che ha donato 1,57 milioni di dollari alle vittime, ha realizzato un video musicale insieme ad altri artisti intitolato \"Promise\"; la canzone è stata composta da Andy Lau. L\\' Artistes 512 Fund Raising Campaign, una maratona di raccolta fondi della durata di 8 ore, si è tenuta il 1° giugno a Hong Kong, alla quale hanno partecipato circa 200 musicisti e celebrità della Sinosfera. A Singapore, MediaCorp Channel 8 ha ospitato un programma dal vivo?? programma di quattro ore chiamato Il dono dell\\' amore.',\n",
       "   'qas': [{'answers': [{'answer_start': 252, 'text': 'Bai Yansong'}],\n",
       "     'id': '56cecff4aab44d1400b88abe',\n",
       "     'question': 'Quanto erano grandi le donazioni del programma?'},\n",
       "    {'answers': [{'answer_start': 803, 'text': '1,57 milioni di dollari'}],\n",
       "     'id': '56cecff4aab44d1400b88abf',\n",
       "     'question': 'Quanto ha donato Jackie Chan per sostenere?'},\n",
       "    {'answers': [{'answer_start': 1273, 'text': \"Il dono dell' amore\"}],\n",
       "     'id': '56cecff4aab44d1400b88ac1',\n",
       "     'question': 'Qual era il programma che CCTV-1 ha ospitato?'},\n",
       "    {'answers': [{'answer_start': 91, 'text': 'The Giving of Love'}],\n",
       "     'id': '56d6477c1c85041400947065',\n",
       "     'question': 'Quali sono state le donazioni totali per il programma?'},\n",
       "    {'answers': [{'answer_start': 26, 'text': 'CCTV'}],\n",
       "     'id': '56d6477c1c85041400947066',\n",
       "     'question': 'Quale azienda ha dato il massimo?'},\n",
       "    {'answers': [{'answer_start': 803, 'text': '1,57 milioni'}],\n",
       "     'id': '56d6477c1c85041400947067',\n",
       "     'question': \"Quanto ha donato l' attore Jackie Chan?\"}]},\n",
       "  {'context': 'Gli sforzi di salvataggio compiuti dal governo cinese sono stati elogiati dai media occidentali, soprattutto in confronto al blocco degli aiuti stranieri da parte del Myanmar durante il ciclone Nargis, nonché ai precedenti risultati della Cina durante il terremoto di Tangshan del 1976. L\\' apertura della Cina durante la copertura mediatica del terremoto del Sichuan ha portato un professore presso l\\' Università di Pechino a dire:\"Questa è la prima volta[che] i media cinesi sono stati all\\' altezza degli standard internazionali\". Los Angeles Times ha elogiato la copertura mediatica della Cina del terremoto di essere \"democratico\".',\n",
       "   'qas': [{'answers': [{'answer_start': 138, 'text': 'aiuti stranieri'}],\n",
       "     'id': '56d61fc11c85041400946f24',\n",
       "     'question': 'Che cosa ha fatto blocco Myanmar dopo Cyclone Nargis?'},\n",
       "    {'answers': [{'answer_start': 532, 'text': 'Los Angeles Times'}],\n",
       "     'id': '56d61fc11c85041400946f26',\n",
       "     'question': 'Chi ha elogiato la copertura mediatica cinese come democratica?'}]},\n",
       "  {'context': 'A causa del terremoto di magnitudo 7,9 e delle numerose forti scosse di assestamento, molti fiumi sono stati bloccati da grandi frane, che hanno portato alla formazione di \"laghi di sisma\" dietro le ostruzioni; queste enormi quantità d\\' acqua si stavano accumulando ad un ritmo molto elevato dietro le dighe naturali di frane e si temeva che le ostruzioni sarebbero infine crollate sotto il peso della massa d\\' acqua sempre crescente, potenzialmente mettendo a repentaglio la vita di milioni di persone. Al 27 maggio 2008,34 laghi si erano formati a causa del terremoto che bloccava i detriti e arginava i fiumi, e si stimava che 28 di essi fossero ancora potenzialmente pericolosi per la popolazione locale. Gli interi villaggi hanno dovuto essere evacuati a causa delle conseguenti inondazioni.',\n",
       "   'qas': [{'answers': [{'answer_start': 522, 'text': '34'}],\n",
       "     'id': '56cedd7daab44d1400b88b50',\n",
       "     'question': 'Quanti laghi di tremito si sono formati?'},\n",
       "    {'answers': [{'answer_start': 630, 'text': '28'}],\n",
       "     'id': '56cedd7daab44d1400b88b51',\n",
       "     'question': 'Quanti laghi costituivano un pericolo per le persone?'},\n",
       "    {'answers': [{'answer_start': 121, 'text': 'grandi frane'}],\n",
       "     'id': '56d624261c85041400946f2d',\n",
       "     'question': 'Che cosa ha bloccato molti dei fiumi della zona?'},\n",
       "    {'answers': [{'answer_start': 522, 'text': '34'}],\n",
       "     'id': '56d624261c85041400946f2f',\n",
       "     'question': 'A partire dal 27 maggio quanti laghi sismici si erano formati dietro i detriti di frane?'},\n",
       "    {'answers': [{'answer_start': 713, 'text': 'interi villaggi'}],\n",
       "     'id': '56d624261c85041400946f30',\n",
       "     'question': 'Che cosa doveva essere evacuato a causa di un potenziale allagamento?'}]},\n",
       "  {'context': \"Il più precario di questi ciarlatani era quello che si trovava nel terreno estremamente difficile del Monte Tangjia nella contea di Beichuan, Sichuan, accessibile solo a piedi o in aereo; un elicottero di sollevamento pesante Mi-26T appartenente alla China Flying Dragon Special Aviation Company è stato utilizzato per portare pesanti trattori movimento terra nella zona colpita. Questa operazione è stata accoppiata con il lavoro svolto da elicotteri PLAAF Mi-17 portando in corpi di ingegneria PLA, specialisti di esplosivi e altro personale per unire 1.200 soldati che sono arrivati sul posto a piedi. Cinque tonnellate di combustibile per azionare il macchinario sono state trasportate in aria fino al sito, dove è stata costruita una saracinesca per consentire lo scarico sicuro dell' acqua di strozzatura. A valle, più di 200.000 persone sono state evacuate dal Mianyang entro il 1 giugno in previsione dello scoppio della diga.\",\n",
       "   'qas': [{'answers': [{'answer_start': 102,\n",
       "       'text': 'Monte Tangjia nella contea di Beichuan, Sichuan'}],\n",
       "     'id': '56ceddf6aab44d1400b88b67',\n",
       "     'question': 'Dove si trovava il lago più precario?'},\n",
       "    {'answers': [{'answer_start': 335, 'text': 'trattori'}],\n",
       "     'id': '56ceddf6aab44d1400b88b69',\n",
       "     'question': 'Quali macchine sono state trasportate in aereo?'},\n",
       "    {'answers': [{'answer_start': 828, 'text': '200.000'}],\n",
       "     'id': '56ceddf6aab44d1400b88b6b',\n",
       "     'question': 'Quante persone sono state evacuate a valle?'},\n",
       "    {'answers': [{'answer_start': 912, 'text': 'lo scoppio della diga'}],\n",
       "     'id': '56d62b0f1c85041400946f5e',\n",
       "     'question': \"Qual è stata la paura che ha causato l' evacuazione di 200.000 persone dal Mianyang?\"},\n",
       "    {'answers': [{'answer_start': 102, 'text': 'Monte Tangjia'}],\n",
       "     'id': '56d62b0f1c85041400946f5f',\n",
       "     'question': 'Dove si trovava il peggio dei laghi sismici?'},\n",
       "    {'answers': [{'answer_start': 122, 'text': 'contea di Beichuan, Sichuan'}],\n",
       "     'id': '56d62b0f1c85041400946f60',\n",
       "     'question': 'Dove si trova il monte Tangjia?'},\n",
       "    {'answers': [{'answer_start': 554, 'text': '1.200'}],\n",
       "     'id': '56d62b0f1c85041400946f62',\n",
       "     'question': 'Quanti soldati hanno dovuto recarsi nella zona a piedi?'}]},\n",
       "  {'context': 'Il Consiglio di Stato ha dichiarato un periodo di tre giorni di lutto nazionale per le vittime del terremoto a partire dal 19 maggio 2008, la bandiera nazionale della RPC e le bandiere regionali di Hong Kong e Macao regioni amministrative speciali ha volato a metà albero. Era la prima volta che un periodo di lutto nazionale era stato dichiarato per qualcosa di diverso dalla morte di un leader statale, e molti lo hanno definito la più grande manifestazione di lutto dalla morte di Mao Zedong. Alle 14:28 CST 28 il 19 maggio 2008, una settimana dopo il terremoto, il pubblico cinese ha tenuto un momento di silenzio. La gente taceva per tre minuti mentre la difesa aerea, la polizia e le sirene antincendio, e le corna di veicoli, navi e treni suonavano. Anche le auto e i camion sulle strade di Pechino si sono fermati. La gente spontaneamente scoppiò in allegria \"Zhongguo jiayou\"! (Vai, Cina!) e \"Sichuan jiayou\" (Let\\'s go, Sichuan!).',\n",
       "   'qas': [{'answers': [{'answer_start': 547, 'text': 'dopo'}],\n",
       "     'id': '56cede78aab44d1400b88b7c',\n",
       "     'question': 'Chi ha dichiarato il lutto?'},\n",
       "    {'answers': [{'answer_start': 64, 'text': 'lutto nazionale'}],\n",
       "     'id': '56d62ce51c85041400946f7a',\n",
       "     'question': 'Che cosa ha dichiarato il Consiglio di Stato?'},\n",
       "    {'answers': [{'answer_start': 484, 'text': 'Mao Zedong'}],\n",
       "     'id': '56d62ce51c85041400946f7b',\n",
       "     'question': 'Questa è stata la più grande manifestazione di lutto dalla morte di chi?'},\n",
       "    {'answers': [{'answer_start': 123, 'text': '19 maggio 2008'}],\n",
       "     'id': '56d62ce51c85041400946f7c',\n",
       "     'question': 'Quando i cinesi hanno avuto un momento di silenzio?'},\n",
       "    {'answers': [{'answer_start': 39, 'text': 'periodo di tre giorni'}],\n",
       "     'id': '56d62ce51c85041400946f7e',\n",
       "     'question': 'Quanto tempo è durato il lutto nazionale per le vittime del terremoto?'}]},\n",
       "  {'context': \"Il Comitato Organizzatore di Ningbo del comitato organizzatore della torcia olimpica di Pechino ha annunciato che la staffetta, prevista per svolgersi a Ningbo durante la mattinata nazionale, sarebbe stata sospesa per la durata del periodo di lutto. Il percorso della torcia attraverso il paese è stato ridimensionato, e c' è stato un minuto di silenzio quando la tappa successiva ha iniziato nella città di Ruijin, Jiangxi il mercoledì dopo il terremoto.\",\n",
       "   'qas': [{'answers': [{'answer_start': 29, 'text': 'Ningbo'}],\n",
       "     'id': '56cedecdaab44d1400b88b8e',\n",
       "     'question': \"Dov' era previsto il relè?\"},\n",
       "    {'answers': [{'answer_start': 151, 'text': 'a Ningbo'}],\n",
       "     'id': '56d62e501c85041400946f95',\n",
       "     'question': 'Dove doveva avvenire il relè della torcia?'},\n",
       "    {'answers': [{'answer_start': 250, 'text': 'Il percorso'}],\n",
       "     'id': '56d62e501c85041400946f96',\n",
       "     'question': 'Quale parte del relè ha cambiato?'},\n",
       "    {'answers': [{'answer_start': 408, 'text': 'Ruijin, Jiangxi'}],\n",
       "     'id': '56d62e501c85041400946f97',\n",
       "     'question': \"Dove c' era un minuto di silenzio durante la staffetta?\"}]},\n",
       "  {'context': 'Molti siti web hanno convertito la loro home page in bianco e nero; Sina. com e Sohu, i principali portali internet, hanno limitato le loro homepage alle notizie e rimosso tutte le pubblicità. I siti web cinesi di condivisione video Youku e Tudou hanno mostrato uno sfondo nero e collocato più video che mostrano filmati di terremoto e reportage di notizie. La versione cinese di MSN, cn. msn. com, mostrava anche annunci pubblicitari sul terremoto e gli sforzi di soccorso.',\n",
       "   'qas': []},\n",
       "  {'context': \"Ye Zhiping, il preside della scuola media di Sangzao a Sangzao, una delle più grandi della Contea di An, ha ricevuto il merito di un' azione proattiva che ha risparmiato la vita a tutti i 2.323 alunni presenti quando si è verificato il terremoto. Nel corso di un triennio che si è concluso nel 2007, ha seguito un' importante revisione della sua scuola. Durante quel periodo ha ottenuto più di 400.000 yuan (US$60.000) dal dipartimento di istruzione contea, denaro usato per ampliare e rafforzare i pilastri di cemento e la ringhiera balcone di tutti e quattro i piani della sua scuola, così come fissare i pavimenti in cemento.\",\n",
       "   'qas': [{'answers': [{'answer_start': 0, 'text': 'Ye Zhiping'}],\n",
       "     'id': '56cee003aab44d1400b88bb1',\n",
       "     'question': 'Chi era il preside della scuola media di Sangzao?'},\n",
       "    {'answers': [{'answer_start': 188, 'text': '2.323'}],\n",
       "     'id': '56cee003aab44d1400b88bb3',\n",
       "     'question': 'Quanti studenti hanno frequentato la scuola?'},\n",
       "    {'answers': [{'answer_start': 394, 'text': '400.000 yuan'}],\n",
       "     'id': '56cee003aab44d1400b88bb5',\n",
       "     'question': 'Quanto denaro è stato utilizzato per rafforzare la costruzione della scuola?'},\n",
       "    {'answers': [{'answer_start': 0, 'text': 'Ye Zhiping'}],\n",
       "     'id': '56d64f7c1c85041400947095',\n",
       "     'question': 'Quale direttore scolastico ha rafforzato la sua scuola?'},\n",
       "    {'answers': [{'answer_start': 45, 'text': 'Sangzao'}],\n",
       "     'id': '56d64f7c1c85041400947097',\n",
       "     'question': \"Dov' è la scuola media di Sangzao?\"}]},\n",
       "  {'context': \"Tuttavia, Reuters ha riferito nel mese di giugno che, ad oggi, i pubblici ministeri cinesi hanno aderito a un' indagine ufficiale in dieci scuole crollato durante il devastante terremoto di maggio per ottenere materiale di prima mano della qualità delle costruzioni nelle scuole crollato, avviare indagini preliminari e prepararsi per eventuali indagini sulla criminalità professionale. È stato inoltre riferito che, dopo il terremoto del mese scorso, si sarebbero dovuti effettuare controlli di sicurezza nelle scuole di tutta la Cina.\",\n",
       "   'qas': [{'answers': [{'answer_start': 483,\n",
       "       'text': 'controlli di sicurezza'}],\n",
       "     'id': '56cee069aab44d1400b88bbd',\n",
       "     'question': 'Cosa doveva essere fatto nelle scuole dopo il sisma?'},\n",
       "    {'answers': [{'answer_start': 360, 'text': 'criminalità professionale'}],\n",
       "     'id': '56d658061c850414009470a8',\n",
       "     'question': 'Quali indagini stanno conducendo i pubblici ministeri?'},\n",
       "    {'answers': [{'answer_start': 512, 'text': 'scuole di tutta la Cina'}],\n",
       "     'id': '56d658061c850414009470a9',\n",
       "     'question': 'Dove saranno i cinesi ad effettuare i controlli di sicurezza?'},\n",
       "    {'answers': [{'answer_start': 10, 'text': 'Reuters'}],\n",
       "     'id': '56d658061c850414009470aa',\n",
       "     'question': 'Quale gruppo ha riferito che i pubblici ministeri cinesi sono stati coinvolti nelle indagini sui crolli della scuola?'}]},\n",
       "  {'context': 'Il New York Times ha riferito che \"funzionari di governo a Pechino e Sichuan hanno detto che stanno indagando sui crolli. Riconoscendo la debolezza dei codici edilizi nelle campagne, il 27 maggio la Commissione nazionale per lo sviluppo e la riforma ha dichiarato di aver elaborato un emendamento per migliorare gli standard di costruzione delle scuole elementari e medie nelle zone rurali. Gli esperti stanno rivedendo il progetto, ha detto la commissione. Per limitare le proteste, i funzionari hanno spinto i genitori a firmare un documento che vietava loro di organizzare proteste in cambio di denaro, ma alcuni che si rifiutavano di firmare sono stati minacciati. Gli importi dei pagamenti variavano da scuola a scuola, ma erano all\\' incirca gli stessi. Ad Hanwang, ai genitori è stato offerto un pacchetto del valore di 8.800 USD in contanti e una pensione per genitore di quasi 5.600 USD.',\n",
       "   'qas': [{'answers': [{'answer_start': 462, 'text': 'limitare le proteste'}],\n",
       "     'id': '56d65a4b1c850414009470b0',\n",
       "     'question': 'Cosa stanno cercando di fare i funzionari per protestare i genitori?'},\n",
       "    {'answers': [{'answer_start': 598, 'text': 'denaro'}],\n",
       "     'id': '56d65a4b1c850414009470b1',\n",
       "     'question': 'Quali sono i funzionari che offrono ai genitori in cambio di proteste?'}]},\n",
       "  {'context': 'Oltre ai genitori, Liu Shaokun (???), un insegnante di scuola del Sichuan, è stato arrestato il 25 giugno 2008 per \"diffondere voci e distruggere l\\' ordine sociale\" sul terremoto del Sichuan. La famiglia di Liu è stato poi detto che egli è stato indagato su sospetto del reato di istigazione alla sovversione. Liu aveva viaggiato per lo Shifang, scattato foto di edifici scolastici crollati, e metterli online. Aveva anche espresso la sua rabbia per \"gli edifici scadenti tofu-dregs\" (?????) in un\\' intervista ai media. Gli è stato ordinato di servire un anno di rieducazione attraverso il lavoro (RTL). Secondo l\\' organizzazione per i diritti umani in Cina, Liu è stato rilasciato per scontare la sua condanna RTL al di fuori del campo di lavoro.',\n",
       "   'qas': [{'answers': [{'answer_start': 19, 'text': 'Liu Shaokun'}],\n",
       "     'id': '56cee14aaab44d1400b88bcb',\n",
       "     'question': 'Chi era un insegnante di scuola del Sichuan?'},\n",
       "    {'answers': [{'answer_start': 271,\n",
       "       'text': 'reato di istigazione alla sovversione'}],\n",
       "     'id': '56d65c671c850414009470ba',\n",
       "     'question': 'Perché è stato indagato?'},\n",
       "    {'answers': [{'answer_start': 394, 'text': 'metterli online'}],\n",
       "     'id': '56d65c671c850414009470bb',\n",
       "     'question': 'Che cosa ha fatto Liu Shankun con le foto che ha scattato delle scuole crollate?'},\n",
       "    {'answers': [{'answer_start': 492, 'text': \"in un' intervista ai media\"}],\n",
       "     'id': '56d65c671c850414009470bc',\n",
       "     'question': 'Dove ha definito gli edifici scolastici scadenti?'},\n",
       "    {'answers': [{'answer_start': 552, 'text': 'un anno di rieducazione'}],\n",
       "     'id': '56d65c671c850414009470bd',\n",
       "     'question': 'Qual era la sua punizione assegnata?'}]},\n",
       "  {'context': 'Nel gennaio 2010, il giornale inglese con sede a Hong Kong The Standard ha riferito che lo scrittore Tan Zuoren ha tentato di documentare la costruzione scadente che potrebbe aver portato a massicce vittime nelle scuole, è stato condannato in prigione apparentemente per la sua scrittura di un articolo nel 2007 a sostegno del movimento pro-democrazia nel 1989.',\n",
       "   'qas': [{'answers': [{'answer_start': 303, 'text': 'nel 2007'}],\n",
       "     'id': '56cee1e4aab44d1400b88be0',\n",
       "     'question': 'Quando è avvenuta la condanna?'},\n",
       "    {'answers': [{'answer_start': 4, 'text': 'gennaio 2010'}],\n",
       "     'id': '56cee1e4aab44d1400b88be1',\n",
       "     'question': \"Quando è stato pubblicato l' articolo sul caso?\"}]},\n",
       "  {'context': \"A causa della magnitudo del terremoto e dell' attenzione mediatica sulla Cina, le nazioni e le organizzazioni straniere hanno risposto immediatamente al disastro offrendo condoglianze e assistenza. Il 14 maggio, l' UNICEF ha riferito che la Cina ha chiesto formalmente il sostegno della comunità internazionale per rispondere ai bisogni delle famiglie colpite.\",\n",
       "   'qas': [{'answers': [{'answer_start': 234,\n",
       "       'text': 'che la Cina ha chiesto formalmente il sostegno della comunità internazionale'}],\n",
       "     'id': '56cee23caab44d1400b88be6',\n",
       "     'question': \"Che cosa ha riferito l' UNICEF?\"},\n",
       "    {'answers': [{'answer_start': 171, 'text': 'condoglianze e assistenza'}],\n",
       "     'id': '56d660e91c850414009470d3',\n",
       "     'question': 'Che cosa hanno offerto alla Cina le nazioni straniere a causa della gravità del terremoto?'},\n",
       "    {'answers': [{'answer_start': 201, 'text': '14 maggio'}],\n",
       "     'id': '56d660e91c850414009470d4',\n",
       "     'question': 'Quando ha chiesto formalmente aiuto alla comunità internazionale?'},\n",
       "    {'answers': [{'answer_start': 215, 'text': 'UNICEF'}],\n",
       "     'id': '56d660e91c850414009470d5',\n",
       "     'question': 'Quale organizzazione ha riferito che la Cina ha chiesto aiuto?'}]},\n",
       "  {'context': \"Entro il 14 maggio, il Ministero degli Affari civili ha dichiarato che 10,7 miliardi di yuan (circa 1,5 miliardi di dollari) era stato donato dal pubblico cinese. Houston Rockets centro Yao Ming, una delle icone sportive più popolari del paese, ha dato $214.000 e $71.000 alla Società Croce Rossa della Cina. L' associazione ha inoltre raccolto un totale di 26 milioni di dollari in donazioni finora raccolte. Anche altre multinazionali situate in Cina hanno annunciato ingenti donazioni.\",\n",
       "   'qas': [{'answers': [{'answer_start': 358,\n",
       "       'text': '26 milioni di dollari'}],\n",
       "     'id': '56cee294aab44d1400b88bed',\n",
       "     'question': 'Quanto ha raccolto la Croce Rossa in donazioni?'},\n",
       "    {'answers': [{'answer_start': 71, 'text': '10,7 miliardi di yuan'}],\n",
       "     'id': '56d6622d1c850414009470db',\n",
       "     'question': 'Quanto denaro era stato donato entro il 14 maggio?'},\n",
       "    {'answers': [{'answer_start': 186, 'text': 'Yao Ming'}],\n",
       "     'id': '56d6622d1c850414009470dd',\n",
       "     'question': 'Quale famoso giocatore di basket ha fatto due grandi donazioni alla crisi?'},\n",
       "    {'answers': [{'answer_start': 358, 'text': '26 milioni'}],\n",
       "     'id': '56d6622d1c850414009470de',\n",
       "     'question': 'Quanto ha raccolto la Società della Croce Rossa?'}]},\n",
       "  {'context': 'Francis Marcus della Federazione Internazionale della Croce Rossa ha elogiato lo sforzo cinese di salvataggio come \"veloce e molto efficiente\" a Pechino martedì. Ma ha aggiunto che la portata del disastro era tale che \"non possiamo aspettarci che il governo possa fare tutto e gestire ogni aspetto delle necessità\". L\\' economista ha osservato che la Cina ha reagito al disastro \"rapidamente e con un\\' insolita apertura\", contrastandola con la risposta segreta della Birmania al ciclone Nargis, che ha devastato il paese 10 giorni prima del terremoto.',\n",
       "   'qas': [{'answers': [{'answer_start': 410, 'text': 'apertura'}],\n",
       "     'id': '56d614dd1c85041400946f07',\n",
       "     'question': 'Quale atteggiamento atipico ha mostrato la Cina?'},\n",
       "    {'answers': [{'answer_start': 520, 'text': '10 giorni'}],\n",
       "     'id': '56d614dd1c85041400946f09',\n",
       "     'question': 'Quanto tempo prima del terremoto il ciclone Nargis colpì la Birmania?'},\n",
       "    {'answers': [{'answer_start': 21,\n",
       "       'text': 'Federazione Internazionale della Croce Rossa'}],\n",
       "     'id': '56d614dd1c85041400946f0a',\n",
       "     'question': 'Quale organizzazione ha rappresentato Francesco Marco?'}]},\n",
       "  {'context': 'Tutte le emittenti televisive della Cina continentale (insieme ad alcune stazioni di Hong Kong e delle comunità espatriate) hanno cancellato tutti i programmi programmati regolarmente, hanno mostrato il loro logo in scala di grigi e hanno sostituito i programmi cancellati con filmati dal vivo del CCTV-1 per più giorni dopo il terremoto. Anche i canali televisivi a pagamento (come il canale V) sono stati sospesi.',\n",
       "   'qas': [{'answers': [{'answer_start': 298, 'text': 'CCTV-1'}],\n",
       "     'id': '56d646091c8504140094705e',\n",
       "     'question': 'Qual è stata la fonte dei feed live?'}]},\n",
       "  {'context': \"Sebbene il governo cinese sia stato inizialmente elogiato per la sua risposta al terremoto (soprattutto rispetto al blocco degli aiuti da parte della giunta militare di governo del Myanmar durante il ciclone Nargis), ha poi visto un' erosione della fiducia nello scandalo della costruzione scolastica.\",\n",
       "   'qas': [{'answers': [{'answer_start': 181, 'text': 'Myanmar'}],\n",
       "     'id': '56d6488e1c8504140094706f',\n",
       "     'question': 'Quale governo ha bloccato gli aiuti dopo il ciclone Nargis?'},\n",
       "    {'answers': [{'answer_start': 263,\n",
       "       'text': 'scandalo della costruzione scolastica'}],\n",
       "     'id': '56d6488e1c85041400947070',\n",
       "     'question': \"Su quale scandalo ha perso nell' opinione pubblica il governo cinese?\"},\n",
       "    {'answers': [{'answer_start': 69, 'text': 'risposta al terremoto'}],\n",
       "     'id': '56d6488e1c85041400947071',\n",
       "     'question': 'A cosa è stato lodato per la prima volta il governo cinese?'}]},\n",
       "  {'context': \"Il 29 maggio 2008, i funzionari governativi hanno iniziato a ispezionare le rovine di migliaia di scuole crollate, alla ricerca di indizi sul perché si sono sgretolate. Migliaia di genitori in tutta la provincia hanno accusato funzionari locali e costruttori di tagliare angoli nella costruzione della scuola, citando che dopo il terremoto altri edifici vicini sono stati poco danneggiati. All' indomani del terremoto, molti governi locali hanno promesso di indagare formalmente sui crolli della scuola, ma a partire dal 17 luglio 2008 in tutto il Sichuan, i genitori di bambini perduti nelle scuole crollate si sono lamentati di non aver ancora ricevuto alcuna segnalazione. Funzionari locali li ha esortati a non protestare, ma i genitori hanno dimostrato e chiesto un' indagine. Inoltre, i censori hanno scoraggiato la pubblicazione sui media di storie di scuole costruite in modo inadeguato e vi è stato un incidente in cui la polizia ha allontanato i manifestanti.\",\n",
       "   'qas': []},\n",
       "  {'context': 'Il AP ha riferito che \"I media controllati dallo Stato ha ampiamente ignorato la questione, apparentemente sotto le istruzioni dell\\' ufficio di propaganda. Genitori e volontari che hanno interrogato le autorità sono stati detenuti e minacciati.',\n",
       "   'qas': [{'answers': [{'answer_start': 25,\n",
       "       'text': 'media controllati dallo Stato'}],\n",
       "     'id': '56d650911c8504140094709f',\n",
       "     'question': 'Chi ha ignorato la questione della scuola?'},\n",
       "    {'answers': [{'answer_start': 0, 'text': 'Il AP'}],\n",
       "     'id': '56d650911c850414009470a2',\n",
       "     'question': 'Quale fonte mediatica ha riferito che ciò accade?'}]},\n",
       "  {'context': 'Il 15 maggio 2008 Geoffery York del Globeandmail. com ha riferito che gli edifici di costruzione scadente sono comunemente chiamati \"edifici tofu\" perché i costruttori tagliano gli angoli sostituendo barre d\\' acciaio con fili di ferro sottili per il rinforzo del calcestruzzo, utilizzando cemento di qualità inferiore, se ce ne sono, e utilizzando meno mattoni di quanto dovrebbero.',\n",
       "   'qas': []},\n",
       "  {'context': \"Rimangono tuttavia ancora delle domande, in quanto alcuni funzionari di governo corrotti non sono ancora stati consegnati alla giustizia, mentre le numerose famiglie che hanno perso l' unico figlio, cercano ancora di ottenere un risarcimento e di rendere giustizia a quanto era accaduto. Secondo il Times, molti genitori sono stati avvertiti dal governo di non mettere in scena una protesta sotto la minaccia dell' arresto.\",\n",
       "   'qas': []}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_it_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7b7e96a5b14d68aef8d5d6d267cb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833ef79a473a40f5ab0bb1fdbe4f8bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'paragraphs'],\n",
       "        num_rows: 442\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['title', 'paragraphs'],\n",
       "        num_rows: 48\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = {\"train\": \"SQuAD_it-train.json\", \"test\": \"SQuAD_it-test.json\"}\n",
    "squad_it_dataset = load_dataset(\"json\", data_files=data_files, field=\"data\")\n",
    "squad_it_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to slice and dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\"\n",
    "!unzip drugsCom_raw.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\"\n",
    "!unzip drugsCom_raw.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d56363f1054e1197b4b6fceed34382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902e4900514a4e9cb4d02384367fa1d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {\"train\": \"drugsComTrain_raw.tsv\", \"test\": \"drugsComTest_raw.tsv\"}\n",
    "# \\t is the tab character in Python\n",
    "drug_dataset = load_dataset(\"csv\", data_files=data_files, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': [87571, 178045, 80482],\n",
       " 'drugName': ['Naproxen', 'Duloxetine', 'Mobic'],\n",
       " 'condition': ['Gout, Acute', 'ibromyalgia', 'Inflammatory Conditions'],\n",
       " 'review': ['\"like the previous person mention, I&#039;m a strong believer of aleve, it works faster for my gout than the prescription meds I take. No more going to the doctor for refills.....Aleve works!\"',\n",
       "  '\"I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\\r\\nas a pain reducer and an anti-depressant, however, the side effects outweighed \\r\\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\\r\\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\\r\\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\\r\\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects.\"',\n",
       "  '\"I have been taking Mobic for over a year with no side effects other than an elevated blood pressure.  I had severe knee and ankle pain which completely went away after taking Mobic.  I attempted to stop the medication however pain returned after a few days.\"'],\n",
       " 'rating': [9.0, 3.0, 10.0],\n",
       " 'date': ['September 2, 2015', 'November 7, 2011', 'June 5, 2013'],\n",
       " 'usefulCount': [36, 13, 128]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_sample = drug_dataset[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "# Peek at the first few examples\n",
    "drug_sample[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in drug_dataset.keys():\n",
    "    assert len(drug_dataset[split]) == len(drug_dataset[split].unique(\"Unnamed: 0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n",
       "        num_rows: 161297\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n",
       "        num_rows: 53766\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_dataset = drug_dataset.rename_column(\n",
    "    original_column_name=\"Unnamed: 0\", new_column_name=\"patient_id\"\n",
    ")\n",
    "drug_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29bc7696baf74f828b7bbeeaec68d983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/161297 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlowercase_condition\u001b[39m(example):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m\"\u001b[39m: example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mlower()}\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdrug_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlowercase_condition\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\dataset_dict.py:886\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m--> 886\u001b[0m     {\n\u001b[0;32m    887\u001b[0m         k: dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m    888\u001b[0m             function\u001b[38;5;241m=\u001b[39mfunction,\n\u001b[0;32m    889\u001b[0m             with_indices\u001b[38;5;241m=\u001b[39mwith_indices,\n\u001b[0;32m    890\u001b[0m             with_rank\u001b[38;5;241m=\u001b[39mwith_rank,\n\u001b[0;32m    891\u001b[0m             input_columns\u001b[38;5;241m=\u001b[39minput_columns,\n\u001b[0;32m    892\u001b[0m             batched\u001b[38;5;241m=\u001b[39mbatched,\n\u001b[0;32m    893\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    894\u001b[0m             drop_last_batch\u001b[38;5;241m=\u001b[39mdrop_last_batch,\n\u001b[0;32m    895\u001b[0m             remove_columns\u001b[38;5;241m=\u001b[39mremove_columns,\n\u001b[0;32m    896\u001b[0m             keep_in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory,\n\u001b[0;32m    897\u001b[0m             load_from_cache_file\u001b[38;5;241m=\u001b[39mload_from_cache_file,\n\u001b[0;32m    898\u001b[0m             cache_file_name\u001b[38;5;241m=\u001b[39mcache_file_names[k],\n\u001b[0;32m    899\u001b[0m             writer_batch_size\u001b[38;5;241m=\u001b[39mwriter_batch_size,\n\u001b[0;32m    900\u001b[0m             features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[0;32m    901\u001b[0m             disable_nullable\u001b[38;5;241m=\u001b[39mdisable_nullable,\n\u001b[0;32m    902\u001b[0m             fn_kwargs\u001b[38;5;241m=\u001b[39mfn_kwargs,\n\u001b[0;32m    903\u001b[0m             num_proc\u001b[38;5;241m=\u001b[39mnum_proc,\n\u001b[0;32m    904\u001b[0m             desc\u001b[38;5;241m=\u001b[39mdesc,\n\u001b[0;32m    905\u001b[0m         )\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    907\u001b[0m     }\n\u001b[0;32m    908\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\dataset_dict.py:887\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m    886\u001b[0m     {\n\u001b[1;32m--> 887\u001b[0m         k: \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    907\u001b[0m     }\n\u001b[0;32m    908\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    558\u001b[0m }\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3073\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3068\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3069\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3070\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3071\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3072\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3073\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3074\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m   3075\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3446\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3444\u001b[0m _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   3445\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[1;32m-> 3446\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m update_data:\n\u001b[0;32m   3448\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3338\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[0;32m   3337\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[1;32m-> 3338\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m function(\u001b[38;5;241m*\u001b[39mfn_args, \u001b[38;5;241m*\u001b[39madditional_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_kwargs)\n\u001b[0;32m   3339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[0;32m   3340\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3341\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[0;32m   3342\u001b[0m     }\n",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m, in \u001b[0;36mlowercase_condition\u001b[1;34m(example)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlowercase_condition\u001b[39m(example):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcondition\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()}\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "def lowercase_condition(example):\n",
    "    return {\"condition\": example[\"condition\"].lower()}\n",
    "\n",
    "\n",
    "drug_dataset.map(lowercase_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_nones(x):\n",
    "    return x[\"condition\"] is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lambda x: x * x)(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lambda base, height: 0.5 * base * height)(4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59854ff1ce5347a2bb7e31e08b902244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/161297 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469c453632ab484d82a76a427febb466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/53766 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drug_dataset = drug_dataset.filter(lambda x: x[\"condition\"] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4119ef30182649f6829ce3f2a564b0df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/160398 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa52993cc5f493082590c1423d26da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/53471 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['left ventricular dysfunction', 'adhd', 'birth control']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_dataset = drug_dataset.map(lowercase_condition)\n",
    "# Check that lowercasing worked\n",
    "drug_dataset[\"train\"][\"condition\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_review_length(example):\n",
    "    return {\"review_length\": len(example[\"review\"].split())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00180d230254ea68c097d50d5f8b7a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/160398 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5850fff120c64c8e8c9ec6e0a2977dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/53471 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'patient_id': 206461,\n",
       " 'drugName': 'Valsartan',\n",
       " 'condition': 'left ventricular dysfunction',\n",
       " 'review': '\"It has no side effect, I take it in combination of Bystolic 5 Mg and Fish Oil\"',\n",
       " 'rating': 9.0,\n",
       " 'date': 'May 20, 2012',\n",
       " 'usefulCount': 27,\n",
       " 'review_length': 17}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_dataset = drug_dataset.map(compute_review_length)\n",
    "# Inspect the first training example\n",
    "drug_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'patient_id': [111469, 13653, 53602],\n",
       " 'drugName': ['Ledipasvir / sofosbuvir',\n",
       "  'Amphetamine / dextroamphetamine',\n",
       "  'Alesse'],\n",
       " 'condition': ['hepatitis c', 'adhd', 'birth control'],\n",
       " 'review': ['\"Headache\"', '\"Great\"', '\"Awesome\"'],\n",
       " 'rating': [10.0, 10.0, 10.0],\n",
       " 'date': ['February 3, 2015', 'October 20, 2009', 'November 23, 2015'],\n",
       " 'usefulCount': [41, 3, 0],\n",
       " 'review_length': [1, 1, 1]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_dataset[\"train\"].sort(\"review_length\")[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8dd0152c82a4756b58edf4bfcd9bcfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/160398 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c403be8b5ee548299a32ff53f9ca27c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/53471 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 138514, 'test': 46108}\n"
     ]
    }
   ],
   "source": [
    "drug_dataset = drug_dataset.filter(lambda x: x[\"review_length\"] > 30)\n",
    "print(drug_dataset.num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm a transformer called BERT\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import html\n",
    "\n",
    "text = \"I&#039;m a transformer called BERT\"\n",
    "html.unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb86c48b2de54a3ca8ecc6b1532116ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/138514 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30624bdffb2f4050973f22ecc4764131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/46108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drug_dataset = drug_dataset.map(lambda x: {\"review\": html.unescape(x[\"review\"])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8116d1fd37e54d6ebbf60585aae30807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/138514 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626245b2bc1e443d87f637c2fcafe6e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/46108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_drug_dataset = drug_dataset.map(\n",
    "    lambda x: {\"review\": [html.unescape(o) for o in x[\"review\"]]}, batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727cc993048b4fd5b3bba77a2abbc658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae53684a69f4d48acec91d1bae08f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6bfc5be41414e00935f929f710bbeae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581d552d3f0a4d55a2007d5132838c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"review\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2c8f663d464cbebcf8b4b696868f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/138514 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209ff8959e2048569a363bb4be943966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/46108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 38s\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%time tokenized_dataset = drug_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bdf73a284dd42898c1f68727ddee9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/138514 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'slow_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\multiprocess\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"c:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\utils\\py_utils.py\", line 678, in _write_generator_to_queue\n    for i, result in enumerate(func(**kwargs)):\n  File \"c:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py\", line 3446, in _map_single\n    example = apply_function_on_filtered_inputs(example, i, offset=offset)\n  File \"c:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py\", line 3338, in apply_function_on_filtered_inputs\n    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)\n  File \"C:\\Users\\reyri\\AppData\\Local\\Temp\\ipykernel_36096\\3279229777.py\", line 5, in slow_tokenize_function\nNameError: name 'slow_tokenizer' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslow_tokenize_function\u001b[39m(examples):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m slow_tokenizer(examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview\u001b[39m\u001b[38;5;124m\"\u001b[39m], truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 8\u001b[0m tokenized_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdrug_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslow_tokenize_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\dataset_dict.py:886\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m--> 886\u001b[0m     {\n\u001b[0;32m    887\u001b[0m         k: dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m    888\u001b[0m             function\u001b[38;5;241m=\u001b[39mfunction,\n\u001b[0;32m    889\u001b[0m             with_indices\u001b[38;5;241m=\u001b[39mwith_indices,\n\u001b[0;32m    890\u001b[0m             with_rank\u001b[38;5;241m=\u001b[39mwith_rank,\n\u001b[0;32m    891\u001b[0m             input_columns\u001b[38;5;241m=\u001b[39minput_columns,\n\u001b[0;32m    892\u001b[0m             batched\u001b[38;5;241m=\u001b[39mbatched,\n\u001b[0;32m    893\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    894\u001b[0m             drop_last_batch\u001b[38;5;241m=\u001b[39mdrop_last_batch,\n\u001b[0;32m    895\u001b[0m             remove_columns\u001b[38;5;241m=\u001b[39mremove_columns,\n\u001b[0;32m    896\u001b[0m             keep_in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory,\n\u001b[0;32m    897\u001b[0m             load_from_cache_file\u001b[38;5;241m=\u001b[39mload_from_cache_file,\n\u001b[0;32m    898\u001b[0m             cache_file_name\u001b[38;5;241m=\u001b[39mcache_file_names[k],\n\u001b[0;32m    899\u001b[0m             writer_batch_size\u001b[38;5;241m=\u001b[39mwriter_batch_size,\n\u001b[0;32m    900\u001b[0m             features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[0;32m    901\u001b[0m             disable_nullable\u001b[38;5;241m=\u001b[39mdisable_nullable,\n\u001b[0;32m    902\u001b[0m             fn_kwargs\u001b[38;5;241m=\u001b[39mfn_kwargs,\n\u001b[0;32m    903\u001b[0m             num_proc\u001b[38;5;241m=\u001b[39mnum_proc,\n\u001b[0;32m    904\u001b[0m             desc\u001b[38;5;241m=\u001b[39mdesc,\n\u001b[0;32m    905\u001b[0m         )\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    907\u001b[0m     }\n\u001b[0;32m    908\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\dataset_dict.py:887\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m    886\u001b[0m     {\n\u001b[1;32m--> 887\u001b[0m         k: \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    907\u001b[0m     }\n\u001b[0;32m    908\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    558\u001b[0m }\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3165\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3159\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpawning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m processes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3160\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3161\u001b[0m     unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3162\u001b[0m     total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3163\u001b[0m     desc\u001b[38;5;241m=\u001b[39m(desc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (num_proc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3164\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3165\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m iflatmap_unordered(\n\u001b[0;32m   3166\u001b[0m         pool, Dataset\u001b[38;5;241m.\u001b[39m_map_single, kwargs_iterable\u001b[38;5;241m=\u001b[39mkwargs_per_job\n\u001b[0;32m   3167\u001b[0m     ):\n\u001b[0;32m   3168\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m   3169\u001b[0m             shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\utils\\py_utils.py:718\u001b[0m, in \u001b[0;36miflatmap_unordered\u001b[1;34m(pool, func, kwargs_iterable)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[0;32m    717\u001b[0m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[1;32m--> 718\u001b[0m         [async_result\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m async_result \u001b[38;5;129;01min\u001b[39;00m async_results]\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\utils\\py_utils.py:718\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[0;32m    717\u001b[0m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n\u001b[1;32m--> 718\u001b[0m         [\u001b[43masync_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m async_result \u001b[38;5;129;01min\u001b[39;00m async_results]\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\multiprocess\\pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[1;31mNameError\u001b[0m: name 'slow_tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "slow_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", use_fast=False)\n",
    "\n",
    "\n",
    "def slow_tokenize_function(examples):\n",
    "    return slow_tokenizer(examples[\"review\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_dataset = drug_dataset.map(slow_tokenize_function, batched=False, num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_split(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"review\"],\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_overflowing_tokens=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128, 49]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = tokenize_and_split(drug_dataset[\"train\"][0])\n",
    "[len(inp) for inp in result[\"input_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c1aba8f3fa42d1a21bf00ae903240d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/138514 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ArrowInvalid",
     "evalue": "Column 8 named input_ids expected length 1000 but got length 1463",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenized_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdrug_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenize_and_split\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\dataset_dict.py:886\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m--> 886\u001b[0m     {\n\u001b[0;32m    887\u001b[0m         k: dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m    888\u001b[0m             function\u001b[38;5;241m=\u001b[39mfunction,\n\u001b[0;32m    889\u001b[0m             with_indices\u001b[38;5;241m=\u001b[39mwith_indices,\n\u001b[0;32m    890\u001b[0m             with_rank\u001b[38;5;241m=\u001b[39mwith_rank,\n\u001b[0;32m    891\u001b[0m             input_columns\u001b[38;5;241m=\u001b[39minput_columns,\n\u001b[0;32m    892\u001b[0m             batched\u001b[38;5;241m=\u001b[39mbatched,\n\u001b[0;32m    893\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m    894\u001b[0m             drop_last_batch\u001b[38;5;241m=\u001b[39mdrop_last_batch,\n\u001b[0;32m    895\u001b[0m             remove_columns\u001b[38;5;241m=\u001b[39mremove_columns,\n\u001b[0;32m    896\u001b[0m             keep_in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory,\n\u001b[0;32m    897\u001b[0m             load_from_cache_file\u001b[38;5;241m=\u001b[39mload_from_cache_file,\n\u001b[0;32m    898\u001b[0m             cache_file_name\u001b[38;5;241m=\u001b[39mcache_file_names[k],\n\u001b[0;32m    899\u001b[0m             writer_batch_size\u001b[38;5;241m=\u001b[39mwriter_batch_size,\n\u001b[0;32m    900\u001b[0m             features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[0;32m    901\u001b[0m             disable_nullable\u001b[38;5;241m=\u001b[39mdisable_nullable,\n\u001b[0;32m    902\u001b[0m             fn_kwargs\u001b[38;5;241m=\u001b[39mfn_kwargs,\n\u001b[0;32m    903\u001b[0m             num_proc\u001b[38;5;241m=\u001b[39mnum_proc,\n\u001b[0;32m    904\u001b[0m             desc\u001b[38;5;241m=\u001b[39mdesc,\n\u001b[0;32m    905\u001b[0m         )\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    907\u001b[0m     }\n\u001b[0;32m    908\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\dataset_dict.py:887\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m    886\u001b[0m     {\n\u001b[1;32m--> 887\u001b[0m         k: \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    907\u001b[0m     }\n\u001b[0;32m    908\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    558\u001b[0m }\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3073\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3068\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3069\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3070\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3071\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3072\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3073\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3074\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m   3075\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3499\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3497\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwrite_table(batch\u001b[38;5;241m.\u001b[39mto_arrow())\n\u001b[0;32m   3498\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3499\u001b[0m         \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3500\u001b[0m num_examples_progress_update \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num_examples_in_batch\n\u001b[0;32m   3501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m _time \u001b[38;5;241m+\u001b[39m config\u001b[38;5;241m.\u001b[39mPBAR_REFRESH_TIME_INTERVAL:\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_writer.py:608\u001b[0m, in \u001b[0;36mArrowWriter.write_batch\u001b[1;34m(self, batch_examples, writer_batch_size)\u001b[0m\n\u001b[0;32m    606\u001b[0m         inferred_features[col] \u001b[38;5;241m=\u001b[39m typed_sequence\u001b[38;5;241m.\u001b[39mget_inferred_type()\n\u001b[0;32m    607\u001b[0m schema \u001b[38;5;241m=\u001b[39m inferred_features\u001b[38;5;241m.\u001b[39marrow_schema \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpa_writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema\n\u001b[1;32m--> 608\u001b[0m pa_table \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_table(pa_table, writer_batch_size)\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyarrow\\table.pxi:4868\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_arrays\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyarrow\\table.pxi:4214\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.validate\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyarrow\\error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowInvalid\u001b[0m: Column 8 named input_ids expected length 1000 but got length 1463"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a6bf7060b340548ae1cb91b42e645e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/138514 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b87c6e8f3540759faa9c1bf744aef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/46108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = drug_dataset.map(\n",
    "    tokenize_and_split, batched=True, remove_columns=drug_dataset[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206772, 138514)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_dataset[\"train\"]), len(drug_dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_split(examples):\n",
    "    result = tokenizer(\n",
    "        examples[\"review\"],\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_overflowing_tokens=True,\n",
    "    )\n",
    "    # Extract mapping between new and old indices\n",
    "    sample_map = result.pop(\"overflow_to_sample_mapping\")\n",
    "    for key, values in examples.items():\n",
    "        result[key] = [values[i] for i in sample_map]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c718ae2733b647bd9cf21b0b3c99ad55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/138514 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece01d0be3464cdc8af7103b2b40f63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/46108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 206772\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 68876\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = drug_dataset.map(tokenize_and_split, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_dataset.set_format(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>adhd</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>April 27, 2010</td>\n",
       "      <td>192</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>birth control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>December 14, 2009</td>\n",
       "      <td>17</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138000</td>\n",
       "      <td>Ortho Evra</td>\n",
       "      <td>birth control</td>\n",
       "      <td>\"This is my first time using any form of birth...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>November 3, 2015</td>\n",
       "      <td>10</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id    drugName      condition  \\\n",
       "0       95260  Guanfacine           adhd   \n",
       "1       92703      Lybrel  birth control   \n",
       "2      138000  Ortho Evra  birth control   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  \"My son is halfway through his fourth week of ...     8.0   \n",
       "1  \"I used to take another oral contraceptive, wh...     5.0   \n",
       "2  \"This is my first time using any form of birth...     8.0   \n",
       "\n",
       "                date  usefulCount  review_length  \n",
       "0     April 27, 2010          192            141  \n",
       "1  December 14, 2009           17            134  \n",
       "2   November 3, 2015           10             89  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_dataset[\"train\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = drug_dataset[\"train\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>birth control</td>\n",
       "      <td>27655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>depression</td>\n",
       "      <td>8023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acne</td>\n",
       "      <td>5209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>4991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pain</td>\n",
       "      <td>4744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       frequency  count\n",
       "0  birth control  27655\n",
       "1     depression   8023\n",
       "2           acne   5209\n",
       "3        anxiety   4991\n",
       "4           pain   4744"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies = (\n",
    "    train_df[\"condition\"]\n",
    "    .value_counts()\n",
    "    .to_frame()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"condition\", \"condition\": \"frequency\"})\n",
    ")\n",
    "frequencies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>birth control</td>\n",
       "      <td>27655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>depression</td>\n",
       "      <td>8023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acne</td>\n",
       "      <td>5209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>4991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pain</td>\n",
       "      <td>4744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       frequency  count\n",
       "0  birth control  27655\n",
       "1     depression   8023\n",
       "2           acne   5209\n",
       "3        anxiety   4991\n",
       "4           pain   4744"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies = (\n",
    "    train_df[\"condition\"]\n",
    "    .value_counts()\n",
    "    .to_frame()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"condition\", \"condition\": \"frequency\"})\n",
    ")\n",
    "frequencies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],\n",
       "        num_rows: 110811\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],\n",
       "        num_rows: 27703\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],\n",
       "        num_rows: 46108\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drug_dataset_clean = drug_dataset[\"train\"].train_test_split(train_size=0.8, seed=42)\n",
    "# Rename the default \"test\" split to \"validation\"\n",
    "drug_dataset_clean[\"validation\"] = drug_dataset_clean.pop(\"test\")\n",
    "# Add the \"test\" set to our `DatasetDict`\n",
    "drug_dataset_clean[\"test\"] = drug_dataset[\"test\"]\n",
    "drug_dataset_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe7adc349bd472b9a3decfe71e8eb17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/110811 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6aaaa153dc34794ac421ce3cf4acab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/27703 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6003b7eeeda4008bc5e97e867a23023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/46108 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "drug_dataset_clean.save_to_disk(\"drug-reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],\n",
       "        num_rows: 110811\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],\n",
       "        num_rows: 27703\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'review_length'],\n",
       "        num_rows: 46108\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "drug_dataset_reloaded = load_from_disk(\"drug-reviews\")\n",
    "drug_dataset_reloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3ae4b501a84a05b7a58cf543dbae6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/111 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a8fc09ab734709bfeb877df2c37ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/28 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620b676f98834fae87997ead80718608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/47 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for split, dataset in drug_dataset_clean.items():\n",
    "    dataset.to_json(f\"drug-reviews-{split}.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'head' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 drug-reviews-train.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc01b68d7b544564ac040aa5158cdf14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201a6c06d86c41f597d8bbda80969500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef4b9f496c8482497662cdd48027bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_files = {\n",
    "    \"train\": \"drug-reviews-train.jsonl\",\n",
    "    \"validation\": \"drug-reviews-validation.jsonl\",\n",
    "    \"test\": \"drug-reviews-test.jsonl\",\n",
    "}\n",
    "drug_dataset_reloaded = load_dataset(\"json\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big data? 🤗 Datasets to the rescue!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting zstandard\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-win_amd64.whl.metadata (3.0 kB)\n",
      "Downloading zstandard-0.23.0-cp310-cp310-win_amd64.whl (495 kB)\n",
      "Installing collected packages: zstandard\n",
      "Successfully installed zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install zstandard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Unable to find 'https://the-eye.eu/public/AI/pile_preliminary_components/PUBMED_title_abstracts_2019_baseline.jsonl.zst'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# This takes a few minutes to run, so go grab a tea or coffee while you wait :)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m data_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://the-eye.eu/public/AI/pile_preliminary_components/PUBMED_title_abstracts_2019_baseline.jsonl.zst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m pubmed_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m pubmed_dataset\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\load.py:2129\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[0;32m   2124\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[0;32m   2125\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[0;32m   2126\u001b[0m )\n\u001b[0;32m   2128\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[1;32m-> 2129\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m load_dataset_builder(\n\u001b[0;32m   2130\u001b[0m     path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m   2131\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   2132\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[0;32m   2133\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[0;32m   2134\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   2135\u001b[0m     features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[0;32m   2136\u001b[0m     download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[0;32m   2137\u001b[0m     download_mode\u001b[38;5;241m=\u001b[39mdownload_mode,\n\u001b[0;32m   2138\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   2139\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   2140\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   2141\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[0;32m   2142\u001b[0m     _require_default_config_name\u001b[38;5;241m=\u001b[39mname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2143\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_kwargs,\n\u001b[0;32m   2144\u001b[0m )\n\u001b[0;32m   2146\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[0;32m   2147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\load.py:1849\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[1;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[0;32m   1847\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[0;32m   1848\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[1;32m-> 1849\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1853\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_custom_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[0;32m   1862\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\load.py:1564\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;66;03m# We have several ways to get a dataset builder:\u001b[39;00m\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;66;03m# - if path is the name of a packaged dataset module\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1555\u001b[0m \n\u001b[0;32m   1556\u001b[0m \u001b[38;5;66;03m# Try packaged\u001b[39;00m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m _PACKAGED_DATASETS_MODULES:\n\u001b[0;32m   1558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPackagedDatasetModuleFactory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 1564\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;66;03m# Try locally\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mendswith(filename):\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\load.py:944\u001b[0m, in \u001b[0;36mPackagedDatasetModuleFactory.get_module\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m base_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexpanduser()\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mas_posix()\n\u001b[0;32m    939\u001b[0m patterns \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    940\u001b[0m     sanitize_patterns(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_files)\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_files \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    942\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m get_data_patterns(base_path, download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config)\n\u001b[0;32m    943\u001b[0m )\n\u001b[1;32m--> 944\u001b[0m data_files \u001b[38;5;241m=\u001b[39m \u001b[43mDataFilesDict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    949\u001b[0m supports_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m _MODULE_SUPPORTS_METADATA\n\u001b[0;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_files \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m supports_metadata \u001b[38;5;129;01mand\u001b[39;00m patterns \u001b[38;5;241m!=\u001b[39m DEFAULT_PATTERNS_ALL:\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\data_files.py:721\u001b[0m, in \u001b[0;36mDataFilesDict.from_patterns\u001b[1;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[0;32m    716\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m()\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, patterns_for_key \u001b[38;5;129;01min\u001b[39;00m patterns\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    718\u001b[0m     out[key] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    719\u001b[0m         patterns_for_key\n\u001b[0;32m    720\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(patterns_for_key, DataFilesList)\n\u001b[1;32m--> 721\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mDataFilesList\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatterns_for_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    727\u001b[0m     )\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\data_files.py:624\u001b[0m, in \u001b[0;36mDataFilesList.from_patterns\u001b[1;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m patterns:\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m         data_files\u001b[38;5;241m.\u001b[39mextend(\n\u001b[1;32m--> 624\u001b[0m             \u001b[43mresolve_pattern\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m                \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m         )\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_magic(pattern):\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\data_files.py:411\u001b[0m, in \u001b[0;36mresolve_pattern\u001b[1;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allowed_extensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m         error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with any supported extension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(allowed_extensions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 411\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(error_msg)\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Unable to find 'https://the-eye.eu/public/AI/pile_preliminary_components/PUBMED_title_abstracts_2019_baseline.jsonl.zst'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# This takes a few minutes to run, so go grab a tea or coffee while you wait :)\n",
    "data_files = \"https://the-eye.eu/public/AI/pile_preliminary_components/PUBMED_title_abstracts_2019_baseline.jsonl.zst\"\n",
    "pubmed_dataset = load_dataset(\"json\", data_files=data_files, split=\"train\")\n",
    "pubmed_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating your own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\reyri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\reyri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\reyri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\reyri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\reyri\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.github.com/repos/huggingface/datasets/issues?page=1&per_page=1\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://api.github.com/repos/huggingface/datasets/issues/7353',\n",
       "  'repository_url': 'https://api.github.com/repos/huggingface/datasets',\n",
       "  'labels_url': 'https://api.github.com/repos/huggingface/datasets/issues/7353/labels{/name}',\n",
       "  'comments_url': 'https://api.github.com/repos/huggingface/datasets/issues/7353/comments',\n",
       "  'events_url': 'https://api.github.com/repos/huggingface/datasets/issues/7353/events',\n",
       "  'html_url': 'https://github.com/huggingface/datasets/pull/7353',\n",
       "  'id': 2768484726,\n",
       "  'node_id': 'PR_kwDODunzps6Gtd6K',\n",
       "  'number': 7353,\n",
       "  'title': 'changes to MappedExamplesIterable to resolve #7345',\n",
       "  'user': {'login': 'vttrifonov',\n",
       "   'id': 12157034,\n",
       "   'node_id': 'MDQ6VXNlcjEyMTU3MDM0',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/12157034?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/vttrifonov',\n",
       "   'html_url': 'https://github.com/vttrifonov',\n",
       "   'followers_url': 'https://api.github.com/users/vttrifonov/followers',\n",
       "   'following_url': 'https://api.github.com/users/vttrifonov/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/vttrifonov/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/vttrifonov/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/vttrifonov/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/vttrifonov/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/vttrifonov/repos',\n",
       "   'events_url': 'https://api.github.com/users/vttrifonov/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/vttrifonov/received_events',\n",
       "   'type': 'User',\n",
       "   'user_view_type': 'public',\n",
       "   'site_admin': False},\n",
       "  'labels': [],\n",
       "  'state': 'open',\n",
       "  'locked': False,\n",
       "  'assignee': None,\n",
       "  'assignees': [],\n",
       "  'milestone': None,\n",
       "  'comments': 0,\n",
       "  'created_at': '2025-01-04T06:01:15Z',\n",
       "  'updated_at': '2025-01-04T06:02:51Z',\n",
       "  'closed_at': None,\n",
       "  'author_association': 'NONE',\n",
       "  'active_lock_reason': None,\n",
       "  'draft': False,\n",
       "  'pull_request': {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/7353',\n",
       "   'html_url': 'https://github.com/huggingface/datasets/pull/7353',\n",
       "   'diff_url': 'https://github.com/huggingface/datasets/pull/7353.diff',\n",
       "   'patch_url': 'https://github.com/huggingface/datasets/pull/7353.patch',\n",
       "   'merged_at': None},\n",
       "  'body': 'modified `MappedExamplesIterable` and `test_iterable_dataset.py::test_mapped_examples_iterable_with_indices`\\r\\n\\r\\n@lhoestq ',\n",
       "  'closed_by': None,\n",
       "  'reactions': {'url': 'https://api.github.com/repos/huggingface/datasets/issues/7353/reactions',\n",
       "   'total_count': 0,\n",
       "   '+1': 0,\n",
       "   '-1': 0,\n",
       "   'laugh': 0,\n",
       "   'hooray': 0,\n",
       "   'confused': 0,\n",
       "   'heart': 0,\n",
       "   'rocket': 0,\n",
       "   'eyes': 0},\n",
       "  'timeline_url': 'https://api.github.com/repos/huggingface/datasets/issues/7353/timeline',\n",
       "  'performed_via_github_app': None,\n",
       "  'state_reason': None}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_TOKEN = \"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\"  # Copy your GitHub token here\n",
    "headers = {\"Authorization\": f\"token {GITHUB_TOKEN}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def fetch_issues(\n",
    "    owner=\"huggingface\",\n",
    "    repo=\"datasets\",\n",
    "    num_issues=10_000,\n",
    "    rate_limit=5_000,\n",
    "    issues_path=Path(\".\"),\n",
    "):\n",
    "    if not issues_path.is_dir():\n",
    "        issues_path.mkdir(exist_ok=True)\n",
    "\n",
    "    batch = []\n",
    "    all_issues = []\n",
    "    per_page = 100  # Number of issues to return per page\n",
    "    num_pages = math.ceil(num_issues / per_page)\n",
    "    base_url = \"https://api.github.com/repos\"\n",
    "\n",
    "    for page in tqdm(range(num_pages)):\n",
    "        # Query with state=all to get both open and closed issues\n",
    "        query = f\"issues?page={page}&per_page={per_page}&state=all\"\n",
    "        issues = requests.get(f\"{base_url}/{owner}/{repo}/{query}\", headers=headers)\n",
    "        batch.extend(issues.json())\n",
    "\n",
    "        if len(batch) > rate_limit and len(all_issues) < num_issues:\n",
    "            all_issues.extend(batch)\n",
    "            batch = []  # Flush batch for next time period\n",
    "            print(f\"Reached GitHub rate limit. Sleeping for one hour ...\")\n",
    "            time.sleep(60 * 60 + 1)\n",
    "\n",
    "    all_issues.extend(batch)\n",
    "    df = pd.DataFrame.from_records(all_issues)\n",
    "    df.to_json(f\"{issues_path}/{repo}-issues.jsonl\", orient=\"records\", lines=True)\n",
    "    print(\n",
    "        f\"Downloaded all the issues for {repo}! Dataset stored at {issues_path}/{repo}-issues.jsonl\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc1b91ed6da42f5bf1dad6720da381a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached GitHub rate limit. Sleeping for one hour ...\n"
     ]
    }
   ],
   "source": [
    "# Depending on your internet connection, this can take several minutes to run...\n",
    "fetch_issues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Unable to find 'D:/Kuliah/Semester 7/Machine learning/MachineLearningTasks/UAS\\datasets-issues.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Muat dataset dari file JSONL\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m issues_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatasets-issues.jsonl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(issues_dataset)\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\load.py:2129\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[0;32m   2124\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[0;32m   2125\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[0;32m   2126\u001b[0m )\n\u001b[0;32m   2128\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[1;32m-> 2129\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m load_dataset_builder(\n\u001b[0;32m   2130\u001b[0m     path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m   2131\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   2132\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[0;32m   2133\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[0;32m   2134\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   2135\u001b[0m     features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[0;32m   2136\u001b[0m     download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[0;32m   2137\u001b[0m     download_mode\u001b[38;5;241m=\u001b[39mdownload_mode,\n\u001b[0;32m   2138\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   2139\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   2140\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   2141\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[0;32m   2142\u001b[0m     _require_default_config_name\u001b[38;5;241m=\u001b[39mname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2143\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_kwargs,\n\u001b[0;32m   2144\u001b[0m )\n\u001b[0;32m   2146\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[0;32m   2147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\load.py:1849\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[1;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[0;32m   1847\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[0;32m   1848\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[1;32m-> 1849\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1853\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1858\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_custom_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[0;32m   1862\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\load.py:1564\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[0;32m   1541\u001b[0m \u001b[38;5;66;03m# We have several ways to get a dataset builder:\u001b[39;00m\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;66;03m# - if path is the name of a packaged dataset module\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1555\u001b[0m \n\u001b[0;32m   1556\u001b[0m \u001b[38;5;66;03m# Try packaged\u001b[39;00m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m _PACKAGED_DATASETS_MODULES:\n\u001b[0;32m   1558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPackagedDatasetModuleFactory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 1564\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;66;03m# Try locally\u001b[39;00m\n\u001b[0;32m   1566\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path\u001b[38;5;241m.\u001b[39mendswith(filename):\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\load.py:944\u001b[0m, in \u001b[0;36mPackagedDatasetModuleFactory.get_module\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m base_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexpanduser()\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;241m.\u001b[39mas_posix()\n\u001b[0;32m    939\u001b[0m patterns \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    940\u001b[0m     sanitize_patterns(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_files)\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_files \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    942\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m get_data_patterns(base_path, download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config)\n\u001b[0;32m    943\u001b[0m )\n\u001b[1;32m--> 944\u001b[0m data_files \u001b[38;5;241m=\u001b[39m \u001b[43mDataFilesDict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatterns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    947\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    949\u001b[0m supports_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m _MODULE_SUPPORTS_METADATA\n\u001b[0;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_files \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m supports_metadata \u001b[38;5;129;01mand\u001b[39;00m patterns \u001b[38;5;241m!=\u001b[39m DEFAULT_PATTERNS_ALL:\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\data_files.py:721\u001b[0m, in \u001b[0;36mDataFilesDict.from_patterns\u001b[1;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[0;32m    716\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m()\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, patterns_for_key \u001b[38;5;129;01min\u001b[39;00m patterns\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    718\u001b[0m     out[key] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    719\u001b[0m         patterns_for_key\n\u001b[0;32m    720\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(patterns_for_key, DataFilesList)\n\u001b[1;32m--> 721\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mDataFilesList\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_patterns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatterns_for_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    727\u001b[0m     )\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\data_files.py:624\u001b[0m, in \u001b[0;36mDataFilesList.from_patterns\u001b[1;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m patterns:\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m         data_files\u001b[38;5;241m.\u001b[39mextend(\n\u001b[1;32m--> 624\u001b[0m             \u001b[43mresolve_pattern\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m                \u001b[49m\u001b[43mallowed_extensions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_extensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m         )\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_magic(pattern):\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\data_files.py:411\u001b[0m, in \u001b[0;36mresolve_pattern\u001b[1;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allowed_extensions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m         error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with any supported extension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(allowed_extensions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 411\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(error_msg)\n\u001b[0;32m    412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Unable to find 'D:/Kuliah/Semester 7/Machine learning/MachineLearningTasks/UAS\\datasets-issues.jsonl'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Muat dataset dari file JSONL\n",
    "issues_dataset = load_dataset(\"json\", data_files=\"datasets-issues.jsonl\", split=\"train\")\n",
    "print(issues_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'issues_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[43missues_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mshuffle(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m666\u001b[39m)\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Print out the URL and pull request entries\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url, pr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml_url\u001b[39m\u001b[38;5;124m\"\u001b[39m], sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpull_request\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'issues_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "sample = issues_dataset.shuffle(seed=666).select(range(3))\n",
    "\n",
    "# Print out the URL and pull request entries\n",
    "for url, pr in zip(sample[\"html_url\"], sample[\"pull_request\"]):\n",
    "    print(f\">> URL: {url}\")\n",
    "    print(f\">> Pull request: {pr}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2324478403.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    >> URL: https://github.com/huggingface/datasets/pull/850\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    ">> URL: https://github.com/huggingface/datasets/pull/850\n",
    ">> Pull request: {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/850', 'html_url': 'https://github.com/huggingface/datasets/pull/850', 'diff_url': 'https://github.com/huggingface/datasets/pull/850.diff', 'patch_url': 'https://github.com/huggingface/datasets/pull/850.patch'}\n",
    "\n",
    ">> URL: https://github.com/huggingface/datasets/issues/2773\n",
    ">> Pull request: None\n",
    "\n",
    ">> URL: https://github.com/huggingface/datasets/pull/783\n",
    ">> Pull request: {'url': 'https://api.github.com/repos/huggingface/datasets/pulls/783', 'html_url': 'https://github.com/huggingface/datasets/pull/783', 'diff_url': 'https://github.com/huggingface/datasets/pull/783.diff', 'patch_url': 'https://github.com/huggingface/datasets/pull/783.patch'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'issues_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m issues_dataset \u001b[38;5;241m=\u001b[39m \u001b[43missues_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_pull_request\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpull_request\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[0;32m      3\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'issues_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "issues_dataset = issues_dataset.map(\n",
    "    lambda x: {\"is_pull_request\": False if x[\"pull_request\"] is None else True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://api.github.com/repos/huggingface/datasets/issues/comments/897594128',\n",
       "  'html_url': 'https://github.com/huggingface/datasets/pull/2792#issuecomment-897594128',\n",
       "  'issue_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792',\n",
       "  'id': 897594128,\n",
       "  'node_id': 'IC_kwDODunzps41gDMQ',\n",
       "  'user': {'login': 'bhavitvyamalik',\n",
       "   'id': 19718818,\n",
       "   'node_id': 'MDQ6VXNlcjE5NzE4ODE4',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/19718818?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/bhavitvyamalik',\n",
       "   'html_url': 'https://github.com/bhavitvyamalik',\n",
       "   'followers_url': 'https://api.github.com/users/bhavitvyamalik/followers',\n",
       "   'following_url': 'https://api.github.com/users/bhavitvyamalik/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/bhavitvyamalik/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/bhavitvyamalik/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/bhavitvyamalik/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/bhavitvyamalik/repos',\n",
       "   'events_url': 'https://api.github.com/users/bhavitvyamalik/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/bhavitvyamalik/received_events',\n",
       "   'type': 'User',\n",
       "   'user_view_type': 'public',\n",
       "   'site_admin': False},\n",
       "  'created_at': '2021-08-12T12:21:52Z',\n",
       "  'updated_at': '2021-08-12T12:31:17Z',\n",
       "  'author_association': 'CONTRIBUTOR',\n",
       "  'body': \"@albertvillanova my tests are failing here:\\r\\n```\\r\\ndataset_name = 'gooaq'\\r\\n\\r\\n    def test_load_dataset(self, dataset_name):\\r\\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\\r\\n>       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\\r\\n\\r\\ntests/test_dataset_common.py:234: \\r\\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\r\\ntests/test_dataset_common.py:187: in check_load_dataset\\r\\n    self.parent.assertTrue(len(dataset[split]) > 0)\\r\\nE   AssertionError: False is not true\\r\\n```\\r\\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?\",\n",
       "  'reactions': {'url': 'https://api.github.com/repos/huggingface/datasets/issues/comments/897594128/reactions',\n",
       "   'total_count': 0,\n",
       "   '+1': 0,\n",
       "   '-1': 0,\n",
       "   'laugh': 0,\n",
       "   'hooray': 0,\n",
       "   'confused': 0,\n",
       "   'heart': 0,\n",
       "   'rocket': 0,\n",
       "   'eyes': 0},\n",
       "  'performed_via_github_app': None},\n",
       " {'url': 'https://api.github.com/repos/huggingface/datasets/issues/comments/898644889',\n",
       "  'html_url': 'https://github.com/huggingface/datasets/pull/2792#issuecomment-898644889',\n",
       "  'issue_url': 'https://api.github.com/repos/huggingface/datasets/issues/2792',\n",
       "  'id': 898644889,\n",
       "  'node_id': 'IC_kwDODunzps41kDuZ',\n",
       "  'user': {'login': 'bhavitvyamalik',\n",
       "   'id': 19718818,\n",
       "   'node_id': 'MDQ6VXNlcjE5NzE4ODE4',\n",
       "   'avatar_url': 'https://avatars.githubusercontent.com/u/19718818?v=4',\n",
       "   'gravatar_id': '',\n",
       "   'url': 'https://api.github.com/users/bhavitvyamalik',\n",
       "   'html_url': 'https://github.com/bhavitvyamalik',\n",
       "   'followers_url': 'https://api.github.com/users/bhavitvyamalik/followers',\n",
       "   'following_url': 'https://api.github.com/users/bhavitvyamalik/following{/other_user}',\n",
       "   'gists_url': 'https://api.github.com/users/bhavitvyamalik/gists{/gist_id}',\n",
       "   'starred_url': 'https://api.github.com/users/bhavitvyamalik/starred{/owner}{/repo}',\n",
       "   'subscriptions_url': 'https://api.github.com/users/bhavitvyamalik/subscriptions',\n",
       "   'organizations_url': 'https://api.github.com/users/bhavitvyamalik/orgs',\n",
       "   'repos_url': 'https://api.github.com/users/bhavitvyamalik/repos',\n",
       "   'events_url': 'https://api.github.com/users/bhavitvyamalik/events{/privacy}',\n",
       "   'received_events_url': 'https://api.github.com/users/bhavitvyamalik/received_events',\n",
       "   'type': 'User',\n",
       "   'user_view_type': 'public',\n",
       "   'site_admin': False},\n",
       "  'created_at': '2021-08-13T18:28:27Z',\n",
       "  'updated_at': '2021-08-13T18:28:27Z',\n",
       "  'author_association': 'CONTRIBUTOR',\n",
       "  'body': 'Thanks for the help, @albertvillanova! All tests are passing now.',\n",
       "  'reactions': {'url': 'https://api.github.com/repos/huggingface/datasets/issues/comments/898644889/reactions',\n",
       "   'total_count': 0,\n",
       "   '+1': 0,\n",
       "   '-1': 0,\n",
       "   'laugh': 0,\n",
       "   'hooray': 0,\n",
       "   'confused': 0,\n",
       "   'heart': 0,\n",
       "   'rocket': 0,\n",
       "   'eyes': 0},\n",
       "  'performed_via_github_app': None}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issue_number = 2792\n",
    "url = f\"https://api.github.com/repos/huggingface/datasets/issues/{issue_number}/comments\"\n",
    "response = requests.get(url, headers=headers)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"@albertvillanova my tests are failing here:\\r\\n```\\r\\ndataset_name = 'gooaq'\\r\\n\\r\\n    def test_load_dataset(self, dataset_name):\\r\\n        configs = self.dataset_tester.load_all_configs(dataset_name, is_local=True)[:1]\\r\\n>       self.dataset_tester.check_load_dataset(dataset_name, configs, is_local=True, use_local_dummy_data=True)\\r\\n\\r\\ntests/test_dataset_common.py:234: \\r\\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \\r\\ntests/test_dataset_common.py:187: in check_load_dataset\\r\\n    self.parent.assertTrue(len(dataset[split]) > 0)\\r\\nE   AssertionError: False is not true\\r\\n```\\r\\nWhen I try loading dataset on local machine it works fine. Any suggestions on how can I avoid this error?\",\n",
       " 'Thanks for the help, @albertvillanova! All tests are passing now.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_comments(issue_number):\n",
    "    url = f\"https://api.github.com/repos/huggingface/datasets/issues/{issue_number}/comments\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return [r[\"body\"] for r in response.json()]\n",
    "\n",
    "\n",
    "# Test our function works as expected\n",
    "get_comments(2792)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'issues_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Depending on your internet connection, this can take a few minutes...\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m issues_with_comments_dataset \u001b[38;5;241m=\u001b[39m \u001b[43missues_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomments\u001b[39m\u001b[38;5;124m\"\u001b[39m: get_comments(x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m\"\u001b[39m])}\n\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'issues_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Depending on your internet connection, this can take a few minutes...\n",
    "issues_with_comments_dataset = issues_dataset.map(\n",
    "    lambda x: {\"comments\": get_comments(x[\"number\"])}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic search with FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc2c025104e4f72953786a67062ccee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "419e2e2d20634ae4ba3c138419a0d8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "datasets-issues-with-comments.jsonl:   0%|          | 0.00/12.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad3cc744eb4b44b4bfce23917780e2b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3019 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'pull_request', 'body', 'timeline_url', 'performed_via_github_app', 'is_pull_request'],\n",
       "    num_rows: 3019\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "issues_dataset = load_dataset(\"lewtun/github-issues\", split=\"train\")\n",
    "issues_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mDataset\u001b[49m({\n\u001b[0;32m      2\u001b[0m     features: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepository_url\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels_url\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomments_url\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevents_url\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml_url\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnode_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocked\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124massignee\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124massignees\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmilestone\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomments\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreated_at\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdated_at\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclosed_at\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor_association\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactive_lock_reason\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpull_request\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperformed_via_github_app\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_pull_request\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      3\u001b[0m     num_rows: \u001b[38;5;241m2855\u001b[39m\n\u001b[0;32m      4\u001b[0m })\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "Dataset({\n",
    "    features: ['url', 'repository_url', 'labels_url', 'comments_url', 'events_url', 'html_url', 'id', 'node_id', 'number', 'title', 'user', 'labels', 'state', 'locked', 'assignee', 'assignees', 'milestone', 'comments', 'created_at', 'updated_at', 'closed_at', 'author_association', 'active_lock_reason', 'pull_request', 'body', 'performed_via_github_app', 'is_pull_request'],\n",
    "    num_rows: 2855\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_dataset = issues_dataset.filter(\n",
    "    lambda x: (x[\"is_pull_request\"] == False and len(x[\"comments\"]) > 0)\n",
    ")\n",
    "issues_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['html_url', 'title', 'comments', 'body'],\n",
       "    num_rows: 3019\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = issues_dataset.column_names\n",
    "columns_to_keep = [\"title\", \"body\", \"html_url\", \"comments\"]\n",
    "columns_to_remove = set(columns_to_keep).symmetric_difference(columns)\n",
    "issues_dataset = issues_dataset.remove_columns(columns_to_remove)\n",
    "issues_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_dataset.set_format(\"pandas\")\n",
    "df = issues_dataset[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"comments\"][0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>html_url</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://github.com/huggingface/datasets/pull/2955</td>\n",
       "      <td>Update legacy Python image for CI tests in Linux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Instead of legacy, use next-generation conveni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://github.com/huggingface/datasets/pull/2954</td>\n",
       "      <td>Run tests in parallel</td>\n",
       "      <td>There is a speed up in Windows machines:\\r\\n- ...</td>\n",
       "      <td>Run CI tests in parallel to speed up the test ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://github.com/huggingface/datasets/pull/2954</td>\n",
       "      <td>Run tests in parallel</td>\n",
       "      <td>There is also a speed up in Linux machines:\\r\\...</td>\n",
       "      <td>Run CI tests in parallel to speed up the test ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://github.com/huggingface/datasets/pull/2952</td>\n",
       "      <td>Fix missing conda deps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>`aiohttp` was added as a dependency in #2662 b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            html_url  \\\n",
       "0  https://github.com/huggingface/datasets/pull/2955   \n",
       "1  https://github.com/huggingface/datasets/pull/2954   \n",
       "2  https://github.com/huggingface/datasets/pull/2954   \n",
       "3  https://github.com/huggingface/datasets/pull/2952   \n",
       "\n",
       "                                              title  \\\n",
       "0  Update legacy Python image for CI tests in Linux   \n",
       "1                             Run tests in parallel   \n",
       "2                             Run tests in parallel   \n",
       "3                            Fix missing conda deps   \n",
       "\n",
       "                                            comments  \\\n",
       "0                                                NaN   \n",
       "1  There is a speed up in Windows machines:\\r\\n- ...   \n",
       "2  There is also a speed up in Linux machines:\\r\\...   \n",
       "3                                                NaN   \n",
       "\n",
       "                                                body  \n",
       "0  Instead of legacy, use next-generation conveni...  \n",
       "1  Run CI tests in parallel to speed up the test ...  \n",
       "2  Run CI tests in parallel to speed up the test ...  \n",
       "3  `aiohttp` was added as a dependency in #2662 b...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df = df.explode(\"comments\", ignore_index=True)\n",
    "comments_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['html_url', 'title', 'comments', 'body'],\n",
       "    num_rows: 7238\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "comments_dataset = Dataset.from_pandas(comments_df)\n",
    "comments_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e21abe1baa49a6bbb076923ec1cef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7238 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m comments_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcomments_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomment_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    558\u001b[0m }\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3073\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3068\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3069\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3070\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3071\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3072\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3073\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3074\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m   3075\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3446\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3444\u001b[0m _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   3445\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[1;32m-> 3446\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m update_data:\n\u001b[0;32m   3448\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3338\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[0;32m   3337\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[1;32m-> 3338\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m function(\u001b[38;5;241m*\u001b[39mfn_args, \u001b[38;5;241m*\u001b[39madditional_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_kwargs)\n\u001b[0;32m   3339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[0;32m   3340\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3341\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[0;32m   3342\u001b[0m     }\n",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m comments_dataset \u001b[38;5;241m=\u001b[39m comments_dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomment_length\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mlen\u001b[39m(\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m())}\n\u001b[0;32m      3\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "comments_dataset = comments_dataset.map(\n",
    "    lambda x: {\"comment_length\": len(x[\"comments\"].split())}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f771fd12f0234c4787e9c9a6342ff2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7238 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'comment_length'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m comments_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcomments_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomment_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m comments_dataset\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    558\u001b[0m }\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\fingerprint.py:442\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    438\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[0;32m    440\u001b[0m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m out \u001b[38;5;241m=\u001b[39m func(dataset, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    444\u001b[0m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3688\u001b[0m, in \u001b[0;36mDataset.filter\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   3686\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m-> 3688\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_indices_from_mask_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3695\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3696\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3697\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mValue\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muint64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3702\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3703\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3710\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuffix_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3712\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFilter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3715\u001b[0m new_dataset \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   3716\u001b[0m new_dataset\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    558\u001b[0m }\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3073\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3068\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3069\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3070\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3071\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3072\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3073\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3074\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m   3075\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3476\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3472\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   3473\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[0;32m   3474\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[0;32m   3475\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3476\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3480\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3481\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3482\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[0;32m   3483\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[0;32m   3484\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3485\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3338\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[0;32m   3337\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[1;32m-> 3338\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m function(\u001b[38;5;241m*\u001b[39mfn_args, \u001b[38;5;241m*\u001b[39madditional_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_kwargs)\n\u001b[0;32m   3339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[0;32m   3340\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3341\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[0;32m   3342\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:6327\u001b[0m, in \u001b[0;36mget_indices_from_mask_function\u001b[1;34m(function, batched, with_indices, with_rank, input_columns, indices_mapping, *args, **fn_kwargs)\u001b[0m\n\u001b[0;32m   6325\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[0;32m   6326\u001b[0m             additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[1;32m-> 6327\u001b[0m         mask\u001b[38;5;241m.\u001b[39mappend(function(example, \u001b[38;5;241m*\u001b[39madditional_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_kwargs))\n\u001b[0;32m   6328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6329\u001b[0m     \u001b[38;5;66;03m# inputs is a list of columns\u001b[39;00m\n\u001b[0;32m   6330\u001b[0m     columns: List[List] \u001b[38;5;241m=\u001b[39m inputs\n",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m comments_dataset \u001b[38;5;241m=\u001b[39m comments_dataset\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomment_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m      2\u001b[0m comments_dataset\n",
      "\u001b[1;31mKeyError\u001b[0m: 'comment_length'"
     ]
    }
   ],
   "source": [
    "comments_dataset = comments_dataset.filter(lambda x: x[\"comment_length\"] > 15)\n",
    "comments_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01bb055d8890405b8efa451ffef1511c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7238 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"NoneType\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcatenate_text\u001b[39m(examples):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;241m+\u001b[39m examples[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomments\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      8\u001b[0m     }\n\u001b[1;32m---> 11\u001b[0m comments_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcomments_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcatenate_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    558\u001b[0m }\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3073\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3068\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3069\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3070\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3071\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3072\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3073\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3074\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m   3075\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3446\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3444\u001b[0m _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   3445\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[1;32m-> 3446\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m update_data:\n\u001b[0;32m   3448\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3338\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[0;32m   3337\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[1;32m-> 3338\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m function(\u001b[38;5;241m*\u001b[39mfn_args, \u001b[38;5;241m*\u001b[39madditional_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_kwargs)\n\u001b[0;32m   3339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[0;32m   3340\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3341\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[0;32m   3342\u001b[0m     }\n",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m, in \u001b[0;36mconcatenate_text\u001b[1;34m(examples)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcatenate_text\u001b[39m(examples):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m----> 3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbody\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      8\u001b[0m     }\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str"
     ]
    }
   ],
   "source": [
    "def concatenate_text(examples):\n",
    "    return {\n",
    "        \"text\": examples[\"title\"]\n",
    "        + \" \\n \"\n",
    "        + examples[\"body\"]\n",
    "        + \" \\n \"\n",
    "        + examples[\"comments\"]\n",
    "    }\n",
    "\n",
    "\n",
    "comments_dataset = comments_dataset.map(concatenate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d451e9fc2f0a47b28dc302a6db703afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279855a965ed4db8848d86248c7b25a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d65e20efbe4c489e54da34a1e55b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e000a457fb6e493bbb7301698b7d465b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5677031364ec4098bab15ceda8af2ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\losses.py:2674: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.mpnet.modeling_mpnet because of the following error (look up to see its traceback):\nDescriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py:1793\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1792\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1793\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\mpnet\\modeling_mpnet.py:35\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     27\u001b[0m     BaseModelOutput,\n\u001b[0;32m     28\u001b[0m     BaseModelOutputWithPooling,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m     TokenClassifierOutput,\n\u001b[0;32m     34\u001b[0m )\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_pruneable_heads_and_indices, prune_linear_layer\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:48\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PeftAdapterMixin, deepspeed_config, is_deepspeed_zero3_enabled\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LOSS_MAPPING\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     Conv1D,\n\u001b[0;32m     51\u001b[0m     apply_chunking_to_forward,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m     translate_to_torch_parallel_style,\n\u001b[0;32m     59\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\loss\\loss_utils.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BCEWithLogitsLoss, MSELoss\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_deformable_detr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_for_object_detection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ForObjectDetectionLoss, ForSegmentationLoss\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\loss\\loss_deformable_detr.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_transforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m center_to_corners_format\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_scipy_available\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\image_transforms.py:50\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tf_available():\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_flax_available():\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py:467\u001b[0m\n\u001b[0;32m    466\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m     \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkeras.src.optimizers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\__init__.py:21\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\models\\__init__.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\functional.py:27\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layout_map \u001b[38;5;28;01mas\u001b[39;00m layout_map_lib\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\dtensor\\layout_map.py:27\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m base_layer\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\base_layer.py:43\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixed_precision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m policy\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layer_serialization\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generic_utils\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\saving\\legacy\\saved_model\\layer_serialization.py:23\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constants\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_impl\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialized_attributes\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\saving\\legacy\\saved_model\\save_impl.py:34\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constants\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load \u001b[38;5;28;01mas\u001b[39;00m keras_load\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialized_attributes\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\saving\\legacy\\saved_model\\load.py:29\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizer_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizer_v2\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saved_metadata_pb2\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m versions_pb2\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\protobuf\\saved_metadata_pb2.py:16\u001b[0m\n\u001b[0;32m     13\u001b[0m _sym_db \u001b[38;5;241m=\u001b[39m _symbol_database\u001b[38;5;241m.\u001b[39mDefault()\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotobuf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m versions_pb2 \u001b[38;5;28;01mas\u001b[39;00m keras_dot_protobuf_dot_versions__pb2\n\u001b[0;32m     19\u001b[0m DESCRIPTOR \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mFileDescriptor(\n\u001b[0;32m     20\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras/protobuf/saved_metadata.proto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     21\u001b[0m   package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthird_party.py.keras.protobuf\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m   ,\n\u001b[0;32m     26\u001b[0m   dependencies\u001b[38;5;241m=\u001b[39m[keras_dot_protobuf_dot_versions__pb2\u001b[38;5;241m.\u001b[39mDESCRIPTOR,])\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\protobuf\\versions_pb2.py:36\u001b[0m\n\u001b[0;32m     18\u001b[0m DESCRIPTOR \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mFileDescriptor(\n\u001b[0;32m     19\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras/protobuf/versions.proto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     20\u001b[0m   package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthird_party.py.keras.protobuf\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m   serialized_pb\u001b[38;5;241m=\u001b[39m_b(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x1d\u001b[39;00m\u001b[38;5;124mkeras/protobuf/versions.proto\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x1d\u001b[39;00m\u001b[38;5;124mthird_party.py.keras.protobuf\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mK\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mVersionDef\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x10\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x08\u001b[39;00m\u001b[38;5;124mproducer\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;130;01m\\x05\u001b[39;00m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x14\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x0c\u001b[39;00m\u001b[38;5;124mmin_consumer\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x02\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;130;01m\\x05\u001b[39;00m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x15\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124mbad_consumers\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;130;01m\\x05\u001b[39;00m\u001b[38;5;130;01m\\x62\u001b[39;00m\u001b[38;5;130;01m\\x06\u001b[39;00m\u001b[38;5;124mproto3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     29\u001b[0m _VERSIONDEF \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mDescriptor(\n\u001b[0;32m     30\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVersionDef\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     31\u001b[0m   full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthird_party.py.keras.protobuf.VersionDef\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     32\u001b[0m   filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     33\u001b[0m   file\u001b[38;5;241m=\u001b[39mDESCRIPTOR,\n\u001b[0;32m     34\u001b[0m   containing_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     35\u001b[0m   fields\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m---> 36\u001b[0m     \u001b[43m_descriptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFieldDescriptor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproducer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mthird_party.py.keras.protobuf.VersionDef.producer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnumber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcpp_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m      \u001b[49m\u001b[43mhas_default_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmessage_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menum_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontaining_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m      \u001b[49m\u001b[43mis_extension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension_scope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43mserialized_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDESCRIPTOR\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     43\u001b[0m     _descriptor\u001b[38;5;241m.\u001b[39mFieldDescriptor(\n\u001b[0;32m     44\u001b[0m       name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_consumer\u001b[39m\u001b[38;5;124m'\u001b[39m, full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthird_party.py.keras.protobuf.VersionDef.min_consumer\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     45\u001b[0m       number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, cpp_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     46\u001b[0m       has_default_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, default_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     47\u001b[0m       message_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, enum_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, containing_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m       is_extension\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, extension_scope\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     49\u001b[0m       serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, file\u001b[38;5;241m=\u001b[39mDESCRIPTOR),\n\u001b[0;32m     50\u001b[0m     _descriptor\u001b[38;5;241m.\u001b[39mFieldDescriptor(\n\u001b[0;32m     51\u001b[0m       name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbad_consumers\u001b[39m\u001b[38;5;124m'\u001b[39m, full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthird_party.py.keras.protobuf.VersionDef.bad_consumers\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m     52\u001b[0m       number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, cpp_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     53\u001b[0m       has_default_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, default_value\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m     54\u001b[0m       message_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, enum_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, containing_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     55\u001b[0m       is_extension\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, extension_scope\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     56\u001b[0m       serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, file\u001b[38;5;241m=\u001b[39mDESCRIPTOR),\n\u001b[0;32m     57\u001b[0m   ],\n\u001b[0;32m     58\u001b[0m   extensions\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     59\u001b[0m   ],\n\u001b[0;32m     60\u001b[0m   nested_types\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m     61\u001b[0m   enum_types\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     62\u001b[0m   ],\n\u001b[0;32m     63\u001b[0m   serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     64\u001b[0m   is_extendable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     65\u001b[0m   syntax\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproto3\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     66\u001b[0m   extension_ranges\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m     67\u001b[0m   oneofs\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     68\u001b[0m   ],\n\u001b[0;32m     69\u001b[0m   serialized_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[0;32m     70\u001b[0m   serialized_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m139\u001b[39m,\n\u001b[0;32m     71\u001b[0m )\n\u001b[0;32m     73\u001b[0m DESCRIPTOR\u001b[38;5;241m.\u001b[39mmessage_types_by_name[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVersionDef\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m _VERSIONDEF\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\descriptor.py:621\u001b[0m, in \u001b[0;36mFieldDescriptor.__new__\u001b[1;34m(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, name, full_name, index, number, \u001b[38;5;28mtype\u001b[39m, cpp_type, label,\n\u001b[0;32m    616\u001b[0m             default_value, message_type, enum_type, containing_type,\n\u001b[0;32m    617\u001b[0m             is_extension, extension_scope, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    618\u001b[0m             serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    619\u001b[0m             has_default_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, containing_oneof\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    620\u001b[0m             file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, create_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[1;32m--> 621\u001b[0m   \u001b[43m_message\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_CheckCalledFromGeneratedFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m is_extension:\n",
      "\u001b[1;31mTypeError\u001b[0m: Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m model_ckpt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence-transformers/multi-qa-mpnet-base-dot-v1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_ckpt)\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_ckpt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    560\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    561\u001b[0m     )\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m--> 563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m \u001b[43m_get_model_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_mapping\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    565\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    566\u001b[0m     )\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    570\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:388\u001b[0m, in \u001b[0;36m_get_model_class\u001b[1;34m(config, model_mapping)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_model_class\u001b[39m(config, model_mapping):\n\u001b[1;32m--> 388\u001b[0m     supported_models \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(supported_models, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    390\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m supported_models\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:763\u001b[0m, in \u001b[0;36m_LazyAutoMapping.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping:\n\u001b[0;32m    762\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping[model_type]\n\u001b[1;32m--> 763\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_attr_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;66;03m# Maybe there was several model types associated with this config.\u001b[39;00m\n\u001b[0;32m    766\u001b[0m model_types \u001b[38;5;241m=\u001b[39m [k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_mapping\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;241m==\u001b[39m key\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:777\u001b[0m, in \u001b[0;36m_LazyAutoMapping._load_attr_from_module\u001b[1;34m(self, model_type, attr)\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[0;32m    776\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[module_name] \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.models\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 777\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetattribute_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:693\u001b[0m, in \u001b[0;36mgetattribute_from_module\u001b[1;34m(module, attr)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(attr, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(getattribute_from_module(module, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m attr)\n\u001b[1;32m--> 693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, attr)\n\u001b[0;32m    695\u001b[0m \u001b[38;5;66;03m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[39;00m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;66;03m# object at the top level.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py:1781\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1779\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1781\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1782\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\import_utils.py:1795\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1793\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1795\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1796\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1797\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1798\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.models.mpnet.modeling_mpnet because of the following error (look up to see its traceback):\nDescriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_ckpt = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModel.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_pooling(model_output):\n",
    "    return model_output.last_hidden_state[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text_list):\n",
    "    encoded_input = tokenizer(\n",
    "        text_list, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "    model_output = model(**encoded_input)\n",
    "    return cls_pooling(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column text not in the dataset. Current columns in the dataset: ['html_url', 'title', 'comments', 'body']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m embedding \u001b[38;5;241m=\u001b[39m get_embeddings(\u001b[43mcomments_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      2\u001b[0m embedding\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:2780\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[0;32m   2779\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:2764\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[1;34m(self, key, **kwargs)\u001b[0m\n\u001b[0;32m   2762\u001b[0m format_kwargs \u001b[38;5;241m=\u001b[39m format_kwargs \u001b[38;5;28;01mif\u001b[39;00m format_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m   2763\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m-> 2764\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m \u001b[43mquery_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2765\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_table(\n\u001b[0;32m   2766\u001b[0m     pa_subtable, key, formatter\u001b[38;5;241m=\u001b[39mformatter, format_columns\u001b[38;5;241m=\u001b[39mformat_columns, output_all_columns\u001b[38;5;241m=\u001b[39moutput_all_columns\n\u001b[0;32m   2767\u001b[0m )\n\u001b[0;32m   2768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\formatting\\formatting.py:590\u001b[0m, in \u001b[0;36mquery_table\u001b[1;34m(table, key, indices)\u001b[0m\n\u001b[0;32m    588\u001b[0m         _raise_bad_key_type(key)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 590\u001b[0m     \u001b[43m_check_valid_column_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    592\u001b[0m     size \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mnum_rows \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m table\u001b[38;5;241m.\u001b[39mnum_rows\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\formatting\\formatting.py:527\u001b[0m, in \u001b[0;36m_check_valid_column_key\u001b[1;34m(key, columns)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_valid_column_key\u001b[39m(key: \u001b[38;5;28mstr\u001b[39m, columns: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[1;32m--> 527\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in the dataset. Current columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Column text not in the dataset. Current columns in the dataset: ['html_url', 'title', 'comments', 'body']\""
     ]
    }
   ],
   "source": [
    "embedding = get_embeddings(comments_dataset[\"text\"][0])\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df1c25db27349fbba33f9e34d07740a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7238 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m embeddings_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcomments_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[0;32m    558\u001b[0m }\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3073\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3068\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[0;32m   3069\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3070\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[0;32m   3071\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3072\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m-> 3073\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   3074\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[0;32m   3075\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3446\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3444\u001b[0m _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   3445\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[1;32m-> 3446\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m update_data:\n\u001b[0;32m   3448\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3338\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[0;32m   3337\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[1;32m-> 3338\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m function(\u001b[38;5;241m*\u001b[39mfn_args, \u001b[38;5;241m*\u001b[39madditional_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_kwargs)\n\u001b[0;32m   3339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[0;32m   3340\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3341\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[0;32m   3342\u001b[0m     }\n",
      "Cell \u001b[1;32mIn[38], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m embeddings_dataset \u001b[38;5;241m=\u001b[39m comments_dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: get_embeddings(\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]}\n\u001b[0;32m      3\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\reyri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\formatting\\formatting.py:277\u001b[0m, in \u001b[0;36mLazyDict.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m--> 277\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys_to_format:\n\u001b[0;32m    279\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "embeddings_dataset = comments_dataset.map(\n",
    "    lambda x: {\"embeddings\": get_embeddings(x[\"text\"]).detach().cpu().numpy()[0]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43membeddings_dataset\u001b[49m\u001b[38;5;241m.\u001b[39madd_faiss_index(column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embeddings_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "embeddings_dataset.add_faiss_index(column=\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow can I load a dataset offline?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m question_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      3\u001b[0m question_embedding\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[1;32mIn[36], line 6\u001b[0m, in \u001b[0;36mget_embeddings\u001b[1;34m(text_list)\u001b[0m\n\u001b[0;32m      2\u001b[0m encoded_input \u001b[38;5;241m=\u001b[39m tokenizer(\n\u001b[0;32m      3\u001b[0m     text_list, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      5\u001b[0m encoded_input \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m encoded_input\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m----> 6\u001b[0m model_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoded_input)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cls_pooling(model_output)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "question = \"How can I load a dataset offline?\"\n",
    "question_embedding = get_embeddings([question]).cpu().detach().numpy()\n",
    "question_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m scores, samples \u001b[38;5;241m=\u001b[39m \u001b[43membeddings_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mget_nearest_examples(\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m, question_embedding, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[0;32m      3\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embeddings_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "scores, samples = embeddings_dataset.get_nearest_examples(\n",
    "    \"embeddings\", question_embedding, k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m samples_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(\u001b[43msamples\u001b[49m)\n\u001b[0;32m      4\u001b[0m samples_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m scores\n\u001b[0;32m      5\u001b[0m samples_df\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'samples' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "samples_df = pd.DataFrame.from_dict(samples)\n",
    "samples_df[\"scores\"] = scores\n",
    "samples_df.sort_values(\"scores\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m samples_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(\u001b[43msamples\u001b[49m)\n\u001b[0;32m      4\u001b[0m samples_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m scores\n\u001b[0;32m      5\u001b[0m samples_df\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'samples' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "samples_df = pd.DataFrame.from_dict(samples)\n",
    "samples_df[\"scores\"] = scores\n",
    "samples_df.sort_values(\"scores\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
