{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "756e5607f8474b6ea1edcc921c8219ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a91d94533974af7947863c1cdaefdba",
              "IPY_MODEL_92e4fb6f12cc49cf967c86194ffa3f1b",
              "IPY_MODEL_f17b9018bee54e93a454f0549af246f9"
            ],
            "layout": "IPY_MODEL_8e094f2e6cb24dbdb9cd5277817abc56"
          }
        },
        "7a91d94533974af7947863c1cdaefdba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_191587671f164b7685539c56f128e259",
            "placeholder": "​",
            "style": "IPY_MODEL_74b967b80ec74045a69ce7031f6a9cb5",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "92e4fb6f12cc49cf967c86194ffa3f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14012b88152e4c369e90e2a2ad07a8aa",
            "max": 406,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c01d96562d62476590cd48d6d5d2846a",
            "value": 406
          }
        },
        "f17b9018bee54e93a454f0549af246f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df19a5921fb84f03b7c82bba52661a02",
            "placeholder": "​",
            "style": "IPY_MODEL_5669436236244874a7b48fbc607ea204",
            "value": " 406/406 [00:00&lt;00:00, 17.5kB/s]"
          }
        },
        "8e094f2e6cb24dbdb9cd5277817abc56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "191587671f164b7685539c56f128e259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74b967b80ec74045a69ce7031f6a9cb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14012b88152e4c369e90e2a2ad07a8aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c01d96562d62476590cd48d6d5d2846a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df19a5921fb84f03b7c82bba52661a02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5669436236244874a7b48fbc607ea204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60b1d81df36c4a24a7e0426c123a5aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4dcce2e15ab4f92bc15b6c2bc3bd561",
              "IPY_MODEL_c0ca9c5b39b04ed78e343dd59c8840db",
              "IPY_MODEL_be35a0456be045a5a52d8f179513ded9"
            ],
            "layout": "IPY_MODEL_49e9d1381a89493bab0f662ea2d758d7"
          }
        },
        "d4dcce2e15ab4f92bc15b6c2bc3bd561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee66ba11c7b74082a59d1cfc0a4fe608",
            "placeholder": "​",
            "style": "IPY_MODEL_c165c0942ed9457f92c3ac33881f0de2",
            "value": "config.json: 100%"
          }
        },
        "c0ca9c5b39b04ed78e343dd59c8840db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f298423dd4340dd93a75be0d749bada",
            "max": 69770,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_482f16507bf746709144773c66d3cf46",
            "value": 69770
          }
        },
        "be35a0456be045a5a52d8f179513ded9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7429e3b41b5e4c699653176c51c07f93",
            "placeholder": "​",
            "style": "IPY_MODEL_67105e42c73c4403bcc96b1d44de9e24",
            "value": " 69.8k/69.8k [00:00&lt;00:00, 2.32MB/s]"
          }
        },
        "49e9d1381a89493bab0f662ea2d758d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee66ba11c7b74082a59d1cfc0a4fe608": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c165c0942ed9457f92c3ac33881f0de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f298423dd4340dd93a75be0d749bada": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "482f16507bf746709144773c66d3cf46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7429e3b41b5e4c699653176c51c07f93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67105e42c73c4403bcc96b1d44de9e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b334e4ac88f4949a6f799347c0d0603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d239863909884602a145232e6b2b2e0a",
              "IPY_MODEL_12e2681d2f214e4a8c4f2b36d1acb9dd",
              "IPY_MODEL_bd0243294bcd4a5dbcdaee35df11057f"
            ],
            "layout": "IPY_MODEL_6cdbc9f4a40648b591106a23567839f7"
          }
        },
        "d239863909884602a145232e6b2b2e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_068b64ee7dbc464eaadb2cc2efaf4c92",
            "placeholder": "​",
            "style": "IPY_MODEL_686c06744da84e2d8acf4dce4095d751",
            "value": "model.safetensors: 100%"
          }
        },
        "12e2681d2f214e4a8c4f2b36d1acb9dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e718a336a1ea4d3098d343d31d6d37cd",
            "max": 14199388,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2e7159ea0091472786876b7947d4d48f",
            "value": 14199388
          }
        },
        "bd0243294bcd4a5dbcdaee35df11057f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63444e9062d94bad80e0406b2ef43f14",
            "placeholder": "​",
            "style": "IPY_MODEL_88c65579274c47d7845c9e9571852e56",
            "value": " 14.2M/14.2M [00:00&lt;00:00, 29.9MB/s]"
          }
        },
        "6cdbc9f4a40648b591106a23567839f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "068b64ee7dbc464eaadb2cc2efaf4c92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "686c06744da84e2d8acf4dce4095d751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e718a336a1ea4d3098d343d31d6d37cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e7159ea0091472786876b7947d4d48f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63444e9062d94bad80e0406b2ef43f14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c65579274c47d7845c9e9571852e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "CONVOLUTIONAL NETWORKS\n",
        "\n",
        "**Pendahuluan Jaringan Saraf Tiruan Konvolusional (CNN)**\n",
        "\n",
        "Jaringan Saraf Tiruan Konvolusional (Convolutional Neural Networks - CNN) adalah jenis jaringan saraf tiruan yang dirancang khusus untuk memproses data yang memiliki struktur seperti grid, seperti gambar. CNN telah merevolusi bidang visi komputer berkat kemampuannya dalam mempelajari fitur-fitur penting dari gambar secara otomatis.  Keunggulan utama CNN terletak pada lapisan konvolusi, yang menggunakan filter untuk mendeteksi pola-pola tertentu dalam gambar, seperti tepi, sudut, dan tekstur. ([Hugging Face Computer Vision Course](https://huggingface.co/learn/computer-vision-course/en/unit2/cnns/introduction))\n",
        "\n",
        "**Jaringan Konvolusional Sangat Dalam untuk Pengenalan Gambar Skala Besar (Very Deep Convolutional Networks for Large-Scale Image Recognition)**\n",
        "\n",
        "Penelitian tentang jaringan konvolusional yang sangat dalam telah menunjukkan peningkatan performa yang signifikan dalam tugas pengenalan gambar skala besar. Arsitektur seperti VGGNet, dengan kedalaman hingga 19 lapisan,  mampu mempelajari representasi gambar yang lebih kaya dan kompleks.  Semakin dalam jaringan, semakin banyak fitur hierarkis yang dapat dipelajari, mulai dari fitur sederhana seperti tepi dan sudut hingga fitur yang lebih kompleks seperti objek dan wajah. ([Hugging Face Computer Vision Course](https://huggingface.co/learn/computer-vision-course/en/unit2/cnns/introduction))\n",
        "\n",
        "\n",
        "**ConvNeXt - Sebuah ConvNet untuk Tahun 2020-an**\n",
        "\n",
        "ConvNeXt merupakan arsitektur CNN modern yang mengadopsi beberapa ide desain dari transformer, seperti penggunaan strategi pelatihan yang lebih modern dan perubahan pada struktur blok konvolusi.  Hasilnya adalah model yang lebih efisien dan akurat dibandingkan dengan CNN tradisional. ([Hugging Face Computer Vision Course](https://huggingface.co/learn/computer-vision-course/en/unit2/cnns/introduction))\n",
        "\n",
        "**Transfer Learning**\n",
        "\n",
        "Transfer learning adalah teknik yang memanfaatkan pengetahuan yang telah dipelajari oleh model yang sudah terlatih pada dataset besar (misalnya ImageNet) untuk tugas yang berbeda atau dataset yang lebih kecil.  Teknik ini sangat berguna ketika kita memiliki data yang terbatas untuk melatih model dari awal.  Dengan transfer learning, kita dapat menghemat waktu dan sumber daya komputasi, serta mencapai performa yang lebih baik. ([Hugging Face Computer Vision Course](https://huggingface.co/learn/computer-vision-course/en/unit2/cnns/introduction))\n",
        "\n"
      ],
      "metadata": {
        "id": "1hJ7ina3J9kf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch Example\n"
      ],
      "metadata": {
        "id": "2b8_To28PGQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class VGG19(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(VGG19, self).__init__()\n",
        "\n",
        "        # Feature extraction layers: Convolutional and pooling layers\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                3, 64, kernel_size=3, padding=1\n",
        "            ),  # 3 input channels, 64 output channels, 3x3 kernel, 1 padding\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(\n",
        "                kernel_size=2, stride=2\n",
        "            ),  # Max pooling with 2x2 kernel and stride 2\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        # Fully connected layers for classification\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(\n",
        "                512 * 7 * 7, 4096\n",
        "            ),  # 512 channels, 7x7 spatial dimensions after max pooling\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),  # Dropout layer with 0.5 dropout probability\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, num_classes),  # Output layer with 'num_classes' output units\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature_extractor(x)  # Pass input through the feature extractor layers\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output for the fully connected layers\n",
        "        x = self.classifier(x)  # Pass flattened output through the classifier layers\n",
        "        return x"
      ],
      "metadata": {
        "id": "2NtZgB0_K2GN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GoogleNet"
      ],
      "metadata": {
        "id": "6X36aYIAPAqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GoogLeNet**\n",
        "\n",
        "GoogLeNet, atau Inception v1, memperkenalkan konsep \"Inception module\" yang memungkinkan jaringan untuk mempelajari berbagai ukuran filter secara bersamaan dalam satu lapisan.  Hal ini meningkatkan efisiensi dan akurasi model.  Arsitektur ini juga memanfaatkan \"global average pooling\" untuk mengurangi jumlah parameter dan mencegah overfitting. ([Hugging Face Computer Vision Course](https://huggingface.co/learn/computer-vision-course/en/unit2/cnns/introduction))"
      ],
      "metadata": {
        "id": "j7piEIwslfKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class BaseConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, **kwargs):\n",
        "        super(BaseConv2d, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class InceptionModule(nn.Module):\n",
        "    def __init__(self, in_channels, n1x1, n3x3red, n3x3, n5x5red, n5x5, pool_proj):\n",
        "        super(InceptionModule, self).__init__()\n",
        "\n",
        "        self.b1 = BaseConv2d(in_channels, n1x1, kernel_size=1)\n",
        "\n",
        "        self.b2 = nn.Sequential(\n",
        "            BaseConv2d(in_channels, n3x3red, kernel_size=1),\n",
        "            BaseConv2d(n3x3red, n3x3, kernel_size=3, padding=1),\n",
        "        )\n",
        "\n",
        "        self.b3 = nn.Sequential(\n",
        "            BaseConv2d(in_channels, n5x5red, kernel_size=1),\n",
        "            BaseConv2d(n5x5red, n5x5, kernel_size=5, padding=2),\n",
        "        )\n",
        "\n",
        "        self.b4 = nn.Sequential(\n",
        "            nn.MaxPool2d(3, stride=1, padding=1),\n",
        "            BaseConv2d(in_channels, pool_proj, kernel_size=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y1 = self.b1(x)\n",
        "        y2 = self.b2(x)\n",
        "        y3 = self.b3(x)\n",
        "        y4 = self.b4(x)\n",
        "        return torch.cat([y1, y2, y3, y4], 1)\n",
        "\n",
        "\n",
        "class AuxiliaryClassifier(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes, dropout=0.7):\n",
        "        super(AuxiliaryClassifier, self).__init__()\n",
        "        self.pool = nn.AvgPool2d(5, stride=3)\n",
        "        self.conv = BaseConv2d(in_channels, 128, kernel_size=1)\n",
        "        self.relu = nn.ReLU(True)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(2048, 1024)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class GoogLeNet(nn.Module):\n",
        "    def __init__(self, use_aux=True):\n",
        "        super(GoogLeNet, self).__init__()\n",
        "\n",
        "        self.use_aux = use_aux\n",
        "        ## block 1\n",
        "        self.conv1 = BaseConv2d(3, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.lrn1 = nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75)\n",
        "        self.maxpool1 = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        ## block 2\n",
        "        self.conv2 = BaseConv2d(64, 64, kernel_size=1)\n",
        "        self.conv3 = BaseConv2d(64, 192, kernel_size=3, padding=1)\n",
        "        self.lrn2 = nn.LocalResponseNorm(5, alpha=0.0001, beta=0.75)\n",
        "        self.maxpool2 = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        ## block 3\n",
        "        self.inception3a = InceptionModule(192, 64, 96, 128, 16, 32, 32)\n",
        "        self.inception3b = InceptionModule(256, 128, 128, 192, 32, 96, 64)\n",
        "        self.maxpool3 = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        ## block 4\n",
        "        self.inception4a = InceptionModule(480, 192, 96, 208, 16, 48, 64)\n",
        "        self.inception4b = InceptionModule(512, 160, 112, 224, 24, 64, 64)\n",
        "        self.inception4c = InceptionModule(512, 128, 128, 256, 24, 64, 64)\n",
        "        self.inception4d = InceptionModule(512, 112, 144, 288, 32, 64, 64)\n",
        "        self.inception4e = InceptionModule(528, 256, 160, 320, 32, 128, 128)\n",
        "        self.maxpool4 = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        ## block 5\n",
        "        self.inception5a = InceptionModule(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.inception5b = InceptionModule(832, 384, 192, 384, 48, 128, 128)\n",
        "\n",
        "        ## auxiliary classifier\n",
        "        if self.use_aux:\n",
        "            self.aux1 = AuxiliaryClassifier(512, 1000)\n",
        "            self.aux2 = AuxiliaryClassifier(528, 1000)\n",
        "\n",
        "        ## block 6\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.fc = nn.Linear(1024, 1000)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ## block 1\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.lrn1(x)\n",
        "\n",
        "        ## block 2\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.lrn2(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        ## block 3\n",
        "        x = self.inception3a(x)\n",
        "        x = self.inception3b(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        ## block 4\n",
        "        x = self.inception4a(x)\n",
        "        if self.use_aux:\n",
        "            aux1 = self.aux1(x)\n",
        "        x = self.inception4b(x)\n",
        "        x = self.inception4c(x)\n",
        "        x = self.inception4d(x)\n",
        "        if self.use_aux:\n",
        "            aux2 = self.aux2(x)\n",
        "        x = self.inception4e(x)\n",
        "        x = self.maxpool4(x)\n",
        "\n",
        "        ## block 5\n",
        "        x = self.inception5a(x)\n",
        "        x = self.inception5b(x)\n",
        "\n",
        "        ## block 6\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        if self.use_aux:\n",
        "            return x, aux1, aux2\n",
        "        else:\n",
        "            return x"
      ],
      "metadata": {
        "id": "U-uqhPtMK6Gj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MOBILENET KODE"
      ],
      "metadata": {
        "id": "gaC40nlALkTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MobileNet**\n",
        "\n",
        "MobileNet dirancang khusus untuk perangkat mobile dan embedded dengan sumber daya terbatas. Arsitektur ini menggunakan \"depthwise separable convolutions\" untuk mengurangi jumlah komputasi dan parameter secara signifikan,  sehingga memungkinkan model untuk berjalan efisien di perangkat dengan daya komputasi dan memori terbatas. ([Hugging Face Computer Vision Course](https://huggingface.co/learn/computer-vision-course/en/unit2/cnns/introduction))"
      ],
      "metadata": {
        "id": "-hLsbc5noZkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "# initialize processor and model\n",
        "preprocessor = AutoImageProcessor.from_pretrained(\"google/mobilenet_v2_1.0_224\")\n",
        "model = AutoModelForImageClassification.from_pretrained(\"google/mobilenet_v2_1.0_224\")\n",
        "\n",
        "# preprocess the inputs\n",
        "inputs = preprocessor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "# get the output and the class labels\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits\n",
        "\n",
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235,
          "referenced_widgets": [
            "756e5607f8474b6ea1edcc921c8219ce",
            "7a91d94533974af7947863c1cdaefdba",
            "92e4fb6f12cc49cf967c86194ffa3f1b",
            "f17b9018bee54e93a454f0549af246f9",
            "8e094f2e6cb24dbdb9cd5277817abc56",
            "191587671f164b7685539c56f128e259",
            "74b967b80ec74045a69ce7031f6a9cb5",
            "14012b88152e4c369e90e2a2ad07a8aa",
            "c01d96562d62476590cd48d6d5d2846a",
            "df19a5921fb84f03b7c82bba52661a02",
            "5669436236244874a7b48fbc607ea204",
            "60b1d81df36c4a24a7e0426c123a5aa7",
            "d4dcce2e15ab4f92bc15b6c2bc3bd561",
            "c0ca9c5b39b04ed78e343dd59c8840db",
            "be35a0456be045a5a52d8f179513ded9",
            "49e9d1381a89493bab0f662ea2d758d7",
            "ee66ba11c7b74082a59d1cfc0a4fe608",
            "c165c0942ed9457f92c3ac33881f0de2",
            "5f298423dd4340dd93a75be0d749bada",
            "482f16507bf746709144773c66d3cf46",
            "7429e3b41b5e4c699653176c51c07f93",
            "67105e42c73c4403bcc96b1d44de9e24",
            "9b334e4ac88f4949a6f799347c0d0603",
            "d239863909884602a145232e6b2b2e0a",
            "12e2681d2f214e4a8c4f2b36d1acb9dd",
            "bd0243294bcd4a5dbcdaee35df11057f",
            "6cdbc9f4a40648b591106a23567839f7",
            "068b64ee7dbc464eaadb2cc2efaf4c92",
            "686c06744da84e2d8acf4dce4095d751",
            "e718a336a1ea4d3098d343d31d6d37cd",
            "2e7159ea0091472786876b7947d4d48f",
            "63444e9062d94bad80e0406b2ef43f14",
            "88c65579274c47d7845c9e9571852e56"
          ]
        },
        "id": "82pkRMg5LmdA",
        "outputId": "44d037ee-7433-4bf7-9cda-c542f663e733"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/406 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "756e5607f8474b6ea1edcc921c8219ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/69.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60b1d81df36c4a24a7e0426c123a5aa7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/14.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b334e4ac88f4949a6f799347c0d0603"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tabby, tabby cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DepthwiseSeparableConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride):\n",
        "        super().__init__()\n",
        "        self.depthwise = nn.Conv2d(\n",
        "            in_channels,\n",
        "            in_channels,\n",
        "            kernel_size=3,\n",
        "            stride=stride,\n",
        "            padding=1,\n",
        "            groups=in_channels,\n",
        "        )\n",
        "        self.pointwise = nn.Conv2d(\n",
        "            in_channels, out_channels, kernel_size=1, stride=1, padding=0\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)\n",
        "        x = self.pointwise(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MobileNet(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # MobileNet body\n",
        "        self.dw_conv2 = DepthwiseSeparableConv(32, 64, 1)\n",
        "        self.dw_conv3 = DepthwiseSeparableConv(64, 128, 2)\n",
        "        self.dw_conv4 = DepthwiseSeparableConv(128, 128, 1)\n",
        "        self.dw_conv5 = DepthwiseSeparableConv(128, 256, 2)\n",
        "        self.dw_conv6 = DepthwiseSeparableConv(256, 256, 1)\n",
        "        self.dw_conv7 = DepthwiseSeparableConv(256, 512, 2)\n",
        "\n",
        "        # 5 depthwise separable convolutions with stride 1\n",
        "        self.dw_conv8 = DepthwiseSeparableConv(512, 512, 1)\n",
        "        self.dw_conv9 = DepthwiseSeparableConv(512, 512, 1)\n",
        "        self.dw_conv10 = DepthwiseSeparableConv(512, 512, 1)\n",
        "        self.dw_conv11 = DepthwiseSeparableConv(512, 512, 1)\n",
        "        self.dw_conv12 = DepthwiseSeparableConv(512, 512, 1)\n",
        "\n",
        "        self.dw_conv13 = DepthwiseSeparableConv(512, 1024, 2)\n",
        "        self.dw_conv14 = DepthwiseSeparableConv(1024, 1024, 1)\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.dw_conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dw_conv3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dw_conv4(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dw_conv5(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dw_conv6(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dw_conv7(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.dw_conv8(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dw_conv9(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dw_conv10(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dw_conv11(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dw_conv12(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.dw_conv13(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dw_conv14(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Create the model\n",
        "mobilenet = MobileNet(num_classes=1000)\n",
        "print(mobilenet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7h3ggVGLpOz",
        "outputId": "f7471f9b-67a5-4966-c358-2c712668c42e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MobileNet(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "  (dw_conv2): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
            "    (pointwise): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv3): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64)\n",
            "    (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv4): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "    (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv5): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)\n",
            "    (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv6): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
            "    (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv7): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
            "    (pointwise): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv8): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
            "    (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv9): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
            "    (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv10): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
            "    (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv11): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
            "    (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv12): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
            "    (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv13): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)\n",
            "    (pointwise): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (dw_conv14): DepthwiseSeparableConv(\n",
            "    (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
            "    (pointwise): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESNET CODE\n"
      ],
      "metadata": {
        "id": "AKXaw5fbLvkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ResNet**\n",
        "\n",
        "ResNet (Residual Network) mengatasi masalah \"vanishing gradient\" pada jaringan yang sangat dalam dengan memperkenalkan \"skip connections\" atau \"shortcut connections\".  Skip connection memungkinkan gradien untuk mengalir langsung ke lapisan sebelumnya,  memudahkan pelatihan jaringan yang sangat dalam dan meningkatkan performa. ([Hugging Face Computer Vision Course](https://huggingface.co/learn/computer-vision-course/en/unit2/cnns/introduction))"
      ],
      "metadata": {
        "id": "qXa7rWQpoicU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ResNetForImageClassification\n",
        "\n",
        "model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsIm_PaULyyF",
        "outputId": "70d17466-e545-4123-e752-c84968b8480a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNetForImageClassification(\n",
              "  (resnet): ResNetModel(\n",
              "    (embedder): ResNetEmbeddings(\n",
              "      (embedder): ResNetConvLayer(\n",
              "        (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "        (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (encoder): ResNetEncoder(\n",
              "      (stages): ModuleList(\n",
              "        (0): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBottleNeckLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (2): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBottleNeckLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (2): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (3): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBottleNeckLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (2): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (3): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (4): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (5): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBottleNeckLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (2): ResNetBottleNeckLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (2): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=2048, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fsspec==2024.10.0\n",
        "!pip install datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptAzITVfjvjt",
        "outputId": "833e939e-ad48-42e5-b1c5-6bbbd98c3304"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fsspec==2024.10.0\n",
            "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.9.0\n",
            "    Uninstalling fsspec-2024.9.0:\n",
            "      Successfully uninstalled fsspec-2024.9.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 3.2.0 requires fsspec[http]<=2024.9.0,>=2023.1.0, but you have fsspec 2024.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2024.10.0\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "Installing collected packages: fsspec\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2024.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoFeatureExtractor, ResNetForImageClassification\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"huggingface/cats-image\")\n",
        "image = dataset[\"test\"][\"image\"][0]\n",
        "\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(\"microsoft/resnet-50\")\n",
        "model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
        "\n",
        "inputs = feature_extractor(image, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "\n",
        "# model predicts one of the 1000 ImageNet classes\n",
        "predicted_label = logits.argmax(-1).item()\n",
        "print(model.config.id2label[predicted_label])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNQT9KYFL0SB",
        "outputId": "6fca107d-e06c-4907-ccdc-f331e872593c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiger cat\n"
          ]
        }
      ]
    }
  ]
}